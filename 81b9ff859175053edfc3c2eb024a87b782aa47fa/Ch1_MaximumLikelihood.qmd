<!-- LTeX: language=en-US -->
# Maximum Likelihood

<!-- For updating: Elements of Statistical Learning and All of Statistics -->

## Introduction: The Likelihood Principle

The basic idea behind maximum likelihood estimation is very simple: Assume that the data is generated by some distribution with a certain (finite) set of unknown distribution parameters (e.g., the normal distribution with unknown mean and variance). Then find the distribution parameters for which it is most likely that the distribution has generated the data we actually observed. 

In (classic) maximum likelihood estimation we must be rather specific about the process that generated the data.  This is a trade-off: by imposing a fair amount of structure on the data, we get in return a very desirable estimator.  The question remains, however, whether we have made the right decision about the general distribution/density function family.

### Properties of Maximum Likelihood Estimators 

Why do we like maximum likelihood as an estimation method? The answer is that: A maximum likelihood estimator $\hat\theta_n$ of some parameter, e.g. $\theta_0\in\mathbb{R}$, is

* **Consistent:**  
$$
\hat\theta_n\rightarrow_p\theta_0,\quad n\to\infty
$$
* **Asymptotically normal:** 
$$
\sqrt{n}(\hat\theta_n-\theta_0) \stackrel{a}{\sim} \mathcal{N}(0, \sigma^2)
$$
* **Asymptotically efficient:** This means that no other consistent estimator has a lower asymptotic mean squared error than the maximum likelihood estimator. 

Likewise for multivariate parameter $\theta_0\in\mathbb{R}^p.$

Thus, maximum likelihood estimators can be very appealing, provided that the assumption on the general distribution family is correct.


::: {.callout-important}
## ML-estimation requires fixing the family of distributions $f(\cdot;\theta)$

Let 
$$
X_1,\dots,X_n
$$
denote a (i.i.d.) random sample, such that $X_i\overset{\text{i.i.d.}}{\sim} f$, for all $i=1,\dots,n.$

Classic ML-estimation requires us to fix the general family of density functions or probability mass functions $f,$ where $f$ is known up to an unknown parameter value $\theta_0,$ and where $\theta_0\in\mathbb{R}^K$ is a *finite* ($1\leq K<\infty$) dimensional parameter vector.  

**Examples:** 

* $f$ being the probability mass function of the Bernoulli distribution $\mathcal{Bern}(\theta)$ with 
$$
f(x;\theta_0)=
\left\{
  \begin{array}{ll}
  \theta_0,   & \text{if } x=1\\
  1-\theta_0, & \text{if } x=0
  \end{array}
\right.
$$ 
and **unknown** parameter $0\leq \theta\leq 1.$
* The density function of the exponential distribution 
$$
f(x;\theta_0)=\left\{
    \begin{matrix}
    \theta_0\exp(- \theta_0 x)& \text{for }x\geq 0\\
    0                     & \text{for }x < 0\\
    \end{matrix}\right.
$$
with unknown rate parameter $\theta_0>0$ and $x\in\mathbb{R}.$ 
* $f$ is the normal density 
$$
f(x;\theta_0)=\frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{1}{2}\left(\frac{x-\mu_0}{\sigma_0}\right)^2\right)
$$ 
with **unknown** parameter vector $\theta_0=(\mu_0,\sigma_0^2)^T$ and $x\in\mathbb{R}.$

This requirement (fixing the family of density functions) can be overly restrictive. In many applications we typically do not know the family of $f.$ To address this issue, the **quasi maximum likelihood theory** generalizes classic maximum likelihood estimation to cases where $f$ is misspecified (see @White1982).   
:::

### Example: Coin Flipping (Bernoulli Trial)

To introduce the main idea of maximum likelihood estimation, we use the simple example of a coin flipping experiment, where a **possibly unfair** $\text{Coin}$ can take the value $H$ (Head) or $T$ (Tail),
$$
\text{Coin}\in\{H,T\}.
$$ 
Such coin-flips can be modeled using Bernoulli random variables 
$$
X\sim\mathcal{Bern}(\theta_0)
$$ 
where
$$
X=\left\{
    \begin{matrix}
    1 & \text{if } \text{Coin}=H\\[2ex]
    0 & \text{if } \text{Coin}=T 
    \end{matrix}
    \right.
$$ 
The probability mass function of the Bernoulli distribution $\mathcal{Bern}(\theta_0),$ with **unknown** probability of success parameter $0<\theta_0<1,$ is given by 
$$
f(x;\theta_0)=
\left\{
  \begin{array}{ll}
  \theta_0,&\text{if } x=1\\
  1-\theta_0, & \text{if } x=0
  \end{array}
\right.
$$ 
I.e., the probability that we get Head $H$ is 
$$
\theta_0 = f(1;\theta_0) = P(X=1) = P(\text{Coin}=H),
$$
and the probability that we get Tail $T$ is 
$$
1-\theta_0 = f(0;\theta_0) = P(X=0) = P(\text{Coin}=T).
$$ 


Our goal is to **estimate the unknown** $\theta_0$ using a random (i.i.d.) sample of size $n$
$$
\{X_1,\dots,X_n\}
$$ 
with 
$$
X_i=\left\{
    \begin{matrix}
    1 & \text{if } \text{Coin}=H\text{ in $i$th coin flip}\\[2ex]
    0 & \text{if } \text{Coin}=T\text{ in $i$th coin flip} 
    \end{matrix}
    \right.
$$ 
such that 
$$
X_i\overset{\text{i.i.d.}}{\sim}\mathcal{Bern}(\theta_0),\quad i=1,\dots,n.
$$
<!-- where $\mathcal{Bern}(\theta)$ denotes the Bernoulli distribution with unknown probability of success parameter $\theta.$  -->

A **given observed realization** of the random sample 
$$
\{X_{1,obs},X_{2,obs},\dots,X_{n,obs}\}=\{0,1,\dots,0\}
$$ 
consists of $0\leq N_{H,obs}\leq n$
$$
N_{H,obs}=\sum_{i=1}^n X_{i,obs}
$$ 
many heads and
$$
0\leq n-N_{H,obs} \leq n
$$ 
many tails.


#### **The (Log-)Likelihood Function** {-}

How do we combine the information from the $n$ observations 
$$
\{X_{1,obs},\dots,X_{n,obs}\}
$$ 
to estimate the unknown $\theta_0$?

If the observations are realizations of an i.i.d. sample, then the joint probability of observing $h$ heads $H$ and $n-h$ tails $T$ in  $n$ coin flips is:
$$
\begin{align*}
\mathcal{L}_{n,obs}(\theta)
&=\prod_{i=1}^nf(X_{i,obs};\theta)\\[2ex]
%&=\left(P(X=1)\right)^{N_{H,obs}}\left(P(X=0)\right)^{n-N_{H,obs}}\\[2ex]
%&= \theta^{N_{H,obs}}(1-\theta)^{n-N_{H,obs}}  \\[2ex]
&= \prod_{i=1}^n \theta^{X_{i,obs}}(1-\theta)^{1-X_{i,obs}}, 
\end{align*} 
$$
where $f(\,\cdot\,;\theta)$ denotes here the probability mass function of the Bernoulli distribution with parameter candidate $p=\theta.$

The function $\mathcal{L}_n(\theta)$ is called the **likelihood function**. The likelihood function depends on the random sample and is thus itself random. If we want to emphasize that we look at a given realization, we write $\mathcal{L}_{,obs}(\theta)$. 


::: {.callout-note appearance="minimal"} 
## 
::: {#def-LikelihoodFunction}
# Likelihood Function
Let 
$$
\{X_{1},\dots,X_{n}\}
$$ 
denote a random sample with $X_i\overset{\text{i.i.d.}}{\sim} f\equiv f(\,\cdot\,;\theta)$ for all $i=1,\dots,n,$ where $\theta$ denotes the unknown finite dimensional parameter vector of $f.$
Then, we call 
$$
\mathcal{L}_{n,obs}(\theta)=\prod_{i=1}^n f(X_{i,obs};\theta),
$$
the (random) **likelihood function**. Let 
$$
\{X_{1,obs},\dots,X_{n,obs}\}
$$ 
denote a (observed) realization of $\{X_1,\dots,X_n\}$. Then, we call 
$$
\mathcal{L}_{n,obs}(\theta)=\prod_{i=1}^n f(X_{i,obs};\theta),
$$
a (observed) realization of the **likelihood function**.

(Note: A definition for dependent data (e.g., time series) is also possible.)
:::
:::

### Estimation Idea

We estimate the unknown parameter $\theta_0$ by maximizing the likelihood of the observed data $\{X_{1,obs},\dots,X_{n,obs}\}$ over the range of possible parameter values. 

* The value $\hat\theta_{ML}$ at which the likelihood function $\mathcal{L}_n(\cdot)$ is maximized is called the **maximum likelihood (ML) estimator**
* The value $\hat\theta_{ML,obs}$ at which the observed likelihood function $\mathcal{L}_{n,obs}(\cdot)$ is maximized is called the **maximum likelihood (ML) estimate**; i.e., $\hat\theta_{ML,obs}$ is a specific realization of the ML-estimator computed from the observed data $\{X_{1,obs},\dots,X_{n,obs}\}.$ 

::: {.callout-note appearance="minimal"} 
## 
::: {#def-MLEstimator}
# Maximum Likelihood (ML) Estimator
Let 
$$
\{X_{1},\dots,X_{n}\}
$$ 
denote a random sample with $X_i\overset{\text{i.i.d.}}{\sim} f\equiv f(\,\cdot\,;\theta)$ for all $i=1,\dots,n,$ where $\theta$ denotes the unknown finite dimensional parameter vector of $f.$
Then, we call 
$$
\begin{align*}
\hat{\theta}_{ML}
&=\arg\max_{\theta\in\Theta} \mathcal{L}_n(\theta)\\[2ex]
&=\arg\max_{\theta\in\Theta} \prod_{i=1}^n f(X_{i};\theta),
\end{align*}
$$
the Maximum Likelihood (ML) Estimator, where $\Theta$ denotes the **parameter space**.

(Note: A definition for dependent data (e.g., time series) is also possible.)
:::
:::

Thus, to derive the estimator for the unknown $\theta_0$ in our coin flip example, we need to maximize the likelihood function,
$$
\begin{align*}
\hat{\theta}_{ML}
&=\arg\max_{\theta\in[0,1]} \mathcal{L}_n(\theta)\\[2ex]
&=\arg\max_{\theta\in[0,1]} \prod_{i=1}^n f(X_{i};\theta)\\[2ex]
&=\arg\max_{\theta\in[0,1]} \prod_{i=1}^n \theta^{X_{i}}(1-\theta)^{1-X_{i}}.
\end{align*}
$$

Usually it's easier to work with sums rather than products---also for doing the asymptotics in @sec-MLAsymp. So we apply a monotonic transformation by taking the logarithm of the likelihood which leads to the **log-likelihood function**:
$$
\begin{align*}
\ell_n(\theta)
&=\ln\mathcal{L}_n(\theta)\\[2ex]
&=\ln\prod_{i=1}^n f(X_{i};\theta)\\[2ex]
&=\sum_{i=1}^n \ln f(X_{i};\theta).
\end{align*}
$$
Since this is only a monotonic transformation, we have that
$$
\begin{align*}
\hat\theta_{ML}
&=\arg\max_{\theta\in\Theta} \mathcal{L}_n(\theta)\\[2ex]
&=\arg\max_{\theta\in\Theta} \ell_n(\theta).
\end{align*}
$$
<!-- but $\ell_n(\theta)$ gives a more simple structure simplifying the maximization problem.  -->


::: {.callout-note title="Log-likelihoods instead of the likelihoods"} 

* From a standpoint of computational complexity, you can imagine that summing is less expensive than multiplication (although nowadays, these are almost equal). 

* More important: likelihoods would become very small and you will run out of your [floating point](https://en.wikipedia.org/wiki/Floating-point_arithmetic) precision very quickly, yielding an underflow. That's why it is way more convenient to use the logarithm of the likelihood. Simply try to calculate the likelihood by hand, using pocket calculator---it's almost impossible.
:::


In our coin flipping example, taking the natural logarithm yields,
$$
\begin{align*}
\mathcal{L}_n(\theta) &= \prod_{i=1}^n \theta^{X_{i}}(1-\theta)^{1-X_{i}} \\[2ex]
\Rightarrow\quad \ell_n(\theta)
&=\ln\mathcal{L}_n(\theta)\\[2ex]
&=\sum_{i=1}^n\left( X_{i} \ln(\theta) + (1-X_{i})\ln(1-\theta)\right).
\end{align*}
$$

The coin flip example is actually so simple that we can maximize $\ell_n(\theta)$ analytically. Computing the first derivative yields
$$
\begin{align*}
\ell'_n(\theta)&=\sum_{i=1}^n \left(X_{i}\dfrac{1}{\theta} - (1-X_{i})\dfrac{1}{1-\theta}\right)\\[2ex]
&=\dfrac{N_{H}}{\theta} - \dfrac{n-N_{H}}{1-\theta} 
\end{align*}
$$
Setting the first derivative to zero determines the maximum likelihood estimator (MLE) $\hat\theta_{ML}$:
$$
\begin{array}{rrcl}
&\ell_n'(\hat\theta_{ML})&\overset{!}{=}&0\\[2ex]
\Leftrightarrow&\dfrac{N_{H}}{\hat\theta_{ML}} &=& \dfrac{n-N_{H}}{1-\hat\theta_{ML}} \\[2ex]
\Leftrightarrow&N_{H}-N_{H}\hat\theta_{ML}  &=& n\hat\theta_{ML}-N_{H}\hat\theta_{ML}\\[2ex]
\Leftrightarrow&\hat\theta_{ML}
&=&\dfrac{N_{H}}{n}\\[2ex]
&&=&\dfrac{1}{n}\sum_{i=1}^n X_i
\end{array}
$${#eq-MLECoinFlipp}

Given observed data $\{X_{1,obs},\dots,X_{n,obs}\},$ a specific estimate of $\theta_0$ can thus be computed as
$$
\begin{align*}
\hat{\theta}_{ML,obs}=\dfrac{1}{n}\sum_{i=1}^n X_{i,obs}.
\end{align*}
$$



Usually, however, the log-likelihood function is **way more complicated** such that it is impossible to derive an explicit expression for the ML-estimator $\hat\theta_{ML}.$ In such cases, one needs to apply **numeric optimization** algorithms to compute the ML-estimates, $\hat\theta_{ML,obs}.$  


## Numeric Optimization

Usually, we are not so fortunate as to have an analytical solution for the MLE, and must rely on the computer to find the maximizing arguments of the log-likelihood function. Various methods exist for finding the maximum (or minimum) of a function. 

<!-- [numerically with the help of the computer](https://jaimemosg.github.io/EstimationTools/index.html) -->

**General idea: Try to find the root of $\ell'$** 

1. Start at some value, $\theta_{(0)},$ in the parameter space $\Theta.$
2. Search across the parameter space $\Theta$ using a step-wise procedure
$$
\theta_{(0)},\theta_{(1)},\dots,\theta_{(m)}
$$ 
until an updated parameter value $\theta_{(m)}$ is found that yields a derivative of the log likelihood that is effectively zero (i.e. smaller than some convergence/stopping criterion), 
$$
\ell'(\theta_{(m)})\approx 0.
$$


### Newton-Raphson Optimization

One of the most-used methods for optimization is the Newton-Raphson method (or a variant of it). The Newton-Raphson method relies on Taylor-series approximations of the log-likelihood function. 


In the following, we consider the univariate case $\theta\in\mathbb{R}.$ However, the multivariate case $\theta\in\mathbb{R}^K$ is treated likewise, but requires substituting first derivatives by gradients, second derivatives by the Hessian, etc. 

::: {.callout-note}
Minimization and maximization are essentially the same problems, since minimizing a function $f(x)$ with respect to $x$ is equivalent to maximizing $-f(x)$ with respect to $x.$
:::


Let $f$ be a two times differentiable function to be optimized (here maximized). The **first- and second-order Taylor-series approximations** of $f$ around the point $\theta$ are:
$$
\begin{align*}
\text{First-order:}\quad &f(\theta+h)\approx \overbrace{f(\theta)+f'(\theta)h}^{\text{Taylor Polynomial of order 1}} \\
\text{Second-order:}\quad& f(\theta+h)\approx \underbrace{f(\theta)+f'(\theta)h + \frac{1}{2} f''(\theta)h^2}_{\text{Taylor Polynomial of order 2}},
\end{align*}
$$
Locally, i.e. for $|h|\approx 0,$ (e.g. $h=\pm 0.04$) the Taylor polynomials are very good approximations of $f(\theta + h);$ see @fig-taylorApprox.

```{r, echo = FALSE}
#| label: fig-taylorApprox
#| fig-cap: First- and second-order Taylor approximations of a function $f$ around $\theta=1.$

## #######################
## Taylor Approximation
## #######################
# install.packages("pracma")
library("pracma")

myFun <- function(x){
  1*exp((-1/2)*(x-1.25)^2)/10 + 
  1*exp((-1/3)*(x-3)^2)/5
}

## Taylor approximation of myFun around x0
x0              <- 1
taylor_poly_1   <- taylor(f = myFun, x0 = x0, n = 1)
taylor_poly_2   <- taylor(f = myFun, x0 = x0, n = 2)

## Plot
#x_seq           <- seq(from = x0 -2, to = x0 + 5, length.out=100)
x_seq           <- seq(from = -.5, to = 4, length.out=100)
y_myFun         <- myFun(x_seq)
y_taylor_poly_1 <- polyval(taylor_poly_1, x_seq)
y_taylor_poly_2 <- polyval(taylor_poly_2, x_seq)


plot(x  = x_seq, y = y_myFun,  type = "l", col = "black", lwd = 1, ylab="", xlab="", main = "Taylor Approximation", ylim = range(y_myFun,y_taylor_poly_1,y_taylor_poly_2))
axis(1, at=1, line=2, labels = expression(theta), tick=FALSE)
#axis(1, at=x_seq[which.max(y_taylor_poly_2)], line=2, labels = expression(theta[1]), tick=FALSE)
lines(x = x_seq, y = y_taylor_poly_1, col = "red", lty=1)
lines(x = x_seq, y = y_taylor_poly_2, col = "blue", lty=1)
points(x=1, y=myFun(1), col="black", pch=19)
# points(x=x_seq[which.max(y_taylor_poly_2)], y=max(y_taylor_poly_2), col="blue", pch=19)
lines(x=rep(x0, 2), y=c(par("usr")[3], myFun(1)), lty=2)
# lines(x=rep(x_seq[which.max(y_taylor_poly_2)],2), 
#       y=c(0,max(y_taylor_poly_2)), lty=2)
legend(x="topleft", legend=c("Function f", "Taylor Polynomial of Order 1", "Taylor Polynomial of Order 2"), col=c("black", "red", "blue"), lty=c(1,1,1), box.lwd=0)
box()
```

<!-- ::: {.callout-important}
The first-order and the second-order Taylor polynomial can both be used to approximate $f.$

The second-order Taylor polynomial can be used to apprixmate $f'.$
::: -->

::: {.callout-note appearance="minimal"} 
## 
::: {#thm-TaylorThm}
# Taylor's Theorem 

</br>
Today, there are many different versions of Taylor's theorem. We consider the following two:

**1. [Peano](https://en.wikipedia.org/wiki/Giuseppe_Peano) form of the remainder term:**</br> 
Let $f:\mathbb{R}\to\mathbb{R}$ be $k$ times differentiable at $x\in\mathbb{R}$ and let $h\in\mathbb{R}.$ Then there exists a function $P_{k,x}:\mathbb{R}\to\mathbb{R}$ such that 
$$
\begin{align*}
f(x+h) &= 
f(x) 
+ \sum_{\ell=1}^k \frac{f^{(\ell)}(x)}{\ell!} h^\ell
+ P_{k,x}(h) \cdot h^k
\end{align*}
$$
with 
$$
P_{k,x}(h)\to 0\quad\text{as}\quad |h|\to 0,
$$ 
where $f^{(\ell)}(x)$ denotes the $\ell$th derivative of $f$ at $x.$

**2. [Lagrange](https://en.wikipedia.org/wiki/Joseph-Louis_Lagrange) or Mean-value form of the remainder term:**</br> 
Let $f:\mathbb{R}\to\mathbb{R}$ be $k+1$ times differentiable on the open interval between $x$ and $x+h,$ with $h\in\mathbb{R},$ and let $f^{(k)}$ be continuous on the closed interval between $x$ and $x+h,$. Then 
$$
\begin{align*}
f(x+h) &= 
f(x) 
+ \sum_{\ell=1}^k \frac{f^{(\ell)}(x)}{\ell!} h^\ell
+ M_{k,x}(h)
\end{align*}
$$
with 
$$
M_{k,x}(h)=\frac{f^{(k+1)}(\xi)}{(k+1)!} h^{k+1}
$$ 
for some real number $\xi$ between $x$ and $x+h.$ This form of Taylor's theorem is based on the mean-value @thm-MVT. Note that 
$$
M_{k,x}(h)\to 0\quad\text{as}\quad |h|\to 0.
$$ 

::: {.callout-tip icon=false} 
## Qualitative version using the small-$o$ notation:
$$
\begin{align*}
f(x + h) & = 
f(x) 
+ \sum_{\ell=1}^k \frac{f^{(\ell)}(x)}{\ell!} h^\ell
+ o\big(|h|^k\big),
\end{align*}
$$
where $o\big(|h|^k\big)$ denotes the family of real-valued functions, $g(h)$ say, that are of a **strictly smaller $o$rder of magnitude** than the function $|h|^k$ as $h\to 0;$ i.e.  
$$
\begin{align*}
& o\big(|h|^k\big)\\[2ex]
& =\left\{\text{Any function}\;g:\mathbb{R}\to\mathbb{R}\text{ such that }\frac{|g(h)|}{|h|^k}\to 0\;\text{ as }\; |h|\to 0\right\}.
\end{align*}
$$

**1. Note: Peano form of the remainder term:**
$$
P_{k,x}(h)\cdot h^k=o\big(|h|^k\big)
$$ 
since 
$$
\frac{|P_{k,x}(h)\;h^k|}{|h|^k}
%=\frac{|P_k(x+h)|\cdot |h|^k|}{|h|^k}
=|P_{k,x}(h)|\to 0\quad\text{as}\quad h\to 0.
$$

**2. Note: Mean-value form of the remainder term:**</br>
$$
M_{k,x}(h)=o\big(|h|^k\big)
$$ 
since 
$$
\frac{|M_{k,x}(h)|}{|h|^k}=
\left|\frac{f^{(k+1)}(\xi)}{(k+1)!}\right|\cdot|h|\to 0\quad\text{as}\quad h\to 0.
$$
:::
:::
:::


#### **Optimization Idea** {-}

Let $\ell_n$ be a log-likelihood function with continuous first, $\ell_n',$ and second, $\ell_n'',$ derivative. 

To optimize the log-likelihood function $\ell_n,$ we try to find the root of $\ell_n',$ i.e. the value of $\theta\in\Theta$ such that 
$$
\ell_n'(\theta)=0.
$$ 
That is, we try to find the value of $\theta$ that fulfills the **first order condition** of the optimization problem. We do so using a step-wise optimization approach, where each step has a smallish size $h.$ 

**Initialization:** Let $\theta_{(0)}\in\Theta$ be our first guess of the root of $\ell'_n.$ 

**$h$-Steps:** Typically, our guess is not perfect and thus $\ell_n'(\theta_{(0)})\neq 0.$ Therefore, we want to move from $\theta_{(0)}$ to a new root-candidate $\theta_{(1)}$ by doing an $h$-step update 
$$
\theta_{(1)} = \theta_{(0)} + h.
$$

<!-- 1. We select some starting value $\theta_0.$ 
2. Optimize the second-order Taylor polynomial of $f$ around $\theta_0$ with respect to $h.$ 
3. In each of the following steps, we optimize new second-order Taylor polynomials of $f$ at those values $\theta,$ for which the previous second-order Taylor polynomial was maximal.  -->

<!-- **Implementation-Idea:** The second-order Taylor-series approximation gives -->
The first-order Taylor-series approximation of $\ell_n'$ around our first guess $\theta_{(0)}$ gives 
$$
\begin{align*}
\ell_n'(\theta_{(0)} + h) & \approx \ell_n'(\theta_{(0)}) + \ell_n''(\theta_{(0)})h 
\end{align*}
$$
Thus, to find the $h$-step that brings us closer to the root of $\ell_n',$ we can (approximatively) use the $h$-step that brings us to the root of its first-order approximation, i.e.
$$
\begin{align*}
\ell_n'(\theta_{(0)}) + \ell_n''(\theta_{(0)}) h_{(0)} = 0\\[2ex]
\Rightarrow h_{(0)} = -\frac{\ell_n'(\theta_{(0)})}{\ell_n''(\theta_{(0)})}.
\end{align*}
$$
Based on this $h$-step, the new root-candidate is 
$$
\begin{align*}
\theta_{(1)} 
& = \theta_{(0)} + h_{(0)}\\[2ex]
& = \theta_{(0)} - \frac{\ell_n'(\theta_{(0)})}{\ell_n''(\theta_{(0)})}.
\end{align*}
$$
Likewise, the $m$th root-candidate is 
$$
\begin{align*}
\theta_{(m)}
& = \theta_{(m-1)} + h_{(m-1)}\\[2ex]
& = \theta_{(m-1)} - \frac{\ell_n'(\theta_{(m-1)})}{\ell_n''(\theta_{(m-1)})};
\end{align*}
$$
see also @fig-NR.


```{r, echo = FALSE}
#| label: fig-NR
#| fig-cap:  The $m$th update step in the Newton-Raphson root-finding algorithm.

## #######################
## Taylor Approximation
## #######################
# install.packages("pracma")
library("pracma")

my_ell <- function(x){
  1*exp((-1/2)*(x-1.25)^2)/10 + 
  1*exp((-1/3)*(x-3)^2)/5
}
my_ell_expr <- expression(
  1*exp((-1/2)*(x-1.25)^2)/10 + 
  1*exp((-1/3)*(x-3)^2)/5
)

my_ell_prime <- function(x){}
body(my_ell_prime) <- D(my_ell_expr, "x") 

## Taylor approximation of my_ell around theta_0
theta_0         <- 1.5
taylor_poly_1   <- taylor(f = my_ell_prime, x0 = theta_0, n = 1)

## Plot
theta_seq       <- seq(from       = .75, 
                       to         = 4, 
                       length.out = 100)
y_my_ell_prime  <- my_ell_prime(theta_seq)
y_taylor_poly_1 <- polyval(taylor_poly_1, theta_seq)


root_taylor_poly_1 <- -1 * taylor_poly_1[2] / taylor_poly_1[1]

plot(x = theta_seq, 
     y = y_my_ell_prime,  
     type = "l", col = "black", lwd = 1, ylab="", xlab="", main = "", ylim = range(y_my_ell_prime,y_taylor_poly_1))
abline(h=0)
points(x=theta_0, y=my_ell_prime(theta_0), col="black", pch=19)
lines(x = theta_seq, y = y_taylor_poly_1, col = "red", lty=1)
lines(x=rep(theta_0, 2), y=c(par("usr")[3], my_ell_prime(theta_0)), lty=2)
axis(1, at=theta_0, line=2, labels = expression(theta['(m-1)']), tick=FALSE)
points(x=root_taylor_poly_1, y= 0, col="red", pch=19)
lines(x=rep(root_taylor_poly_1, 2), y=c(par("usr")[3], 0), lty=2)
axis(1, at=root_taylor_poly_1, line=2, labels = expression(theta['(m)']), tick=FALSE)
legend(x="topright", legend=c("1st Deriv. of the Log-Likelihoodfunction", expression("Taylor Polynomial of Order 1 around"~theta[(m-1)])), 
col=c("black", "red"), lty=c(1,1), box.lwd=0)
box()
```


### Convergence of the Newton-Raphson Algorithm {#sec-ConvNR}

Let $\theta_{root}$ denote the root of $\ell_n';$ i.e. 
$$
\ell_n'(\theta_{root})=0.
$$ 
We aim to find $\theta_{root}$ using the Newton-Raphson algorithm and call our best approximation of $\theta_{root}$ the maximum likelihood estimate; i.e. $\hat{\theta}_{ML}\approx\theta_{root}.$ 

Let 
$$
e_{(0)}=\theta_{root}-\theta_{(0)}
$$
denote the start value error and let 
$$
I=[\theta_{root}-|e_{(0)}|, \theta_{root}+|e_{(0)}|]
$$
denote the start value error neighborhood around $\theta_{root}.$   

One can shown that if $\ell_n'$ is "well behaved" over $I;$ i.e. 

* if $\ell_n''(\theta)\neq 0$ for all $\theta\in I$ and 
* if $\ell_n'''(\theta)$ is finite and continuous for all $\theta\in I,$ 

and if our first guess $\theta_{(0)}$ is "close enough;" i.e. 

* if $M|e_{(0)}|<1,$ 
where 
$$
M=\frac{1}{2}\left(\sup_{\theta\in I}|\ell_n'''(\theta)|\right)\left(\sup_{\theta\in I}\frac{1}{|\ell_n''(\theta)|}\right)\geq 0,
$$ 

then $\theta_{(m)}$ will converge to $\theta_{root}$ as $m\to\infty.$ 

::: {.callout-warning}
Unfortunately, we typically don't know if $\ell_n'$ is "well behaved" and we usually don't know whether our first guess is "close enough". So, typically we cannot guarantee convergence of the Newton-Raphson algorithm. 😭
<!-- Exercise: Let this be proofen: https://en.wikipedia.org/wiki/Newton%27s_method -->
:::


::: {.callout-tip}
* For problems that are globally concave, the starting value $\theta_0$ doesn't matter.  For more complex problems, however, the  Newton-Raphson algorithm can get stuck into a local maximum. In such cases, it is usually a good idea to **try multiple starting values**.

* In practice, the implementation of the Newton-Raphson algorithm can be tricky. We may have $\ell_n''(\theta_{(m)})=0,$ in which case the function looks locally like a straight line, with no solution to the Taylor series approximation 
$$
\begin{align*}
\ell_n'(\theta_{(m)} + h) & \approx \ell_n'(\theta_{(m)}) + \ell_n''(\theta_{(m)})h = \ell_n'(\theta_{(m)}). 
\end{align*}
$$
In this case a simple strategy is to move a small step in the direction which decreases the function value, based only on $\ell_n'(\theta_m).$


* In other cases where $\theta_{(m)}$ is too far from the true root $\theta_{root}$, the Taylor approximation may be so inaccurate that $\ell_n(\theta_{(m+1)})$ is actually *more distant* from zero than $\ell_n(\theta_{(m)}).$ When this happens one may replace $\theta_{(m+1)}$ with $(\theta_{(m+1)}+\theta_{(m)})/2$ (or some other value between $\theta_{(m)}$ and $\theta_{(m+1)}$) in the hope that a smaller step will produce a better result.
:::

**Stopping Criterion:** Since we are expecting that $\ell_n'(\theta_{(m)})\to 0,$ as $m\to\infty,$ a good stopping condition for the Newton-Raphson algorithm is 
$$
|\ell_n'(\theta_{(m)})|\leq \varepsilon
$$ 
for some (small) tolerance $\varepsilon>0.$ 

::: {.callout-note}
# Pseudo-Code: Newton-Raphson Algorithm
$$
\begin{array}{ll}
\texttt{\textbf{select }} \theta_{(0)}\in\Theta\;\;\text{ and}&\varepsilon>0 \\[2ex]
\texttt{\textbf{let }} m=0         &  \\
\texttt{\textbf{while }}  | \ell_n'(\theta_{(m)}) | >\varepsilon & \texttt{\textbf{do}}\\
&\left[
                                    \begin{array}{l}\texttt{\textbf{let }} m = m+1 \\
                                    \texttt{\textbf{let }} \theta_{(m)} = \theta_{(m-1)} - \frac{\ell_n'(\theta_{(m-1)})}{\ell_n''(\theta_{(m-1)})} \\
                                    \end{array} \right.\\
\texttt{\textbf{let }}\hat\theta_{ML}=\theta_{(m)} & \\
\texttt{\textbf{return }} \hat\theta_{ML} &  \\
\end{array}
$$
::: 



### Newton-Raphson Algorithm: Coin-Flipping Example 

Let's return to our earlier coin flipping example. 

If we observe, for instance, only one head $N_{H,obs}=1$ for a sample size of $n=5,$ we already know from @eq-MLECoinFlipp that 
$$
\hat\theta_{ML}=\frac{N_{H,obs}}{n}=\frac{1}{5}=0.2,
$$
but let us, nevertheless, apply the Newton-Raphson algorithm.  

The first and second derivatives of 
$$
\ell_n(\theta)=\sum_{i=1}^n\big(X_{i,obs} \ln(\theta) + (1-X_{i,obs})\ln(1-\theta)\big)
$$ 
are 
$$
\begin{align*}
\ell_n'(\theta)&=\dfrac{N_{H,obs}}{\theta} - \dfrac{n-N_{H,obs}}{1-\theta} \\[2ex]
\ell_n''(\theta) &= -\dfrac{N_{H,obs}}{\theta^2} + \dfrac{n}{(1-\theta)^2}(-1)-\dfrac{N_{H,obs}}{(1-\theta)^2}(-1)\\[2ex]
&= -\dfrac{N_{H,obs}}{\theta^2} - \dfrac{n-N_{H,obs}}{(1-\theta)^2}.
\end{align*}
$$

We consider a sample size of $n=5$ with the following observed outcome: 

* One Head:   $\quad N_{H,obs}=1$ 
* Four Tails: $\quad n-N_{H,obs}=4$

Setting $\varepsilon=10^{-10}$ as our stopping criterion and $\theta_{(0)}=0.4$ as our starting value allows us to run the Newton-Raphson algorithm which gives us the results shown in @tbl-NR. The numeric optimization solution is $\hat\theta_{ML} = 0.2$ which equals the analytic solution. 


|$m$ 	|	$\hat\theta_{(m)}$	|	$h_{{(m)}}=\frac{-\ell_n'(\hat\theta_{(m)})}{\ell_n''(\hat\theta_{(m)})}$ |$\ell_n'(\hat\theta_{(m)})\gtrless \varepsilon$	 |  
|-------------------|-------------------|:--------------------------:|---------------------------------------------:|
|$0$| $0.40$| $-2.4\cdot 10^{-1}$| ${\color{red}-4.2 > \varepsilon}$                        |
|$1$| $0.16$| $\phantom{-}3.3\cdot 10^{-2}$ |${\color{red}\phantom{-}1.5 > \varepsilon}$              |
|$2$| $0.19$| $\phantom{-}6.6\cdot 10^{-3}$ |${\color{red}\phantom{-}2.2\cdot 10^{-1} > \varepsilon}$ |
|$3$| $0.19$| $\phantom{-}1.7\cdot 10^{-4}$ |${\color{red}\phantom{-}5.4\cdot 10^{-3} > \varepsilon}$ |
|$4$| $0.19$| $\phantom{-}1.1\cdot 10^{-7}$ |${\color{red}\phantom{-}3.5\cdot 10^{-6} > \varepsilon}$ |
|$5$| $0.20$| $\phantom{-}4.8\cdot 10^{-14}$|${\color{darkgreen}\phantom{-}1.5\cdot 10^{-12} < \varepsilon}$|

: Result of applying the Newton Raphson optimization algorithm to our coin flipping example for given data with $N_{H,obs}=1,$ sample size $n=5,$ starting value $\theta_{(0)}=0.4,$ and convergence criterion $\varepsilon=10^{-10}.$ {#tbl-NR}





## Linear Regression under Normality {#sec-LinRegNorm}

Now, let's return to the linear regression model 
$$
Y_i=X_i^T\beta_0 + \varepsilon_i,\quad  i=1,\dots,n,
$${#eq-LinMod}
where $Y_i\in\mathbb{R}$ denotes the response (or "dependent") variable, 
$$
\beta_0\in\mathbb{R}^K
$$ 
denotes the vector of unknown slope parameters, and 
$$
X_i:=(\underbrace{X_{i1}}_{=1},X_{i2},\ldots,X_{ip})^T\in\mathbb{R}^K
$$
denotes the vector of predictor variables, where the (i.i.d.) random sample  
$$
(Y_1,X_1), (Y_2,X_2), \dots, (Y_n,X_n)
$$
follows a **random design with homoskedastic errors** (see @def-RandomDesign). 

::: {.callout-note appearance="minimal"} 
## 
::: {#def-RandomDesign}

## Random Design (Regression Analysis) 
<br>

A **random desgin** in regression analysis is given by the following setup: 

Let 
$$
(Y_1,X_1), (Y_2,X_2), \dots, (Y_n,X_n)
$$
or equivalently 
$$
(X_1,\varepsilon_1), (X_2,\varepsilon_2), \dots, (X_n,\varepsilon_n)
$$
denote a (i.i.d.) random sample with 
$\mathbb{E}(\varepsilon_i|X_i)=0$, intertable $(K\times K)$ matrix $\mathbb{E}(X_iX_i^T)=\Sigma_{X^TX}$, $i=1,\dots,n,$ 
and with either

* **homoskedastic** errors: $0<\mathbb{E}(\varepsilon_i^2|X_i)=\sigma^2_0<\infty$

or

* **heteroskedastic** errors: $0<\mathbb{E}(\varepsilon_i^2|X_i)=\sigma^2_0(X_i)<\infty$, for a strictly positive and finite variance function $\sigma^2_0(\cdot).$
:::
:::

For the following, it is convenient to write @eq-LinMod using matrix notation
$$
\begin{eqnarray*}
  \underset{(n\times 1)}{Y}&=&\underset{(n\times K)}{X}\underset{(K\times 1)}{\beta_0} + \underset{(n\times 1)}{\varepsilon},
\end{eqnarray*}
$$
where 
$$
\begin{equation*}
Y=\left(\begin{matrix}Y_1\\ \vdots\\Y_n\end{matrix}\right),\quad X=\left(\begin{matrix}X_{11}&\dots&X_{1K}\\\vdots&\ddots&\vdots\\ X_{n1}&\dots&X_{nK}\\\end{matrix}\right),\quad\text{and}\quad \varepsilon=\left(\begin{matrix}\varepsilon_1\\ \vdots\\ \varepsilon_n\end{matrix}\right).
\end{equation*}
$$


Under **normally distributed and homoskedastic** error terms, $\varepsilon_i,$ we have that 
$$
\begin{align}
\underset{(n\times 1)}{\varepsilon} &\sim \mathcal{N}_n\left(0, \sigma_0^2I_n\right)\\[2ex]
\Rightarrow\quad 
(Y-X\beta_0)|X &\sim \mathcal{N}_n\left(0, \sigma^2_0I_n\right).
\end{align}
$$
That is, for each $i=1,\dots,n,$ we have that
$$
\begin{align}
(Y_i-X_i^T\beta_0)|X_i &\sim \mathcal{N}\left(0, \sigma^2_0\right)\\[2ex]
\Rightarrow\quad 
Y_i|X_i &\sim \mathcal{N}\left(X_i^T\beta_0, \sigma^2_0\right)
\end{align}
$${#eq-OLSnormAss}

<!-- We could also choose another distributional assumption for $\varepsilon,$ but the classical ML estimation theory requires us to assumed the correct error distribution. Luckily, the quasi maximum likelihood theory of @White1982 shows that false distributional assumptions are typically not problematic. -->

<!-- ::: {.callout-note}
The requirement to make a (correct) distributional assumption is much more restrictive than requirements for analyzing the OLS estimator under standard large sample inference. However, taking into account specific distributional assumptions allows us to consider also more complicated non-linear regression models such as, for instance, logistic regression. 
:::pe -->

<!-- \begin{itemize} -->
<!-- \item The $\varepsilon$'s are jointly normally distributed. -->
<!-- \item The $\varepsilon$'s are independent of one another. -->
<!-- \item The $\varepsilon$'s are identically distributed, i.e. homoskedastic. -->
<!-- \end{itemize} -->

Under @eq-OLSnormAss, we have
$$
f(Y_i|X_i;\beta_0^T,\sigma_0^2)=
\frac{1}{(2\pi\sigma^2)^{1/2}}\exp\left(-\frac{(Y_i-X_i^T\beta_0)^2}{2\sigma_0^2}\right),
$$
where 
$$
\theta_0=(\beta_0^T,\sigma_0^2)^T\in\mathbb{R}^K\times\mathbb{R}_{>0}
$$ 
denotes the $((K+1)\times 1)$ dimensional unknown parameter vector. 

This allows us to setup the likelihood function, 
$$
\begin{align*}
\mathcal{L}_n(\beta^T,\sigma^2)
& =\prod_{i=1}^n f(Y_i|X_i;\beta^T,\sigma^2)\\[2ex]
& =\prod_{i=1}^n \frac{1}{(2\pi\sigma^2)^{1/2}}\exp\left(-\frac{(Y_i-X_i^T\beta)^2}{2\sigma^2}\right)\\[2ex]
& =\left(\frac{1}{(2\pi\sigma^2)^{1/2}}\right)^{n}\exp\left(-\frac{\sum_{i=1}^n (Y_i-X_i^T\beta)^2}{2\sigma^2}\right)\\[2ex]
%& =\dfrac{1}{(2\pi \sigma^2)^{n/2}} \exp\left(-\frac{\varepsilon'\varepsilon}{2\sigma^2}\right)\\[2ex]
& =(2\pi)^{-n/2} \cdot (\sigma^2)^{-n/2}\cdot  \exp\left(-\frac{(Y-X\beta)^T(Y-X\beta)}{2\sigma^2}\right),\\[2ex]
\end{align*}
$$
<!-- The multivariate density for $\varepsilon=(\varepsilon_1,\dots,\varepsilon_n)^T$ is then
$$
\begin{equation*}
f(\varepsilon)=\dfrac{1}{(2\pi \sigma^2)^{n/2}} \exp\left(-\frac{\varepsilon'\varepsilon}{2\sigma^2}\right).
\end{equation*}
$$ -->
<!-- Noting that $\varepsilon=Y-X\beta$, we get the  -->
and the log-likelihood function,
$$
\begin{align*}
\ell_n(\beta^T,\sigma^2)& =-\dfrac{n}{2} \ln(2\pi) - \dfrac{n}{2}\ln(\sigma^2) - \dfrac{1}{2 \sigma^2}(Y-X\beta)^T(Y-X\beta).
\end{align*}
$$
<!-- with $K+1$ unknown parameters: 

* $\beta=(\beta_1,\dots,\beta_K)^T\in\mathbb{R}^K$ and 
* $\sigma^2\in\mathbb{R}_{>0}.$ -->

Taking first derivatives gives 
$$
\begin{align*}
\underset{(K\times 1)}{\dfrac{\partial \ell_n}{\partial \beta}(\beta^T,\sigma^2)}    
&= - \dfrac{1}{\sigma^2}(-X^TY + X^TX\beta)\\[2ex]
\underset{(1\times 1)}{\dfrac{\partial \ell_n}{\partial \sigma^2}(\beta^T,\sigma^2)} 
%&= -\dfrac{n}{2\sigma^2}+ \dfrac{1}{2\sigma^4}(Y-X\beta)^T(Y-X\beta)
&=-\frac{n}{2 \sigma^{2}}+\left[\frac{1}{2}(Y-X\beta)^T(Y-X\beta)\right]\frac{1}{\left(\sigma^{2}\right)^{2}}\\
%&=\frac{1}{2 \sigma^{2}}\left[\frac{1}{\sigma^{2}} (Y-X\beta)^T(Y-X\beta)-n\right]
\end{align*}
$$
Putting the above derivative functions into one column vector yields the $((K+1)\times 1)$-dimensional **gradient** called **score function** in ML-theory:
$$
\nabla\ell_n(\theta^T)=
\left(\begin{matrix}
\dfrac{\partial \ell_n}{\partial \beta}(\beta^T,\sigma^2)\\
\dfrac{\partial \ell_n}{\partial \sigma^2}(\beta^T,\sigma^2)
\end{matrix}\right)
$${#eq-LinRegScoreFun}


::: {.callout-note appearance="minimal"} 
## 
::: {#def-ScoreFunction}

# Score Function

More generally, let $\ell_n(\theta)$ denote the log-likelihood function evaluated at a $p$-dimensional parameter vector $\theta=(\theta_1,\dots,\theta_p)^T.$ 

Then the $(p\times 1)$ dimensional gradient 
$$
\nabla\ell_n(\theta^T)=\left(\begin{matrix}
  \dfrac{\partial \ell_n}{\partial \theta_1}(\theta^T)\\ \vdots\\ 
  \dfrac{\partial \ell_n}{\partial \theta_p}(\theta^T)
  \end{matrix}
  \right)
$$ 
is called the **score-function**.  
:::
:::


::: {.callout-note} 
The score function is **random**, since it depends on the random sample. For a given set of observed data, we compute one realization of the score function.

At the **true parameter** vector $\theta_0\in\mathbb{R}^p,$ the score function satisfies 
$$
\mathbb{E}\left(\dfrac{\partial \ell_n}{\partial \theta_j}(\theta_0')\right)=0
$$ 
for all $j=1,\dots,p;$ i.e. 
$$
\mathbb{E}\left(\nabla\ell_n(\theta^T)\right)=\left(\begin{matrix}
  \mathbb{E}\left(\dfrac{\partial \ell_n}{\partial \theta_1}(\theta^T)\right)\\ \vdots\\ 
  \mathbb{E}\left(\dfrac{\partial \ell_n}{\partial \theta_p}(\theta^T)\right)
  \end{matrix}
  \right) = \underset{(p\times 1)}{0}
$$ 
We prove this below in @sec-MLAsymp.
:::

Setting the score function in @eq-LinRegScoreFun equal to zero yields a system of $K+1$ equations with $K+1$ unknowns, which identifies the ML-estimators, 
$$
\begin{align*}
&\nabla\ell_n(\hat\theta^T_{ML})
=
\left(\begin{matrix}
\dfrac{\partial \ell_n}{\partial \beta}(\hat\beta^T_{ML},s_{ML}^2)\\
\dfrac{\partial \ell_n}{\partial \sigma^2}(\hat\beta^T_{ML},s_{ML}^2),
\end{matrix}\right)=\\[2ex]
&=
\left(\begin{matrix}
- \dfrac{1}{s_{ML}^2}(-X^TY + X^TX\hat\beta_{ML})\\
-\frac{n}{2 s_{ML}^2}+\left[\frac{1}{2}(Y-X\hat\beta_{ML})^T(Y-X\hat\beta_{ML})\right]\frac{1}{\left(s_{ML}^2\right)^{2}}
\end{matrix}\right)
\overset{!}{=} \underset{((K+1)\times 1)}{0}
\end{align*}
$$
and which we can solve for the maximum likelihood estimators $\hat\beta_{ML}$ and $s^2_{ML}.$

Solving for $\hat\beta_{ML}:$
$$
\begin{align*}
%& \dfrac{\partial \ell_n}{\partial \beta}(\hat\beta_{ML}',s^2_{ML}) \overset{!}{=}0\\[2ex]\Leftrightarrow\quad
& - \dfrac{1}{s_{ML}^2}(-X^TY + X^TX\hat\beta_{ML})  \overset{!}{=}0\\[2ex]
\Rightarrow\quad & \hat\beta_{ML}=(X^TX)^{-1}X^TY\\[2ex]
\end{align*}
$$
Solving for $s^2_{ML}:$
$$
\begin{align*}
%& \dfrac{\partial \ell_n}{\partial \sigma^2}(\hat\beta_{ML}',s^2_{ML}) \overset{!}{=}0\\[2ex]\Leftrightarrow\quad
&-\frac{n}{2 s_{ML}^2}+\left[\frac{1}{2}(Y-X\hat\beta_{ML})^T(Y-X\hat\beta_{ML})\right]\frac{1}{\left(s_{ML}^2\right)^{2}}  \overset{!}{=}0\ \\[2ex]
\Rightarrow\quad  &
s_{ML}^2 =\dfrac{1}{n}(Y-X\hat\beta_{ML})^T(Y-X\hat\beta_{ML})\\[2ex]
&\phantom{s_{ML}^2}=\dfrac{1}{n}\sum_i^n \hat\varepsilon_i^2,
\end{align*}
$$
where 
$\hat\varepsilon_i = Y_i - X_i^T\hat{\beta}_{ML}.$

**Observations:**

* $\hat\beta_{ML}$ equals the OLS estimator $\hat\beta=(X^TX)^{-1}X^TY.$  </br>
Since the ML estimator $\hat\beta_{ML}$ is here equivalent to the OLS estimator we can use the classic inference machinery ($t$-test, $F$-test, confidence intervals) developed for the classic OLS estimator (see your econometrics class). 

* $s_{ML}^2$ differs from the unbiased variance estimator $s_{UB}^2=\frac{1}{n-K}\hat{\varepsilon}_i^2.$


### Variance of ML-Estimators $\hat\beta_{ML}$ and $s^2_{ML}$ {#sec-varMLE}

::: {.callout-tip}
# Computing the Asymptotic Variance
To compute the **asymptotic variance** of the ML-estimators $\hat\beta_{ML}$ and $s^2_{ML},$ we need to 

1. compute the Hessian matrix (i.e. all second partial derivatives) of $\ell_n,$  
2. take the expectation of this Hessian matrix and multiply it by $-1/n$, which gives us the **Fisher Information matrix**. 
3. Inverting the Fisher information matrix give the **asymptotic variance** expression. 
:::

Let's do this preliminary work in the following:

* Partial second derivatives with respect to $\beta:$
$$
\begin{align*}
\underset{(K\times 1)}{\dfrac{\partial \ell_n}{\partial \beta}(\beta^T,\sigma^2)}    
&= - \dfrac{1}{\sigma^2}(-X^TY + X^TX\beta)\\[2ex]
\Rightarrow\quad 
\underset{(K\times K)}{\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta^T}(\beta^T,\sigma^2)}
&= - \dfrac{1}{\sigma^2}(X^TX)
\end{align*}
$$
$$
\begin{align*}
\Rightarrow\quad 
&-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta^T}(\beta^T,\sigma^2)\right)\\[2ex]
&=  -\frac{1}{n}\cdot \left(-\dfrac{1}{\sigma^2} \mathbb{E}(X^TX)\right)\\[2ex]
&=  -\frac{1}{n}\cdot \left(-\dfrac{n}{\sigma^2} \Sigma_{X^TX}\right)\\[2ex]
&=  \dfrac{1}{\sigma^2} \Sigma_{X^TX},
\end{align*}
$$
where  
$$
\mathbb{E}\left(X^TX\right)
=\mathbb{E}\left(\sum_{i=1}^nX_iX_i^T\right)
=n\underbrace{\mathbb{E}\left(X_iX_i^T\right)}_{=:\Sigma_{X^TX}} = n\Sigma_{X^TX}.
$$ 

* Second derivative with respect to $\sigma^2:$
$$
\begin{align*}
\underset{(1\times 1)}{\dfrac{\partial \ell_n}{\partial \sigma^2}(\beta^T,\sigma^2)} 
&=-\frac{n}{2 \sigma^{2}}+\frac{1}{2}\frac{(Y-X\beta)^T(Y-X\beta)}{\left(\sigma^{2}\right)^{2}}\\[2ex]
\Rightarrow\quad\underset{(1\times 1)}{\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta^T,\sigma^2)}
&=\frac{n}{2 \left(\sigma^{2}\right)^2}-\dfrac{(Y-X\beta)^T(Y-X\beta)}{\left(\sigma^{2}\right)^{3}} \\[2ex]
&=\frac{n}{2\sigma^{4}}-\frac{\sum_{i=1}^n\varepsilon_i^2}{\sigma^{6}} \\[2ex]
\end{align*}
$$
$$
\begin{align*}
\Rightarrow\quad 
&-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta^T,\sigma^2)\right)\\[2ex]
&=-\frac{1}{n}\cdot \left(\frac{n}{2\sigma^{4}}-\frac{\mathbb{E}\left(\sum_{i=1}^n\varepsilon_i^2\right)}{\sigma^{6}} \right)\\[2ex]
&=-\frac{1}{n}\cdot \left(\frac{n}{2\sigma^{4}}-\frac{n\sigma^2}{\sigma^{6}}\right)\\[2ex]
&=\left(-\frac{1}{2\sigma^{4}}+\frac{1}{\sigma^{4}}\right)\\[2ex]
&=\frac{1}{2\sigma^{4}}\\[2ex]
\end{align*}
$$

* First derivative with respect to $\beta,$ second derivative with respect to $\sigma^2:$
$$
\begin{align*}
\underset{(K\times 1)}{\dfrac{\partial \ell_n}{\partial \beta}(\beta^T,\sigma^2)}    
&= - \dfrac{1}{\sigma^2}(-X^TY + X^TX\beta)\\[2ex]
&= \dfrac{1}{\sigma^2}(X^T)(Y - X\beta)\\[2ex]
&= \dfrac{1}{\sigma^2}X^T\varepsilon\\[2ex]
\end{align*}
$$

$$
\begin{align*}
\Rightarrow\quad 
\underset{(K\times 1)}{\dfrac{\partial^2 \ell_n}{\partial \beta \partial \sigma^2}(\beta^T,\sigma^2)}
=   \left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta^T}(\beta^T,\sigma^2)\right)^T
& = -\frac{X^T\varepsilon}{\sigma^4}\\
\end{align*}
$$
$$
\begin{align*}
\Rightarrow\quad 
&-\frac{1}{n}\cdot  \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \sigma^2}(\beta^T,\sigma^2)\right)\\[2ex]
&=-\frac{1}{n}\cdot\left(\mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta^T,\sigma^2)\right)\right)^T\\[2ex]
&=\frac{1}{n}\cdot\frac{\mathbb{E}(X^T\varepsilon)}{\sigma^4}\\[2ex]
&=\frac{1}{n}\cdot\frac{\mathbb{E}(\mathbb{E}(X^T\varepsilon|X))}{\sigma^4}\\[2ex]
&=\frac{1}{n}\cdot\frac{\mathbb{E}(X^T\mathbb{E}(\varepsilon|X))}{\sigma^4}\\[2ex]
&=\frac{1}{n}\cdot 0=0,
\end{align*}
$$
since $\mathbb{E}(\varepsilon|X)=0$ is an $(n\times 1)$ zero vector. 

Collecting the above results, allows us to write down the expression for $(-1/n)$ times the expectation of the **Hessian matrix** of $\ell_n$ which yields the **Fisher Information (Matrix):**

$$
\begin{align*}
&\mathcal{I}(\theta) :=\; -\frac{1}{n}\cdot\mathbb{E}\left(H_{\ell_n}(\beta^T,\sigma^2)\right)\\[2ex] 
&=
-\frac{1}{n}\cdot \mathbb{E}
\left[\begin{array}{cc}
\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta^T}(\beta^T,\sigma^2)\right) & 
\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \sigma^2 }(\beta^T,\sigma^2)\right)\\
\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta^T}(\beta^T,\sigma^2)\right) & 
\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta^T,\sigma^2) \right)
\end{array}\right]\\[2ex]
&=\left[\begin{array}{cc}
\underset{(K\times K)}{\frac{1}{\sigma^2}\Sigma_{X^TX}}
& 
\underset{(K\times 1)}{0}\\
\underset{(1\times K)}{0} & 
\underset{(1\times 1)}{\frac{1}{2\sigma^4}}
\end{array}\right]
\end{align*}
$$


::: {.callout-note appearance="minimal"} 
## 
::: {#def-FisherInformMat}

# Fisher Information Matrix
The matrix 
$$
\mathcal{I}(\theta) := -\frac{1}{n}\cdot\mathbb{E}\left(H_{\ell_n}(\theta)\right)
$$
is called **Fisher Information Matrix**.
:::
:::

#### **Asymptotic Variance and Fisher Information Matrix** {-}

The asymptotic variance of the MLE 
$$
\hat{\theta}_{ML}=\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)
$$ 
is given by the **inverse of the Fisher information matrix** evaluated at the true parameter values $\beta_0$ and $\sigma^2_0.$
$$
\begin{align*}
&AVar\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right) 
=\lim_{n\to\infty} n Var\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)\\[2ex]
&=\left(\mathcal{I}(\beta^T_0,\sigma^2_0)\right)^{-1}\\[2ex]
&=\left(-\frac{1}{n}\cdot\mathbb{E}\left(H_{\ell_n}(\beta^T_0,\sigma^2_0)\right)\right)^{-1}\\[2ex] 
&=
\left[\begin{array}{cc}
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta^T}(\beta^T_0,\sigma^2_0)\right) & 
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \sigma^2}(\beta^T_0,\sigma^2_0)\right)\\
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta^T}(\beta^T_0,\sigma^2_0)\right) & 
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta^T_0,\sigma^2_0) \right)
\end{array}\right]^{-1}\\[2ex]
&=\left[\begin{array}{cc}
\underset{(K\times K)}{\frac{1}{\sigma^2_0}\Sigma_{X^TX}}
& 
\underset{(K\times 1)}{0}\\
\underset{(1\times K)}{0} & 
\underset{(1\times 1)}{\frac{1}{2\sigma^4_0}}
\end{array}\right]^{-1}\\[2ex]
&=\left[\begin{array}{cc}
\underset{(K\times K)}{\sigma^2_0\Sigma_{X^TX}^{-1}}
& 
\underset{(K\times 1)}{0}\\
\underset{(1\times K)}{0} & 
\underset{(1\times 1)}{2\sigma^4_0}
\end{array}\right]
\end{align*}
$$

<!-- where $\mathcal{I}(\beta^T,\sigma^2)$ is called the **Fisher information matrix**. 

From our above derivations we know that
$$
\begin{align*}
&\mathcal{I}\left(\beta, \sigma^2\right)\\[2ex]
&=
\left[\begin{array}{cc}
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta^T}(\beta^T,\sigma^2)\right) & 
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta^T,\sigma^2)\right)\\
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta^T,\sigma^2)\right) & 
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta^T,\sigma^2) \right)
\end{array}\right]\\[2ex]
% &=
% \left[\begin{array}{cc}
% \frac{1}{\sigma^2}E(X^TX) & 0 \\
% 0 & \frac{n}{2\sigma^4}
% \end{array}\right]\\[2ex]
&=
\left[\begin{array}{cc}
\dfrac{n}{\sigma^2}\Sigma_{X^TX} & 0 \\[2ex]
0 & \ \dfrac{n}{2\sigma^4}
\end{array}\right],
\end{align*}
$$ -->

That is, 
$$
\begin{align*}
AVar\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right) 
&=\lim_{n\to\infty} n Var\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)\\[2ex] 
&=
\left[\begin{array}{cc}
\sigma^2_0\Sigma_{X^TX}^{-1} & 0 \\[2ex]
0 & \ 2\sigma^4_0
\end{array}\right].
\end{align*}
$${#eq-FIMVar}


<!-- While the upper left element of the Fisher information matrix is easily seen, the derivation of the lower right element is rather tedious and thus omitted.
[^1]: See [https://www.statlect.com/fundamentals-of-statistics/linear-regression-maximum-likelihood](https://www.statlect.com/fundamentals-of-statistics/linear-regression-maximum-likelihood) for more details. -->

<!-- Taking the inverse of the Fisher information matrix $\mathcal{I}\left(\beta, \sigma^2\right)$ gives the variance-covariance matrix of the vector of estimators $(\hat\beta_{ML}, s_{ML}^2)$
$$
\begin{align*}
Var\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right) 
& \approx \left(\mathcal{I}\left(\beta, \sigma^2\right)\right)^{-1}\\[2ex]
& =
\left[\begin{array}{cc}
\dfrac{\sigma^2}{n}\Sigma_{X^TX}^{-1} & 0 \\
0 & \ \dfrac{2\sigma^4}{n}
\end{array}\right],
\end{align*}
$${#eq-FIMVar}
where the approximation error becomes small as $n\to\infty.$ That is, 
$$
n Var\left(\hat\beta_{ML}\right) \to \sigma^2\Sigma_{X^TX}^{-1}\quad\text{as}\quad n\to\infty,
$$
and
$$
n Var\left(s_{ML}^2\right) \to 2\sigma^4\quad\text{as}\quad n\to\infty.
$$


Given this result, it is easy to see that 
$$
Var(\hat\beta_{ML}) \to 0\quad\text{and}\quad Var(s_{ML}^2) \to 0
$$ 
as $n\to\infty$. -->

Of course, the variance expressions in @eq-FIMVar contain unknown quantities and thus are not directly usable in practice. However, we can plug in estimates of the unknown quantities; namely 
$$
s_{ML}^2                         \quad\text{for}\quad \sigma^2_0
$$
and
$$
S_{X^TX}^{-1}=\left(\frac{1}{n}\sum_{i=1}^nX_i X_i^T\right)^{-1} \quad \text{for}\quad \Sigma_{X^TX}^{-1}.
$$

This leads to estimators of the asymptotic variances of $\hat{\beta}_{ML}$ and $s_{ML}^2:$
$$
\begin{align}
\widehat{AVar}(\hat{\beta}_{ML})
&=s_{ML}^2 S_{X^TX}^{-1}\\[2ex]
&=s_{ML}^2 \left(\frac{1}{n}\sum_{i=1}^nX_i X_i^T\right)^{-1}\\[2ex]
\widehat{AVar}(s^2_{ML})
&=2\left(s_{ML}^2\right)^2
\end{align}
$$
and thus to estimators of the variances of $\hat{\beta}_{ML}$ and $s_{ML}^2:$ 
$$
\begin{align}
\widehat{Var}(\hat{\beta}_{ML})
=\frac{1}{n}\widehat{AVar}(\hat{\beta}_{ML})
&=s_{ML}^2 \frac{1}{n}S_{X^TX}^{-1}\\[2ex]
&=s_{ML}^2 \left(\sum_{i=1}^nX_i X_i^T\right)^{-1}\\[2ex]
\widehat{Var}(s^2_{ML})
=\frac{1}{n}\widehat{AVar}(s^2_{ML})
&=\frac{1}{n}2\left(s_{ML}^2\right)^2.
\end{align}
$$

<!-- ### Consistency of $\hat\beta_{ML}$ and $s_{ML}^2$ {#sec-MLconsistency}

If $E[\varepsilon|X]=0$ (strict exogeneity, follows from the random design (@def-RandomFixedDesign) assumption), then the bias of $\hat\beta$ is zero since $E[\hat\beta_{ML}]=\beta$
$$
\begin{align*}
E[\hat\beta_{ML}]&=E[(X^TX)^{-1}X^T(X\beta + \varepsilon)] \\
                 &=E[E[(X^TX)^{-1}X^T(X\beta + \varepsilon)|X]] \\
                 &=E[E[(X^TX)^{-1}X^TX\beta|X]] + E[E[(X^TX)^{-1}X^T\varepsilon|X]] \\
                 &=E[E[\beta|X]] + E[(X^TX)^{-1}X^TE[\varepsilon|X]] \\
                 &=        \beta + E[(X^TX)^{-1}X^TE[\varepsilon|X]] \\
                 &=        \beta  \\
\Leftrightarrow E[\hat\beta_{ML}]-\beta&=\operatorname{Bias}(\hat\beta_{ML})=0
\end{align*}
$$
Of course, from this it also follows that the squared bias is equal to zero 
$$
\text{Bias}^2(\hat\beta_{ML})=0.
$$  
This implies that the mean square error (MSE) of the ML estimator $\hat\beta_{ML}$ equals the variance of the ML estimator $\hat\beta_{ML}$: 
$$
\operatorname{MSE}(\hat\beta_{ML})=\underbrace{E[(\hat\beta_{ML}-\beta)^2]=Var(\hat\beta_{ML})}_{\text{MSE}(\hat\beta_{ML})=Var(\hat\beta_{ML})\text{ since }\hat\beta_{ML}\text{ is unbiased.}}\to 0\quad\text{as}\quad n\to\infty.
$$
Since convergence in mean square implies convergence in probability, we have established that the ML-estimator $\hat\beta_{ML}$ is a (weakly) consistent estimator of $\beta$
$$
\hat\beta_{ML}\to_p \beta\quad\text{as}\quad n\to\infty.
$$

Moreover, one can also show that $s_{ML}^2$ is a biased but *asymptotically unbiased* estimator, that is 
$$
\left(\operatorname{Bias}(s^2_{ML})\right)^2\to 0
$$ 
as $n\to\infty$. Together with the result that $Var(s^2_{ML})\to 0$ as $n\to\infty$ we have that
$$
\begin{align*}
\operatorname{MSE}(s^2_{ML})&=E[(s^2_{ML}-\sigma^2)^2]\\
&=\operatorname{Bias}^2(s^2_{ML})+Var(s^2_{ML})\to 0\quad\text{as}\quad n\to\infty.
\end{align*}
$$
Again, since convergence in mean square implies convergence in probability, we have established that the ML-estimator $s^2_{ML}$ is a (weakly) consistent estimator of $\sigma^2$
$$
s^2_{ML}\to_p \sigma^2\quad\text{as}\quad n\to\infty.
$$ -->


<!-- In practice, however, one usually works with the unbiased (and consistent) alternative $s_{UB}^2=\dfrac{1}{n-K}\sum_{i=1}^n \hat{\varepsilon}_i^2$ even though one can show that $\operatorname{MSE}(s^2_{ML})<\operatorname{MSE}(\hat\sigma^2_{UB})$ for sufficiently large $n$. -->


### Asymptotic Distribution and Single Parameter Testing

It follows from asymptotic maximum likelihood theory (see @sec-MLAsymp) that the probability distribution of the vector of parameter estimates
$$
\begin{pmatrix}
\hat\beta_{ML,n}\\
\hat s_{ML,n}^2
\end{pmatrix}
$$
can be approximated (for largish $n$) by the following multivariate normal distribution 
$$
\begin{align*}
\sqrt{n}\left(
\hat\theta_{ML,n}-\theta_0
\right)
&\to_d
\mathcal{N}_{p}\left(
0,
\left(\mathcal{I}(\beta^T_0,\sigma^2_0)\right)^{-1}
\right)\\[2ex]
\sqrt{n}\left(
\begin{pmatrix}
\hat\beta_{ML}\\
\hat s_{ML}^2
\end{pmatrix}-
\begin{pmatrix}
\beta_0\\
\sigma_0^2
\end{pmatrix}\right)
&\to_d
\mathcal{N}_{K+1}\left(\begin{pmatrix}
0\\
0
\end{pmatrix},
\begin{pmatrix}
\sigma_0^2\Sigma_{X^TX} & 0\\
0 & 2\sigma_0^4
\end{pmatrix}
\right)\\[2ex]
\Leftrightarrow
\begin{pmatrix}
\hat\beta_{ML}\\
\hat s_{ML}^2
\end{pmatrix}
&\overset{a}{\sim}
\mathcal{N}_{K+1}\left(
\begin{pmatrix}
\beta_0\\
\sigma_0^2
\end{pmatrix},
\begin{pmatrix}
\frac{1}{n}\sigma_0^2\Sigma_{X^TX} & 0\\
0 & \frac{1}{n}2\sigma_0^4
\end{pmatrix}
\right)
\end{align*}
$$ 

Plugging-in estimators for the unknown variance components, i.e.

* $s_{ML}^2 \frac{1}{n}S_{X^TX}^{-1}\quad$ for $\quad\sigma_0^2 \frac{1}{n} \Sigma_{X^TX}$

and 

* $\frac{1}{n}2\left(s_{ML}^2\right)^2\quad$ for $\quad\frac{1}{n}2\sigma_0^4$

allows using this asymptotic normality result in testing. 


#### **Single Parameter Testing** {-}

For instance, we can do a single-parameter test for 

$$
\begin{align*}
H_0\colon \beta_{0,k} & =   \beta_{0,k}^{(0)}\\
H_1\colon \beta_{0,k} &\neq \beta_{0,k}^{(0)},\\
\end{align*}
$$
where $\beta_{0,k}^{(0)}$ denotes the null-hypothetical value (typically, $\beta_{0,k}^{(0)}=0$), 
using the Wald statistic
$$
T_{\beta_{0,k},n}=\frac{\hat\beta_{ML,k} - 0}{\sqrt{s_{ML}^2 \frac{1}{n}\left[S_{X^TX}^{-1}\right]_{(k,k)}}}\overset{H_0}{\to_d}
\mathcal{N}(0,1)\quad \text{as}\quad n\to\infty.
$$

Likewise, for 
$$
\begin{align*}
H_0\colon \sigma_0^2 & = (\sigma_0^{(0)})^2\\
H_1\colon \sigma_0^2 &\neq (\sigma_0^{(0)})^2,\\
\end{align*}
$$
where $(\sigma_0^{(0)})^2$ denotes the null-hypothetical value, 
using the Wald statistic
$$
T_{\sigma_0,n}=\frac{s_{ML}^2 - (\sigma_0^{(0)})^2}{\sqrt{\frac{1}{n}2\left(s_{ML}^2\right)^2}}\overset{H_0}{\to_d}
\mathcal{N}(0,1)\quad \text{as}\quad n\to\infty.
$$

**Testing:** 
We reject $H_0,$ if the observed value $T_{n,obs},$ computed from the observed realization of the random sample, is in absolute values larger than the $(1-\alpha/2)$-qantile of the standard normal distribution; i.e. if 
$$
|T_{n,obs}| > z_{1-\alpha/2},
$$ 
where $\alpha\in(0,1)$ denotes the chosen significance level, such as $\alpha=0.01.$ 

## Asymptotic Theory of Maximum-Likelihood Estimators {#sec-MLAsymp}

In the following, we consider the asymptotic distribution of ML-estimators. 

We only consider the simplest situation: Assume a random sample  
$$
X_1,\dots,X_n\overset{\text{i.i.d.}}{\sim}X,
$$ 
where $X\in\mathbb{R}$ is a univariate random variable with density function 
$$f(x;\theta_0),
$$ 
where the true (unknown, univariate) parameter $\theta_0\in\Theta$ is an interior point of a compact parameter interval 
$$\Theta=[\theta_l,\theta_u]\subset\mathbb{R}.
$$ 
**Note:** $\theta_0$ is an "interior point" of $\Theta$ if $\theta_l<\theta_0<\theta_u.$

Moreover, we consider the following setup.

* Likelihood function:
$$
\mathcal{L}_n(\theta)=\prod_{i=1}^n f(X_i;\theta)
$$
* Log-likelihood function:
$$
\ell_n(\theta)=\ln\mathcal{L}(\theta)=\sum_{i=1}^n \ln f(X_i;\theta)
$$
* Maximum-likelihood estimator $\hat{\theta}_n$
$$
\hat{\theta}_n=\arg\max_{\theta\in\Theta}\ell_n(\theta)
$$
* The maximum-likelihood estimator $\hat{\theta}_n$ maximizes $\ell_n(\theta)$ uniquely such that 
$$
\ell_n'(\hat\theta_n)=0\quad\text{and}\quad\ell_n''(\hat\theta_n)<0
$$
* It is assumed that the partial derivatives 
$$
\frac{\partial}{\partial\theta}f(x;\theta)\quad\text{and}\quad \frac{\partial^2}{\partial\theta^2}f(x;\theta)
$$
exist and that these partial derivatives can be passed under the integral such that
$$
\begin{align*}
\frac{\partial}{\partial\theta}\int f(x;\theta)dx 
&=\int\frac{\partial}{\partial\theta} f(x;\theta)dx\\
\frac{\partial^2}{\partial\theta^2}\int f(x;\theta)dx 
&=\int\frac{\partial^2}{\partial\theta^2} f(x;\theta)dx
\end{align*}
$$
for all $\theta\in\Theta.$

::: {.callout-note}
# Example
An **example** that fits into the above setup is the density of the exponential distribution 
$$
f(x;\theta)=\left\{
    \begin{matrix}
    \theta\exp(- \theta x)& \text{for }x\geq 0\\
    0                     & \text{for }x < 0\\
    \end{matrix}\right.
$$
with unknown rate parameter $\theta>0.$ 


Or, more generally, the densities of the one-parameter, $\theta\in\Theta\subset\mathbb{R},$ exponential family  
$$
f(x;\theta)=h(x)\exp(\eta(\theta) T(x) - B(\theta))
$$
where $h:$ $\mathbb{R}\to\mathbb{R},$ $T:$ $\mathbb{R}\to\mathbb{R},$ $\eta:$ $\Theta\to\mathbb{R},$ and $B:$ $\Theta\to\mathbb{R}.$
:::


The derivation of the asymptotic distribution of the ML estimator, $\hat\theta_n,$ relies on a Taylor expansion of the derivative of the log-likelihood function, 
$$
\ell_n'(\cdot),
$$ 
around $\theta_0$ (see @eq-MVT). To derive this expression, we use the mean value theorem (@thm-MVT).


::: {.callout-note appearance="minimal"} 
## 
::: {#thm-MVT}

# Mean Value Theorem 

*Let $f$ be continuous over the closed interval $[a,b]$ and differentiable over the open interval $(a,b).$ Then, there exists at least one point $c\in(a,b)$ such that*
$$
f'(c) = \frac{f(b)-f(a)}{b-a}
$$
*or equivalently*
$$
f(b)=f(a) + f'(c)(b-a). 
$$
:::
:::


By the Mean Value Theorem (@thm-MVT), we know that 
$$
\ell_n'(\hat{\theta}_n)=\ell_n'(\theta_0)+\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0)
$${#eq-MVT}
for some $\psi_n$ between $\hat{\theta}_n$ and $\theta_0;$ i.e.

* $\psi_n\in(\theta_0,\hat{\theta}_n)\quad$ if $\quad\theta_0<\hat{\theta}_n$
* $\psi_n\in(\hat{\theta}_n,\theta_0)\quad$ if $\quad\hat{\theta}_n<\theta_0$

> Note: @eq-MVT is simply the first-order version of the mean-value form of Taylor's theorem (@thm-TaylorThm).

Since $\hat{\theta}_n$ maximizes the log-Likelihood function it follows that 
$$
\ell_n'(\hat{\theta}_n)=0.
$$ 
Together with @eq-MVT, this implies that 
$$
\overbrace{\ell_n'(\hat{\theta}_n)}^{=0}=\ell_n'(\theta_0)+\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0)
$$
$$
\Rightarrow\quad \ell_n'(\theta_0)=-\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0).
$${#eq-ml2}
Now, note that necessarily
$$
\int_{-\infty}^{\infty} f(x;\theta)dx=1
$$ 
for *all possible values* of $\theta\in\Theta,$ since $f$ is a density function. 

Therefore,
$$
\begin{align*}
\frac{\partial}{\partial \theta}\underbrace{\int_{-\infty}^{\infty} f(x;\theta)dx}_{=1}&=\frac{\partial}{\partial \theta}1 = 0,\quad\text{for all}\quad\theta\in\Theta.
\end{align*}
$$
Using that we can here pass the partial derivative under the integral sign, we thus have 
$$
\int_{-\infty}^{\infty} \frac{\partial}{\partial \theta}f(x;\theta)dx
=\frac{\partial}{\partial \theta}\int_{-\infty}^{\infty} f(x;\theta)dx
=0 
$${#eq-zero1} 
for all $\theta\in\Theta.$ 

Likewise, 
$$
\begin{align*}
\frac{\partial^2}{\partial \theta^2}\underbrace{\int_{-\infty}^{\infty} f(x;\theta)dx}_{=1}&=\frac{\partial^2}{\partial \theta^2}1 = 0,\quad\text{for all}\quad\theta\in\Theta.
\end{align*}
$$ 
Using again that we can here pass the partial derivative under the integral sign, we thus have
$$
\int_{-\infty}^{\infty} \frac{\partial^2}{\partial \theta^2}f(x;\theta)dx
=\frac{\partial^2}{\partial \theta^2}\int_{-\infty}^{\infty} f(x;\theta)dx
=0
$${#eq-zero2} 
for all $\theta\in\Theta.$

Using @eq-zero1 and @eq-zero2, we can now show that the average 
$$
\frac{1}{n}\ell_n'(\theta_0)=\frac{1}{n}\underbrace{\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)}_{\ell_n'(\theta_0)}
$$ 
is **asymptotically normal**. This is done in the following by checking the three conditions for applying the Lindeberg-Lévy central limit theorem. 


Firstly, the average 
$$
\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)
$$ 
is taken over i.i.d. random variables: 
$$
\frac{\partial}{\partial \theta} \ln f(X_1;\theta_0),\dots,\frac{\partial}{\partial \theta} \ln f(X_n;\theta_0)\overset{\text{i.i.d.}}{\sim}\frac{\partial}{\partial \theta} \ln f(X;\theta_0)
$$ 

Secondly, for the mean one gets:
$$
\begin{align*}
\mathbb{E}\left(\frac{1}{n}\ell_n'(\theta_0)\right)
&=\mathbb{E}\left(\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)\right)\\[2ex]
&=\frac{n}{n}\mathbb{E}\left(\frac{\partial}{\partial \theta} \ln f(X;\theta_0)\right)\quad[\text{i.i.d.}]\\[2ex]
&=\mathbb{E}\left(\frac{\frac{\partial}{\partial \theta}f(X;\theta_0)}{f(X;\theta_0)}\right)\quad[\text{chain rule}]\\[2ex]
&=\int_{-\infty}^{\infty} \frac{\frac{\partial}{\partial \theta}  f(x;\theta_0)}
{f(x;\theta_0)}f(x;\theta_0)dx\quad[\text{Def. of $\mathbb{E}$}]\\[2ex] 
&=\int_{-\infty}^{\infty} \frac{\partial}{\partial \theta}  f(x;\theta_0)dx\\[2ex] 
&=0,
\end{align*}
$${#eq-Mean}
where the last step follows from @eq-zero1. 

Thirdly, for the variance one gets:
$$
\begin{align*}
Var\left(\frac{1}{n}\ell_n'(\theta_0)\right)
&=Var\left(\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)\right)\\
&=\frac{1}{n}Var\left(\frac{\partial}{\partial \theta} \ln f(X;\theta_0)\right)\quad[\text{i.i.d.}]\\
&=\frac{1}{n}Var\left(\frac{\frac{\partial}{\partial \theta} f(X;\theta_0)}{f(X;\theta)}\right)\quad[\text{chain rule}]\\
&=\frac{1}{n}\mathbb{E}\left(\left(\frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}{f(X;\theta_0)}\right)^2\right)\\
&=\frac{1}{n}\mathcal{I}(\theta_0),
\end{align*}
$$
where the simplification of the variance expression to a second moment expression follows from @eq-Mean. </br>

> We can write the last expression using the Fisher Information $\mathcal{I}(\theta_0)-\frac{1}{n}\mathbb{E}(\ell_n''(\theta_0))$ since below in @eq-FisherInfoDeriv we'll see that 
$$
\begin{align*}
\mathbb{E}\left(\left(\frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}{f(X;\theta_0)}\right)^2\right)
& =-\frac{1}{n}\mathbb{E}(\ell_n''(\theta_0)) = \mathcal{I}(\theta_0).
\end{align*}
$$  

<!-- , where we found that 
$$
\mathbb{E}\left(\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)\right)=0.
$$  
-->


Thus, we can apply the **Lindeberg-Lévy central limit theorem** from which it follows that
$$
\frac{\frac{1}{n}\ell_n'(\theta_0)-\overbrace{\mathbb{E}\left(\frac{1}{n}\ell_n'(\theta_0)\right)}^{=0}}{\sqrt{\frac{1}{n}\mathcal{I}(\theta_0)} } = \frac{\ell_n'(\theta_0)}{\sqrt{n\mathcal{I}(\theta_0)} } \to_d \mathcal{N}(0,1)
$$
as $n\to\infty.$

By our mean value expression in @eq-ml2 
$$
\ell_n'(\theta_0)=-\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0)
$$ 
we thus have
$$
\frac{-\ell_n''(\psi_n)}{\sqrt{n \mathcal{I}(\theta_0)}}\left(\hat{\theta}_n-\theta_0\right) \to_d \mathcal{N}(0,1),
$$
which is equivalent to 
$$
\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)\;\sqrt{n}\left(\hat{\theta}_n-\theta_0\right) \to_d \mathcal{N}(0,1).
$${#eq-MLNorm}
The $\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)$-part in @eq-MLNorm is our object of interest. 

The further analysis requires us to study the asymptotic behavior of  
$$
-\frac{1}{n}\ell_n''(\psi_n)
$$ 
which will help us to understand the behavior of $\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)$ in @eq-MLNorm.

::: {.callout-important}
Before we consider $-\frac{1}{n}\ell_n''(\psi_n),$ we begin with studying the mean and the variance of the simpler statistic 
$$
-\frac{1}{n}\ell_n''(\theta_0)
$$
with $\psi_n$ replaced by $\theta_0.$
::: 

First, the mean of $-\frac{1}{n}\ell_n''(\theta_0):$
$$
\begin{align*}
-\frac{1}{n}\ell_n''(\theta_0)
&=-\frac{1}{n}\sum_{i=1}^n\frac{\partial^2}{\partial \theta\partial \theta}\ln f(X_i;\theta_0)\\[2ex]
&=-\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta}\left(\frac{\partial}{\partial\theta}\ln f(X_i;\theta_0)\right)\\[2ex]
&=-\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta}\left(\frac{\frac{\partial}{\partial \theta}f(X_i;\theta_0)}{f(X_i;\theta_0)}\right)\quad[\text{chain rule}]
\end{align*}
$$
Applying the quotient rule yields
$$
\begin{align*}
-\frac{1}{n}\ell_n''(\theta_0)
&=-\frac{1}{n}\sum_{i=1}^n
\left(
\frac{\left(\frac{\partial^2}{\partial \theta\partial \theta}f(X_i;\theta_0)\right) f(X_i;\theta_0)-\frac{\partial}{\partial\theta}f(X_i;\theta_0)\frac{\partial}{\partial\theta} f(X_i;\theta_0)}{\left(f(X_i;\theta_0)\right)^2}\right)\\[2ex]
&=-\frac{1}{n}\sum_{i=1}^n
\left(
\frac{\frac{\partial^2}{\partial \theta^2}  f(X_i;\theta_0)}
{f(X_i;\theta_0)}-\left( \frac{\frac{\partial}{\partial \theta}  f(X_i;\theta_0)}
{f(X_i;\theta_0)}\right)^2  
\right).
\end{align*}
$$
Taking the mean of $-\frac{1}{n}\ell_n''(\theta_0)$ yields that 
$$
\begin{align*}
\mathbb{E}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)
&=\frac{n}{n}\mathbb{E}\left(-\frac{\frac{\partial^2}{\partial \theta^2}  f(X;\theta_0)}
{f(X;\theta_0)}+\left( \frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}
{f(X;\theta_0)}\right)^2\right)\quad[\text{i.i.d.}]\\[2ex]
&=\frac{n}{n}\mathbb{E}\left(-\frac{\frac{\partial^2}{\partial \theta^2}  f(X;\theta_0)}{f(X;\theta_0)}\right)+\mathbb{E}\left(\left( \frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}
{f(X;\theta_0)}\right)^2\right)
\end{align*}
$$
From @eq-Mean, we know that 
$\mathbb{E}\left(-\frac{\frac{\partial^2}{\partial \theta^2}  f(X;\theta_0)}{f(X;\theta_0)}\right)=0$
thus
$$
\begin{align*}
\underbrace{\mathbb{E}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)}_{=\mathcal{I}(\theta_0)}
&=0 + \mathbb{E}\left(\left( \frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}{f(X;\theta_0)}\right)^2\right)
\end{align*}
$$
$$
\Rightarrow \qquad 
\mathcal{I}(\theta_0) = 
\mathbb{E}\left(\left( \frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}{f(X;\theta_0)}\right)^2\right)
$${#eq-FisherInfoDeriv}

This means that 
$$
-\frac{1}{n}\ell_n''(\theta_0)
$$ 
is an **unbiased estimator** of the Fisher information $\mathcal{I}(\theta_0).$

Moreover, @eq-FisherInfoDeriv provides an alternative expression for the Fisher information $\mathcal{I}(\theta_0).$

::: {.callout-note}
# Multivariate Settings
For multivariate ($p$-dimensional) parameters $\theta_0,$ the Fisher information $\mathcal{I}(\theta_0)=(-1)\cdot \mathbb{E}\left(\ell_n''(\theta_0)\right)$  becomes the ($p\times p$) Fisher information matrix (see @sec-varMLE).
:::

Second, the variance of variance of $-\frac{1}{n}\ell_n''(\theta_0):$
$$
\begin{align*}
Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)
&=Var\left(-\frac{1}{n}\sum_{i=1}^n\frac{\partial^2}{\partial \theta\partial \theta}\ln f(X_i;\theta_0)\right)\\[2ex]
&=\frac{n}{n^2}
\underbrace{Var\left(\frac{\partial^2}{\partial \theta \partial \theta}  \ln f(X;\theta_0)\right)}_{=\texttt{constant}}\\[2ex]
&=\frac{1}{n}\texttt{constant},
\end{align*}
$$
which implies that
$$
Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\to 0\quad\text{as}\quad n\to\infty.
$$

With these mean and variance results for $-\frac{1}{n}\ell_n''(\theta_0),$ we can write down the Mean Squared Error (MSE) of the estimator $-\frac{1}{n}\ell_n''(\theta_0)$ of $\mathcal{I}(\theta_0):$
$$
\begin{align*}
&\operatorname{MSE}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\\[2ex]
&=
\mathbb{E}\left(\left(-\frac{1}{n}\ell_n''(\theta_0) -\mathcal{I}(\theta_0)\right)^2\right)\\[2ex]
&=\underbrace{\left(\operatorname{Bias}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\right)^2}_{=0}+Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\\[3ex]
&=Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\to 0\quad\text{as}\quad n\to\infty.
\end{align*}
$$

That is, the estimator $-\frac{1}{n}\ell_n''(\theta_0)$ is a **mean square consistent** estimator, i.e.
$$
-\frac{1}{n}\ell_n''(\theta_0)\to_{m.s.} \mathcal{I}(\theta_0)\quad \hbox{as}\quad n\to\infty,
$$
which implies that $\frac{1}{n}\ell_n''(\theta_0)$ is also a **(weakly) consistent** estimator, i.e. 
$$
-\frac{1}{n}\ell_n''(\theta_0)\to_p \mathcal{I}(\theta_0)\quad \hbox{as}\quad n\to\infty, 
$$
since mean square convergence implies convergence in probability.


::: {.callout-important}
🤔 Remember, we wanted to study $-\frac{1}{n}\ell_n''(\psi_n)$ in @eq-MLNorm **not** $-\frac{1}{n}\ell_n''(\theta_0).$ Studying $-\frac{1}{n}\ell_n''(\theta_0)$ was only the simpler thing to do. 

Luckily, we are actually close now. 
:::

Next, we use that ML estimators $\hat\theta_n$ are (weakly) **consistent**, i.e., 
$$
\hat\theta_n\to_p\theta_0\quad\text{as}\quad n\to\infty.
$$

> **Example:** Our results in @sec-LinRegNorm imply, for instance, that the ML estimator $\hat{\beta}_n$ is consistent for $\beta.$  


Since $\psi_n$ is a **mean value** between $\theta_0$ and $\hat{\theta}_n$ (@eq-MVT), consistency of $\hat{\theta}_n$ implies that 
$$
\psi_n\to_p\theta_0\quad\text{as}\quad n\to\infty.
$$

Therefore, we have by the **continuous mapping theorem** that 
$$
\begin{align}
-\frac{1}{n}\ell_n''(\psi_n) & \to_p \phantom{-}\mathcal{I}(\theta_0)\quad \hbox{ as }\quad n\to\infty\\[2ex]
\Rightarrow\qquad 
\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)&\to_p \sqrt{\mathcal{I}(\theta_0)} \quad \hbox{ as }\quad n\to\infty.
\end{align}
$$

Now, using **Slutsky's theorem**, we can connect the above consistency result with the asymptotic normality result in @eq-MLNorm such that 
$$
\begin{align*}
\underbrace{\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)}_{\to_p \sqrt{\mathcal{I}(\theta_0)} }\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\to_d\mathcal{N}(0,1)
\end{align*}
$$
or equivalently
$$
\begin{align*}
\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\to_d \mathcal{N}\left(0,\frac{1}{\mathcal{I}(\theta_0)}\right),
\end{align*}
$${#eq-AsymNormMLE}
where $1/\mathcal{I}(\theta_0)$ is the **asymptotic variance** of the ML estimator $\hat{\theta}_n$ and equals the inverse of the (here scalar valued) Fisher information 
$$
\mathcal{I}(\theta_0)=-\frac{1}{n}\mathbb{E}(\ell_n''(\theta_0)).
$$ 

@eq-AsymNormMLE is the asymptotic normality result we aimed for. 

::: {.callout-note} 
# Multivariate Settings
The above arguments can easily be generalized to multivariate ($p$-dimensional) parameter vectors $\theta\in\mathbb{R}^p$. In this case, $\mathcal{I}(\theta_0)$ becomes a $p\times p$ matrix, and 
$$
\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\to_d \mathcal{N}_p\left(0, \mathcal{I}(\theta_0)^{-1}\right),
$$
where $\mathcal{I}(\theta_0)=-\frac{1}{n}\mathbb{E}\left(H_{\ell_n}(\theta_0)\right)$ is the $(p\times p)$ Fisher information matrix with $H_{\ell_n}(\theta_0)$ denoting the Hesse matrix of $\ell_n(\cdot)$ evaluated at $\theta_0.$ 
:::

::: {.callout-tip}
# ML-Theory and Machine learning

The Fisher information is used in machine learning techniques such as elastic weight consolidation, which reduces catastrophic forgetting in artificial neural networks (@Kirkpatrick_2017).

Fisher information can be used as an alternative to the Hessian of the loss function in second-order gradient descent network training (@Martens_2020).
:::



## Cramér–Rao Lower Bound

Harald Cramér and Calyampudi Radhakrishna Rao showed that for any unbiased estimator $\hat\theta$, its asymptotic variance-covariance matrix cannot be smaller than 
$$
\mathcal{I}^{-1}(\theta_0),
$$ 
where $\mathcal{I}(\theta_0)$ is the **Fisher information matrix** 
$$
\mathcal{I}(\theta) = -\frac{1}{n}\mathbb{E}\left(H_{\ell_n}(\theta)\right)
$$
evaluated at the true parameter value $\theta_0.$ 

Thus, maximum likelihood estimators attain the Cramer-Rao lower bound and will therefore be asymptotically efficient. 



## Invariance Property of the ML-Estimator 

Suppose that a distribution has the parameter $\theta_0,$ but we are interested in finding an estimator of a function of $\theta_0,$ say 
$$
\eta_0=\tau(\theta_0).
$$
The invariance property of ML-estimators says that if $\hat{\theta}_n$ is the ML-estimator of $\theta_0,$ then $\tau(\hat{\theta}_n)$ is the ML-estimator of $\eta_0=\tau(\theta_0).$

### One-to-One Functions {-}

Let the function 
$$
\eta = \tau(\theta) 
$$ 
be a **one-to-one** function. That is, for each value of $\theta$ there is a unique value of $\eta$ and vice versa. 


Important property of one-to-one functions: A one-to-one function $\eta = \tau(\theta)$ possesses a well-defined **inverse** 
$$
\theta=\tau^{-1}(\eta).
$$ 


::: {.callout-note}
# Example: 
For instance, the functions
$$
\begin{align*}
\eta = \tau(\theta) & = \theta + 3 
\quad\Rightarrow\quad \theta = \tau^{-1}(\eta) = \eta -3 \\[2ex]
\eta = \tau(\theta) & = \theta/5  
\quad\Rightarrow\quad \theta = \tau^{-1}(\eta) = 5 \eta
\end{align*}
$$
are one-to-one functions. However, for instance, the functions 
$$
\begin{align*}
\tau(\theta) & = \sin(\theta)\\[2ex]
\tau(\theta) & = \theta^2  
\end{align*}
$$
are **not** one-to-one functions. 
:::

In this one-to-one case, it is easily seen that it makes no difference whether we maximize the likelihood function as a function of $\theta$ or as a function of $\eta = \tau(\theta)$---in each case we get the same answer.

The likelihood function of $\tau(\theta),$ written as a function of $\eta,$ is given by
$$
\begin{align*}
\mathcal{L}^*(\eta) 
&= \prod_{i=1}^n f\big(X_i;\tau^{-1}(\eta)\big)
= \mathcal{L}\big(\;\overbrace{\tau^{-1}(\eta)}^{=\theta}\;\big) 
\end{align*}
$$
and 
$$
\begin{align*}
  \sup_{\eta}  \mathcal{L}^*(\eta) 
= \sup_{\eta}  \mathcal{L}\big(\;\overbrace{\tau^{-1}(\eta)}^{=\theta}\;\big)
= \sup_{\theta}\mathcal{L}\big(\theta\big). 
\end{align*}
$$
Thus, the maximum of $\mathcal{L}^*(\eta)$ is attained at 
$$
\eta=\tau(\theta)=\tau(\hat\theta_n),
$$ 
showing that the ML-estimator of $\tau(\theta_0)$ is $\tau(\hat\theta_n).$ 


<!-- 
Moreover, using the multivariate version (for $\tau(\theta_0)\in\mathcal{K}$) of the first-order Taylor expansion of $\tau$ around $\theta_0,$ one can show that
$$
\sqrt{n}\left(\tau(\hat\theta_n) - \tau(\theta_0)\right)\sim\mathcal{N}\left(0,\left(\mathcal{I}(\theta_0)\right)^{-1}\right) \nabla\ell_n(\theta^T)
$$ 
-->


::: {.callout-note}
# More general (not one-to-one) functions
In many cases, however, this simply version of the invariance of ML-estimators is not useful since many functions of interest are not one-to-one. 

Luckily, the invariance property of the ML-estimator also holds for functions that are not one-to-one; see Chapter 7 in @CasellaBerger_StatInf_2001. 
:::



## Exercises {-}

#### Exercise 1. {-} 

Program the Newton-Raphson algorithm for a numerical computation of the ML estimate $\hat\theta$ of the parameter $\theta=P(\text{Coin}=\texttt{HEAD})$ in our coin toss example of this chapter. Replicate the results shown in @tbl-NR.  

#### Exercise 2. {-} 

Assume an i.i.d. random sample $X_1,\dots,X_n$ from an exponential distribution, i.e. the underlying density of $X_i$ is given by 
$$
f(x;\theta_0)=
\left\{\begin{array}{ll}\theta_0\exp(-\theta_0 x),&x\geq 0\\0,&x<0\end{array}\right.
$$ 
with $\theta_0>0,$ where
$$
\mu:=\mathbb{E}(X_i)=\frac{1}{\theta_0}
$$ 
and
$$
Var(X_i)=\frac{1}{\theta_0^2}.
$$ 

(a) What is the log-likelihood function for the i.i.d. random sample $X_1,\dots,X_n$?
(b) Derive the maximum likelihood (ML) estimator $\hat\theta_n$ of $\theta_0.$
(c) From maximum likelihood theory we know that 
$$
\sqrt{n}(\hat\theta_n-\theta_0)\to_d \mathcal{N}\left(0,\frac{1}{\mathcal{I}(\theta_0)}\right).
$$
Derive the expression for the Fisher information $\mathcal{I}(\theta_0).$ Use the Fisher information to give the *explicit* formula for the asymptotic distribution of $\hat\theta_n$.



#### Exercise 3. {-} 

<!-- From All of Statistics p 151 -->

Let $X_1,\dots,X_n\overset{\text{i.i.d.}}{\sim}X$ with $X\sim\mathcal{Unif}(0,\theta_0).$

(a) What is the likelihood function? 

(b) What is the maximum likelihood estimator of $\theta_0$? 


#### Exercise 4. {-}


Let $X_1,\dots,X_n\overset{\text{i.i.d.}}{\sim}X$ with $X\sim\mathcal{Poisson}(\lambda_0).$ That is $X\sim f$ with density function 
$$
f(x;\lambda_0) = \frac{\lambda_0^x \exp(-\lambda_0)}{x!}.
$$
 
(a) Find the maximum likelihood estimator, $\hat{\lambda},$ of $\lambda_0.$

(b) Let $0<\lambda_0\leq 4.$ Find the maximum likelihood estimator, $\hat{P}(X=4),$ of $P(X=4).$


#### Exercise 5. {-}

Show that the Newton-Raphson algorithm converges; i.e. that 
$$
|e_{(m)}|\to 0 \quad\text{as}\quad m \to\infty. 
$$ 
under the setup outlined in @sec-ConvNR. 

**Tip:** Use the first-order Taylor expansion of $\ell'(\theta_{root})$ around $\theta_{(m)}$ with **explicit reminder** term $R$ given by 
$$
\begin{align*}
\overset{\theta_{(m)}+(\theta_{root}-\theta_{(m)})}{\ell'\big(\;\overbrace{\theta_{root}}\;\big)} 
& = \ell'(\theta_{(m)}) + \ell''(\theta_{(m)})(\theta_{root}-\theta_{(m)}) + R,
\end{align*}
$$
where 
$$
R=\frac{1}{2}\ell'''(\xi_{(m)})(\theta_{root}-\theta_{(m)})^2
$$
for a mean-value $\xi_{(m)}$ between $\theta_{(m)}$ and $\theta_{root}$. This is called the Lagrange form of the Taylor-Series reminder term and follows from the Mean-Value Theorem @thm-MVT.   




<!-- 
## Solutions {-} 

#### Solutions of Exercise 1. {-} 

Below I use the same data (one H, four T) that was used to produce the results in @tbl-NR of our script. However, you can produce new data by setting another seed-value

```{r}
theta_true <- 0.2    # unknown true theta value
n          <-  5     # sample size

set.seed(1)

# simulate data: n many (unfair) coin tosses
x <- sample(x       = c(0,1), 
            size    = n, 
            replace = TRUE, 
            prob    = c(1-theta_true, theta_true)) 

## number of heads (i.e., the number of "1"s in x)
N_H <- sum(x)

## First derivative of the log-likelihood function
Lp_fct   <- function(theta, N_H = N_H, n = n){
    (N_H/theta) - (n - N_H)/(1 - theta)    
}
## Second derivative of the log-likelihood function
Lpp_fct   <- function(theta, N_H = N_H, n = n){
    - (N_H/theta^2) - (n - N_H)/(1 - theta)^2    
}

t     <- 1e-10   # convergence criterion
check <- TRUE    # check object to stop the while-loop
i     <- 0       # count iterations

## Initializations 
theta  <- 0.4     # starting value theta_{(0)}
h_step <- NULL    # empty value 
Lp     <- Lp_fct( theta, N_H=N_H, n=n)
Lpp    <- Lpp_fct(theta, N_H=N_H, n=n)

while(check){
    i         <- i + 1
    ##
    h_step_new <- -1 * (Lp_fct(theta[i], N_H=N_H, n=n) / Lpp_fct(theta[i], N_H=N_H, n=n))    
    h_step     <- c(h_step, h_step_new)
    theta_new  <- theta[i] + h_step_new
    Lp_new     <- Lp_fct( theta_new, N_H=N_H, n=n)
    Lpp_new    <- Lpp_fct(theta_new, N_H=N_H, n=n)
    ##
    theta      <- c(theta, theta_new) 
    Lp         <- c(Lp,    Lp_new) 
    Lpp        <- c(Lpp,   Lpp_new) 
    ##
    if( abs(Lp_fct(theta_new, N_H=N_H, n=n)) < t ){
      check <- FALSE
    }
}

results           <- cbind(1:length(theta)-1, theta, -Lp/Lpp, Lp)
colnames(results) <- c("m", "theta_m", "h_m", "Lp(theta_m)")
results
```


#### Solutions of Exercise 2. {-} 

##### (a) Log-Likelihood Function {-}

The log-likelihood function is given by
$$
\begin{align*}
\ell_n(\theta)
&=\sum_{i=1}^n \ln (\theta\exp(-\theta X_i))\\
&=\sum_{i=1}^n (\ln \theta -\theta X_i)\\
&=n \ln \theta -\sum_{i=1}^n \theta X_i
\end{align*}
$$

##### (b) ML-Estimator  {-}

The ML estimator is defined as $\hat{\theta}_{n}=\arg\max_{\theta}\ell(\theta)$. Deriving the ML estimator $\hat\theta_n$:
$$
\begin{align*}
\ell_n'(\theta)&=n\frac{1}{\theta} - \sum_{i=1}^n X_i\\
\ell_n'(\hat\theta_n)=0\quad \Leftrightarrow &\quad 0=n\frac{1}{\hat\theta_n} - \sum_{i=1}^n X_i\\
\Leftrightarrow &\quad n\frac{1}{\hat\theta_n} = \sum_{i=1}^n X_i\\
\Leftrightarrow &\quad \hat\theta_n = \frac{1}{\frac{1}{n}\sum_{i=1}^n X_i}= \frac{1}{\bar{X}_n}
\end{align*}
$$

##### (b) Fisher Information {-}

The Fisher information is given by 
$$
\mathcal{I}(\theta_0)=-\frac{1}{n}\mathbb{E}(\ell''(\theta_0)).
$$ 
The second derivative of $\ell_n(\theta)$ evaluated at $\theta_0$ is given by
$$
\ell''_n(\theta)=-n\frac{1}{\theta^2_0}.
$$
Thus,
$$
\begin{align*}
\mathcal{I}(\theta_0)
&=-\frac{1}{n}\mathbb{E}(\ell''_n(\theta_0))\\[2ex]
&=-\frac{1}{n}\left(-n\frac{1}{\theta^2_0}\right)\\[2ex]
&=\frac{1}{\theta^2_0}.
\end{align*}
$$
Therefore, the asymptotic distribution of $\hat\theta_n$ is 
$$
\begin{align*}
\sqrt{n}(\hat\theta_n-\theta)&\to_d \mathcal{N}\left(0,\theta^2_0\right),
\end{align*}
$$
$n\to\infty.$

Since we do not know the asymptotic variance $\theta_0^2,$ we need to plug-in a consistent estimator; namely,
$$
\hat{\theta}_n^2 = \left(\frac{1}{\bar{X}_n}\right)^2 \approx \theta^2_0.
$$
This allows us to use the following Normal approximation to construct statistical hypothesis tests and confidence intervals, etc:
$$
\begin{align*}
\hat\theta_n&\overset{a}{\sim}\mathcal{N}\left(\theta,\frac{\hat{\theta}_n^2}{n}\right)
\end{align*}
$$
This approximation is good for largish sample sizes (roughly $n\geq 30$). 

Note: The above asymptotic normality result coincides with the result obtained by the delta-method.

#### Solutions of Exercise 3. {-}

##### (a) Likelihood Function {-}

Recall that the density function of $\mathcal{Unif}(0,\theta)$ is
$$
f(x;\theta_0)
=\left\{
\begin{array}{ll}
\frac{1}{\theta} & 0\leq x\leq \theta_0\\
0                & \text{otherwise}\\
\end{array}
\right.
$$
Thus, the likelihood function is
$$
\mathcal{L}_n(\theta) = \prod_{i=1}^n f(X_i;\theta).
$$
**Note:** If any $\theta<X_i,$ we have that 
$$
\mathcal{L}_n(\theta)=0.
$$ 
Putting it differently, let 
$$
X_{(n)}=\max\{X_1,\dots,X_n\}
$$ 
denote the $n$th order-statistic, then
$$
\mathcal{L}_n(\theta)=0\quad\text{for all}\quad \theta<X_{(n)}.
$$ 

However, for all values of $\theta$ with $\theta \geq X_{(n)}$ we have that 
$$
f(X_i;\theta)=\frac{1}{\theta}\quad\textbf{for all}\quad i=1,\dots,n.
$$
Thus, for all values of $\theta$ with $\theta \geq X_{(n)},$
$$
\mathcal{L}_n(\theta)=\left(\frac{1}{\theta}\right)^n.
$$ 

Summing up, 
$$
\mathcal{L}_n(\theta)
=\left\{
\begin{array}{ll}
\left(\frac{1}{\theta}\right)^n & \theta \geq  X_{(n)}\\
0                               & \theta < X_{(n)}\\
\end{array}
\right.
$${#eq-MLMaxestim}


#### (b) Maximum Likelihood Estimator of $\theta_0$ {-}

$\mathcal{L}_n(\theta)$ is strictly decreasing over the interval $[X_{(n)},\infty);$ see @fig-MLMaxestim.

```{r}
#| label: fig-MLMaxestim
#| fig-cap: Graph of the likelihood function $\mathcal{L}_n(\theta)$ given in @eq-MLMaxestim.
n          <- 20   # sample size
X_max      <- 0.25

theta_vec  <- seq(from = 0, 
                  to   = X_max * 1.5, 
                  len  = 100) 
likelihood_fun <- function(theta, X_max, n){ 
    likelihood                <- 1/(theta^n)
    likelihood[theta < X_max] <- 0 
    return(likelihood) 
}

likelihood_vec <- likelihood_fun(theta = theta_vec,
                                 X_max = X_max, 
                                 n     = n)

plot(y = likelihood_vec, 
     x = theta_vec, 
     type = "l", 
     xlab = expression(theta),
     ylab = "Likelihood", 
     main = "")            
axis(1, at = X_max, labels = expression(X[(n)]))                  
```

Thus, the maximum likelihood estimator of $\theta_0$ is 
$$
\begin{align}
\hat{\theta}_{ML} 
& =\arg\max_{\theta>0}\mathcal{L}_n(\theta)\\
& = X_{(n)}.
\end{align}
$$


#### Solutions of Exercise 4. {-}


##### (a) Finding the Maximum Likelihood Estimator of $\lambda_0$ {-}

$$
\begin{align}
\mathcal{L}_n(\lambda) 
& = \prod_{i=1}^n f(X_i;\lambda)\\[2ex]
& = \prod_{i=1}^n \frac{\lambda^{X_i} \exp(-\lambda)}{X_i!} \\[2ex]
& = \frac{\lambda^{\sum_{i=1}^n X_i}  \exp(-n \lambda)}{\prod_{i=1}^n (X_i!)} \\[4ex]
\ell(\lambda) 
&= \left(\sum_{i=1}^n X_i\right) \ln(\lambda) -n\lambda\cdot 1 - \sum_{i=1}^n \ln(X_i!)
\end{align}
$$

$$
\begin{align}
\ell'_n(\lambda) 
&= \frac{\left(\sum_{i=1}^n X_i\right)}{\lambda}  - n 
\end{align}
$$

$$
\begin{align}
\ell''_n(\lambda) 
&= -\frac{\left(\sum_{i=1}^n X_i\right)}{\lambda^2} < 0  
\end{align}
$$
since by the properties of the Poisson distribution $X_1,\dots,X_n>0$ and $\lambda>0.$

Thus the maximum likelihood estimator of $\lambda_0$ is given by
$$
\begin{align}
&\frac{\left(\sum_{i=1}^n X_i\right)}{\hat\lambda_n}  - n \overset{!}{=} 0\\[2ex]
\Rightarrow & \hat \lambda_n = \frac{1}{n}\sum_{i=1}^n X_i.
\end{align}
$$


##### (b) Finding the Maximum Likelihood Estimator of $P(X=4)$ {-}

$$
\begin{align}
P(X=4) = \frac{\lambda_0^4 \exp(-\lambda_0)}{4!}
\end{align}
$$

Thus $P(X=4)$ is a function of $\lambda$
$$
\begin{align}
P(X=4)\equiv P(X=4|\lambda) = \frac{\lambda^4 \exp(-\lambda)}{4!} = \tau(\lambda)
\end{align}
$$


```{r}
lambda_vec <- seq(from = .0001, to = 15, len = 100)
g_vec      <- (lambda_vec^4 * exp(-1*lambda_vec))/( factorial(4) )

plot(x = lambda_vec, y = g_vec, 
     type = "l", xlab=expression(lambda), ylab=expression(tau(lambda)))
abline(v = 4)
axis(1, at = 4)
```

(For $0<\lambda\leq 4,$ $g(\lambda)$ is even a one-to-one mapping.) 

By the invariance property of the maximum likelihood estimator (which also applies to functions $\tau$ that are not one-to-one) we thus have
$$
\begin{align}
\hat{P}(X=4)\equiv \hat{P}(X=4|\hat{\lambda}_n) = \frac{\hat{\lambda}^4_n \exp(-\hat{\lambda}_n)}{4!}
\end{align}
$$
with $\hat{\lambda}_n=\frac{1}{n}\sum_{i=1}^n X_i.$


#### Solutions of Exercise 5. {-}

Setup of @sec-ConvNR: 

Let $\theta_{root}$ denote the root of $\ell_n';$ i.e. 
$$
\ell_n'(\theta_{root})=0.
$$ 
Let 
$$
\begin{align*}
e_{(0)}&=\theta_{root}-\theta_{(0)}\\[2ex]
e_{(m)}&=\theta_{root}-\theta_{(m)}
\end{align*}
$$
denote the start-value error and the $m$th step error, respectively.

Let 
$$
I=[\theta_{root}-|e_{(0)}|, \theta_{root}+|e_{(0)}|]
$$
denote the start-value neighborhood around $\theta_{root}.$   

Let $\ell_n'$ be "well behaved" over $I;$ such that 

* $\ell_n''(\theta)\neq 0$ for all $\theta\in I$  and 
* $\ell_n'''(\theta)$ is finite and continuous for all $\theta\in I.$ 

Let $\theta_{(0)}$ be "close enough;" i.e. let

* $M|e_{(0)}|<1,$ 

where 
$$
M=\frac{1}{2}\left(\sup_{\theta\in I}|\ell_n'''(\theta)|\right)\left(\sup_{\theta\in I}\frac{1}{|\ell_n''(\theta)|}\right)\geq 0,
$$ 

In the following, we show that the Newton-Raphson algorithm converges under this setup. 


By the second-order Taylor expansion of $\ell'(\theta_{root})$ around $\theta_{(m)}$ with the mean-value form of the remainder term, we have that 
$$
\begin{align*}
\overset{\theta_{(m)}+(\theta_{root}-\theta_{(m)})}{\ell'\big(\;\overbrace{\theta_{root}}\;\big)} 
& = \ell'(\theta_{(m)}) + 
    \ell''(\theta_{(m)})(\theta_{root}-\theta_{(m)}) + 
    \frac{1}{2}\ell'''(\xi)(\theta_{root}-\theta_{(m)})^2
\end{align*}
$$
for some real-valued number $\xi_{(m)}$ between $\theta_{root}$ and $\theta_{(m)}.$ 


Since $\ell'(\theta_{root})=0,$ we have that
$$
\begin{align*}
0
& = \ell'(\theta_{(m)}) + \ell''(\theta_{(m)})(\theta_{root}-\theta_{(m)}) + \frac{1}{2}\ell'''(\xi_{(m)})(\theta_{root}-\theta_{(m)})^2
\end{align*}
$$
Some rearrangments lead
$$
\begin{align*}
\ell'(\theta_{(m)}) + \ell''(\theta_{(m)})(\theta_{root}-\theta_{(m)}) 
& = -\frac{1}{2}\ell'''(\xi_{(m)})(\theta_{root}-\theta_{(m)})^2\\[2ex]
{\color{blue}\frac{\ell'(\theta_{(m)})}{\ell''(\theta_{(m)})}} + (\theta_{root}-\theta_{(m)}) 
&= \frac{-\ell'''(\xi_{(m)})}{2\ell''(\theta_{(m)})}(\theta_{root}-\theta_{(m)})^2\qquad[\text{dividing by}\;\ell''(\theta_{(m)})]\\[2ex]
\end{align*}
$$
Using the update steps of the alrorithm
$$
\theta_{(m+1)} = \theta_{(m)} - \frac{\ell'(\theta_{(m)})}{\ell''(\theta_{(m)})}
\quad\Leftrightarrow\quad 
\theta_{(m)} - \theta_{(m+1)}  = {\color{blue}\frac{\ell'(\theta_{(m)})}{\ell''(\theta_{(m)})}}
$$
yields
$$
\begin{align*}
\theta_{(m)} - \theta_{(m+1)} + (\theta_{root}-\theta_{(m)}) 
&= \frac{-\ell'''(\xi_{(m)})}{2\ell''(\theta_{(m)})}(\theta_{root}-\theta_{(m)})^2\\[2ex]
\Leftrightarrow\quad
\theta_{root} - \theta_{(m+1)}  
&= \frac{-\ell'''(\xi_{(m)})}{2\ell''(\theta_{(m)})}(\theta_{root}-\theta_{(m)})^2\\[2ex]
\Leftrightarrow\quad
e_{(m+1)}  
&= \frac{-\ell'''(\xi_{(m)})}{2\ell''(\theta_{(m)})}(e_{(m)})^2
\end{align*}
$$
Taking absolute values, since we are not interested in the sign of the approximation errors, yields
$$
\begin{align*}
|e_{(m+1)}|  
&= \frac{1}{2} \; |\ell'''(\xi_{(m)})|\;\frac{1}{|\ell''(\theta_{(m)})|}(e_{(m)})^2
\end{align*}
$$
Considering the worst case within $I,$ leads to the following inequality
$$
\begin{align*}
|e_{(m+1)}|  
&\leq  \overbrace{\frac{1}{2} \; \left(\sup_{\theta\in I}|\ell'''(\theta)|\right)\;\left(\sup_{\theta\in I}\frac{1}{|\ell''(\theta_{(m)})|}\right)}^{=M}\;(e_{(m)})^2\\[2ex]
\Leftrightarrow\quad |e_{(m+1)}|  
&\leq  M\;(e_{(m)})^2\\[-2ex]
\end{align*}
$${#eq-NRIneq}
To show that the Newton-Raphon algorithm converges, we need to show that 
$$
|e_{(m)}|\to 0 \quad\text{as}\quad m \to\infty. 
$$

For $0\leq M\,|e_{(0)}|<1$ the inequality in @eq-NRIneq becomes a sharp inequality
$$
\begin{align*}
&|e_{(1)}|\leq \overbrace{M\;|e_{(0)}|}^{<1}\,|e_{(0)}|
\quad\Rightarrow\quad |e_{(1)}|< \,|e_{(0)}|\\[3ex]
&{\color{darkgreen}[\text{Using that $M\;|e_{(0)}|<1$ and that $|e_{(1)}|<|e_{(0)}|$}]}\\[2ex]
\Rightarrow\quad 
& |e_{(2)}|\leq {\color{darkgreen}\overbrace{M\;|e_{(1)}|}^{<1}}\,|e_{(1)}|
\quad\Rightarrow\quad |e_{(2)}|< \,|e_{(1)}|\\[2ex]
&\phantom{|e_{(2)}|\leq \overbrace{M\;|e_{(1)}|}^{<1}\,|e_{(1)}|}\vdots\\[2ex]
\Rightarrow\quad 
& |e_{(m+1)}|< \,|e_{(m)}| \quad\text{for all }m=0,1,2\dots
\end{align*}
$$
which shows the convergence of the Newton Raphson algorithm. (The inequality in @eq-NRIneq implies that the convergence is even quadratic; i.e. very fast.)

**Special Case** $M=0$: </br>
For
$$
\sup_{\theta\in I}|\ell'''(\theta)|=0
$$
we have that $M=0$ which implies that we find the root, $\theta_{root},$ already in the first $(m=1)$ update step, since  
$$
\begin{align*}
|e_{(1)}|  
&\leq \overbrace{\left(M |e_{(0)}|\right)}^{=0}\;|e_{(0)}|\\[2ex]
\Rightarrow\quad |e_{(1)}|&=0\\[2ex]
\Rightarrow\quad \theta_{(1)}&=\theta_{root},
\end{align*}
$$ 
even when $|e_{(0)}|\gg 0.$ 

This makes sense, since $\sup_{\theta\in I}|\ell'''(\theta)|=0$ implies that $\ell'(\theta)$ has no curvature; i.e. $\ell'(\theta)$ is a straight line for all $x\in I$ which implies that the Taylor approximation used in the update steps of the Newton-Raphson algorithm is just perfect (no approximation error).


-->

## References {-}







<!-- DO NOT DELETE! -->
<!-- Further ML-Material (Particularly Tests) -->
<!-- DO NOT DELETE! -->







<!-- ## Discussion of Assumptions and Results {-} -->
<!-- \begin{itemize} -->
<!-- \item **Strict exogeneity**:  Needed to assume $\E[\varepsilon | X]=0$ to show consistency of $\hat\beta_{ML}$.  -->
<!-- \item **Homoskedasticity and non-autocorrelation**:  We used the assumption that $\E[\varepsilon eps']\sim(0, \sigma^2 I)$ to derive estimator of $\sigma^2$.   -->
<!-- \item **Normality**:  The normality assumption is used **only** to derive small-sample properties of the estimators. By using asymptotic arguments one can show that both $\hat\beta_{ML}$ and $s_{ML}^2$ will be distributed -->
<!-- asymptotically normally also without the normality assumption. -->
<!-- \end{itemize} -->

<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Best Linear Unbiased Estimator} -->
<!-- Given our assumptions, then by the Gauss-Markov theorem, it is possible to show that  -->
<!-- \begin{itemize}  -->
<!-- \item<1->$\hat\beta$ is the Best Linear Unbiased (BLUE) estimator of $\beta$ -->
<!-- \item<2-> The best linear unbiased estimator of any linear combination of the $\beta$'s is the same linear combination -->
<!-- of the $\hat\beta$'s. -->
<!-- \item<3-> The Best Linear Unbiased Predictor (BLUP) of $Y$ based on the vector $X_s$ is $\hat y_s=X^T_s\hat\beta$ -->
<!-- \end{itemize} -->

<!-- \end{frame} -->


<!-- ## Hypothesis Testing -->
<!-- ### Testing Hypotheses about One Parameter -->

<!-- \noindent**Definition of the Score** -->

<!-- Define the **score of the log likelihood** (also known as the **gradient vector** -->
<!-- for observation $i$ -->
<!-- \begin{equation*} -->
<!-- s_i(\beta)\equiv \left(\dfrac{\partial L_i}{\partial \beta_0}(\beta), \dfrac{\partial L_i}{\partial \beta_1}(\beta), \dots, \dfrac{\partial L_i}{\partial \beta_k}(\beta)\right)^T -->
<!-- \end{equation*} -->



<!-- %In the logit and probit cases, this can be shown to be -->
<!-- %\begin{equation*} -->
<!-- %s_i(\beta)\equiv\dfrac{g(x_i\beta)[y_i-G(x_i\beta)]} -->
<!-- %{G(x_i\beta)[1-G(x_i\beta)]}x_i' -->
<!-- %\end{equation*} -->
<!-- %Since $x_i$ is $1 \times (k+1)$, the score is a $(k+1) \times 1$ vector.  Recalling that in the probit %case -->
<!-- %\begin{center} -->
<!-- %$g(z)=\phi(z)$ and $G(z)=\Phi(z)$ -->
<!-- %\end{center} -->
<!-- %while with logit -->
<!-- %\begin{center} -->
<!-- %$g(z)=\exp(z)/[1+\exp(z)]^2$ and $G(z)=\exp(z)/[1+\exp(z)]$. -->
<!-- %\end{center} -->


<!-- #### Variance-Covariance Matrix {-} -->

<!-- Using the standard maximum likelihood theory it can be -->
<!-- show that the asymptotic-variance covariance matrix of the MLE $\hat\beta_{ML}$ is given by -->
<!-- \begin{equation*} -->
<!-- \text{Asy.~Var}(\hat\beta_{ML})=\left[\sum_{i=1}^N s_i(\hat\beta)s_i(\hat\beta)^T\right]^{-1} -->
<!-- \end{equation*} -->
<!-- %and therefore in our case we have -->
<!-- %\begin{equation*} -->
<!-- %\text{Asy. Var-Cov}(\hat\beta)=\left[\sum_{i=1}^N\dfrac{[g(x_i\hat\beta)]^2 x_i' x_i}{G(x_i\hat\beta) -->
<!-- %[1-G(x_i\hat\beta)]}\right]^{-1} -->
<!-- %\end{equation*} -->
<!-- %with $g(\cdot)$ and $G(\cdot)$ defined as above. -->
<!-- %\vskip .1in -->
<!-- The square roots of the diagonals of this matrix will give us the -->
<!-- **standard errors** of the estimates. -->











<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Asymptotic Distribution} -->

<!-- Now, by the usual asymptotic theory, we have -->
<!-- \begin{equation*} -->
<!-- \dfrac{\hat\beta_j - \beta_j^0}{\text{std. err.}(\hat\beta_j)}\stackrel{a}{\sim} \mathcal{N}(0,1) -->
<!-- \end{equation*} -->
<!-- where $\beta_j^0$ is the value of the parameter under the null hypothesis. -->
<!-- So, we can do our usual "$t$-tests" although because we rely on asymptotics, -->
<!-- they should probably be more properly called $z$-tests. -->

<!-- \end{frame} -->


<!-- \subsection{Testing Hypotheses about Multiple Parameters} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Testing Joint Hypotheses} -->

<!-- We may also want to test hypotheses about multiple parameters.  Here it will -->
<!-- be useful to think about the regressions implied by imposing the restrictions. -->
<!-- So, for example,  -->
<!-- \begin{equation*} -->
<!-- \begin{array}{ll} -->
<!-- H_0: & R\beta - r = 0\\ -->
<!-- H_A: & H_0 \text{ is not true} \\ -->
<!-- \end{array} -->
<!-- \end{equation*} -->
<!-- where $R$ is a $q \times (k+1)$ matrix that defines the $q$ restrictions placed on the parameters -->
<!-- under the null hypothesis and $r$ is a $q \times 1$ vector of constants. -->

<!-- \end{frame} -->

<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Restricted and Unrestricted Regressions} -->

<!-- We will define the **restricted regression** as one in which we force -->
<!-- the $R\hat\beta$ to be equal to  -->
<!-- $r$ (i.e. under the null hypothesis), and the -->
<!-- **unrestricted regression** to be one in which we allow the data to tell -->
<!-- us what the values of $\beta$ should be. -->
<!-- \vskip .2in -->
<!-- Define $L_r$ as the log-likelihood corresponding to the restricted regeression -->
<!-- and $L_u$ as the log-likelihood corresponding to the unrestricted regression. -->

<!-- \end{frame} -->

<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Three Asymptotically Equivalent Tests} -->

<!-- We will discuss three asymptotically equivalent tests: -->
<!-- \begin{itemize} -->
<!-- \item **Wald test**: based on the unrestricted regression -->
<!-- \item **Likelihood ratio test**: based on both the restricted and unrestrcited regressions -->
<!-- \item **Lagrange multiplier test**: based on the restricted regression. -->
<!-- \end{itemize} -->

<!-- All three tests will give us the same answer asymptotically, but will differ -->
<!-- in their values in finite samples. -->

<!-- \end{frame} -->

<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Wald Test (1)} -->

<!-- From maximum likelihood theory, we know that  -->
<!-- \begin{equation*} -->
<!-- \hat\beta \adist \mathcal{N}(\beta,V) -->
<!-- \end{equation*} -->
<!-- and therefore that $R\hat\beta$ also has an asymptotically normal distribution -->
<!-- (since it is just a linear combination of asymptotically normal variables): -->
<!-- \begin{equation*} -->
<!-- (R\hat\beta - R\beta) \adist \mathcal{N}(0, RVR') -->
<!-- \end{equation*} -->
<!-- This suggests a quadratic form which we can use to test hypotheses -->
<!-- \begin{equation*} -->
<!-- W\equiv(R\hat\beta - r)^T[R \hat V_u R']^{-1}(R\hat\beta - r) \adist \chi_q^2 -->
<!-- \end{equation*} -->
<!-- \end{frame} -->

<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Wald Test (2)} -->

<!-- Thus, with the **Wald test**, we need only estimate the *unrestricted* regression. -->

<!-- \vskip .25in -->

<!-- It measures how far apart the estimated parameters are from the values of  -->
<!-- the parameters under the null hypothesis. -->

<!-- \end{frame} -->

<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Likelihood Ratio Test} -->

<!-- More conceptually simple, perhaps, is the **Likelihood Ratio Test**. -->
<!-- \vskip .15in -->
<!-- If the null hypothesis holds, imposing restrictions on the data should lead -->
<!-- to values of $L_r$ and $L_u$ that are ``close''.  The question then, is what -->
<!-- metric to use to judget how ``close '' they are. -->
<!-- \vskip .15in -->
<!-- It can be shown that -->
<!-- \begin{equation*} -->
<!-- LR\equiv -2 [L_r - L_u] \adist \chi^2_q -->
<!-- \end{equation*} -->
<!-- Therefore the $\chi^2_q$ distribution is the proper metric for judging how close -->
<!-- the likelihoods are. -->
<!-- \vskip .15in -->
<!-- We must fit both models to calculate the differences between the restricted -->
<!-- and restricted likelihoods. -->

<!-- \end{frame} -->

<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Motivation} -->

<!-- The **Lagrange Multiplier Test** (also called the **Score Test**) is based -->
<!-- on the score, or gradient, vector (as defined earlier).  The idea is to measure -->
<!-- how far away from the peak of the *unrestricted* likelihood imposing the -->
<!-- restrctions forces us, which is some akin to the notion of the likelihood ratio -->
<!-- test.  -->
<!-- \vskip.15in -->
<!-- At the peak of the unrestricted log likelihood, the score would be a vector of -->
<!-- zeros.  Intuitively, then, the Lagrante Multiplier Test will measure how ``close'' -->
<!-- the score vector when we estimate the *restricted* regression is to  -->
<!-- the vector of zeroes. -->

<!-- \end{frame} -->

<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Derivation (1)} -->

<!-- We can think about finding the maximum of the log likelihood subject to -->
<!-- the constraints imposed by the null hypothesis.  To simplify things, suppose we have only two -->
<!-- parameters, $\beta_1$ and $\beta_2$ with $H_0: \beta_2=c$. -->
<!-- Then: -->
<!-- \begin{equation*} -->
<!-- H(\beta, \lambda)=\sum_{i=1}^N  L_i(\beta) - \lambda'(\beta_2-c) -->
<!-- \end{equation*} -->
<!-- where $\lambda$ is the Lagrange multiplier.  Then the first order conditions -->
<!-- are -->
<!-- \begin{align*} -->
<!-- \sum_{i=1}^N  \dfrac{\partial L_i (\beta)}{\partial \beta_1} \big\vert_{\tilde\beta} -->
<!-- &=\sum_{i=1}^N s_{i1}(\tilde\beta)=0\\ -->
<!-- \tilde\lambda=\sum_{i=1}^N \dfrac{\partial L_i (\beta)}{\partial \beta_1} \big\vert_{\tilde\beta} &=\sum_{i=1}^N s_{i2}(\tilde\beta)\\ -->
<!-- \end{align*} -->
<!-- \end{frame} -->


<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Derivation (2)} -->

<!-- Define $s_{i1}$ and $s_{i2}$ are the subvectors of $s_i(\beta)$ corresponding to  -->
<!-- $\beta_1$ and $\beta_2$, respectively. -->

<!-- \vskip .15in -->

<!-- So we are in some sense testing whether $\tilde\lambda$ is ``close'' to zero or -->
<!-- not, evaluated at the restricted values of the parameters. -->

<!-- \vskip .15in -->

<!-- It's possible to show, then, that -->

<!-- \begin{equation*} -->
<!-- LM\equiv  s'(\tilde\beta) \tilde V_r^{-1} s(\tilde\beta) \adist \chi^2_q -->
<!-- \end{equation*} -->
<!-- where $s(\tilde\beta)$ is the score evaluated at the *restricted* estimates of -->
<!-- the parameters, and $\tilde V_r$ is the estimated variance-covariance matrix from the *restricted* regression. -->
<!-- \end{frame} -->


<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Relationshiop between W, LR, and LM tests} -->

<!-- \includegraphics[angle=90, scale=.60]{wald-lm-lr.ps} -->
<!-- \end{frame} -->


<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Relationship between W, LR, and LM} -->

<!-- While all three tests are asymptotically equivalent, it can be shown that in finite -->
<!-- samples -->
<!-- \begin{center} -->
<!-- $LM < LR < W$ -->
<!-- \end{center} -->
<!-- meaning that LM tests will favor not rejecting the null and W tests will favor rejecting -->
<!-- the null. -->

<!-- \end{frame} -->


<!-- \end{document} -->

<!-- \section{Goodness of Fit Measures} -->
<!-- \subsection{Goodness of Fit Measures} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Goodness of Fit in Probit and Logit} -->

<!-- As in the linear regression model, we would like to have some measure -->
<!-- of how well our model fits the data.  Unlike linear models, however, where -->
<!-- $R^2$ serves as the primary goodness-of-fit measure, there is no -->
<!-- standard metric that is used. -->
<!-- \vskip .15in -->
<!-- Now, define $L_0$ as the log likelihood of a model in which we constrain -->
<!-- all of the coefficients (except the constant) to be equal to zero. -->

<!-- \end{frame} -->




<!-- %------------------------------------------------- -->
<!-- %------------------------------------------------- -->
<!-- %\begin{frame} -->
<!-- %\frametitle{A Note on $L_0$} -->
<!-- %Note that we do not actually need to run a  regression to estimate $L_0$. -->
<!-- %\vskip .15in -->
<!-- %With just a constant term in the model, the likelihood function is given by -->
<!-- %\begin{align*} -->
<!-- %L_0&=\sum y_i \ln(N_1/N) + \sum (1-y_i) \ln(1-N_1/N)\\ -->
<!--  %    &=N_1 \ln(N_1/N) + N_0\ln(N_0/N)\\ -->
<!-- %\end{align*} -->
<!-- %where $N_1$ indicates the number of success and $N_0$ is the number of failures. -->
<!-- %\end{frame} -->


<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Pseudo-$R^2$} -->

<!-- The first goodness-of-fit measure is meant as an analog to the $R^2$ from -->
<!-- linear regression, called the pseudo-$R^2$.  It is defined as -->
<!-- \begin{equation*} -->
<!-- \text{pseudo}-R^2=1-\dfrac{1}{1+2(L_u - L_0)/N} -->
<!-- \end{equation*} -->
<!-- Intuitively, the greater the distance between the restricted and -->
<!-- unrestricted log likelihoods, the more the model explains the variation -->
<!-- in $y$, and the greater the pseudo-$R^2$ will be. -->

<!-- \end{frame} -->

<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{McFadden's $R^2$} -->

<!-- McFadden suggested an alternative goodness of fit-measures: -->

<!-- \begin{equation*} -->
<!-- \text{McFadden}-R^2= 1- L_u/L_0 -->
<!-- \end{equation*} -->
<!-- since the log likelihood is just the sum of log probabilities, it must be that -->
<!-- $L_0 < L_u < 0$. -->

<!-- \end{frame} -->


<!-- %------------------------------------------------- -->
<!-- %\begin{frame} -->
<!-- %\frametitle{Proportion of Correct Predictions} -->

<!-- %An additional measure of the fit of the model is the number of observations for -->
<!-- %which the model correctly predicts the outcome. -->

<!-- %\end{frame} -->