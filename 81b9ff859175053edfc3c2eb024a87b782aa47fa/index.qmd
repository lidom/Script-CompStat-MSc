# Organization of the Course {-}

### Timetable {-}

```{r, echo=FALSE}
suppressPackageStartupMessages(library("kableExtra"))
suppressPackageStartupMessages(library("tidyverse"))

timetable <- tibble("Day"          = c("Monday",         "Wednesday"),
                    "Time"         = c("16:15-17:45",    "8:30-10:00"),
                    "Lecture Hall" = c("Lecture Hall F", "Lecture Hall N"))
           
timetable %>% kbl() %>%  kable_styling()
```

### Syllabus {-}

* Maximum Likelihood Estimation 
* EM Algorithm & Cluster Analysis 
* Bootstrap 
* Nonparametric Regression
<!-- * Functional Data Analysis -->

### Lecture Material {-}

* This online script available at: [https://www.dliebl.com/Script-CompStat-MSc/](https://www.dliebl.com/Script-CompStat-MSc/) (pwd: compstat)

* We'll use an [eWhiteboard](https://www.dropbox.com/scl/fi/uud9ifhccfwiy07x60dsx/eWhiteboard_COS_MA_2025_annotated.pdf?rlkey=nmnfoaxyqvflruqvdzzmmutqh&dl=0) for derivations and some extra explanations.  

* Basic material from our econometrics course: 

  * [Introduction to R](https://www.dliebl.com/Script-Econometrics-MSc/966b9734015a6d617d09dae170c907a100bded72/docs/01-Introduction-to-R.html)
  * [Probability](https://www.dliebl.com/Script-Econometrics-MSc/966b9734015a6d617d09dae170c907a100bded72/docs/02-Probability.html)


<!-- * Course Textbook (`ISLR`): 
  * [An Introduction to Statistical Learning (2nd Edition)](https://www.statlearning.com/), by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani
  * The pdf-Version of the textbook `ISLR` can be downloaded for free: [Free Book](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)   -->

<!-- * Online resources (datasets, etc.) for the book can be found [HERE](https://www.statlearning.com/resources-second-edition).
* [eWhiteboard](https://uni-bonn.sciebo.de/s/qdGFYfqMno0QfzX) for the lecture notes.
* [This online script](https://www.dliebl.com/Script-ISLR/)

The above links to the lecture materials can also be found at [eCampus](https://ecampus.uni-bonn.de/goto_ecampus_crs_2700628.html) -->


<!-- ### Communication {-}

* You can use the Zulip-Chat [CompStat (M.Sc.)](https://ifs-bonn.zulipchat.com/join/mpq7rq7enmwv23rjp7c3giwn/) to post questions, share codes, etc. Happy sharing and discussing!  -->


<!-- 
### Information on the Exam {-} 

* The exam will contain 10 multiple-choice (single-select) problems and a few free-text problems. Both parts (multiple-choice and free-text) of the exam are graded separately and the final grade is then an equally weighted average of these grades. 
* You are allowed to use a handwritten cheat-sheet (**one side** of a DIN A4 page).
* You are allowed to use a non-programmable scientific calculator.
* Please, do **not** use a pencil.
* Exam dates and times are published by the [examinations office](https://www.econ.uni-bonn.de/examinations/en/dates/dates?set_language=en) 
-->


<!-- ### Miscellaneous {-}

* Consider using **git/github** for your personal course notes. 
  * [https://happygitwithr.com/](https://happygitwithr.com/) -->


<!-- ### Further Material

The following resources are not directly used in our course, but you may find them useful nevertheless:

* [`R` Labs using `Tidymodels`](https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/index.html)

* [Slides, Datasets, R-Scripts, etc](https://www.statlearning.com/resources-second-edition)

* [Slides and Videos (1st edition of the course textbook)](https://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)


Zur Vorbereitung der Klausur ist es grunds채tzlich aussreichend dieses Kapitel durchzuarbeiten - aber Lesen hat ja noch nie geschadet. Dieses Kapitel basiert haupts채chlich auf: 

+ Kapitel 9 in [**Pattern Recognition and Machine Learning**](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf) [@book_Bishop2006].<br> 
Die pdf-Version des Buches ist frei erh채ltlichen: [**pdf-Version**](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)

Weiteren guten Lesestoff zum EM Algoithmus gibt es z.B. hier:

+ Kapitel 8.5 in [**Elements of Statistical Learning: Data Mining, Inference and Prediction**](https://web.stanford.edu/~hastie/ElemStatLearn/) [@Elements].<br> 
Die pdf-Version des Buches ist frei erh채ltlichen: [**pdf-Version**](https://web.stanford.edu/~hastie/ElemStatLearn/)

 -->


