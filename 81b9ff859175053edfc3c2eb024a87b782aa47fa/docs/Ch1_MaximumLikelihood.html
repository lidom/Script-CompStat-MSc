<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; Maximum Likelihood – Computational Statistics (M.Sc.)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Ch2_EMAlgorithmus.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Ch1_MaximumLikelihood.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./images/Uni_Bonn_Logo.jpeg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Computational Statistics (M.Sc.)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Organization of the Course</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch1_MaximumLikelihood.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch2_EMAlgorithmus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">EM Algorithm &amp; Cluster Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch3_Bootstrap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Bootstrap</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ch4_NPRegression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Nonparametric Regression</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction-the-likelihood-principle" id="toc-introduction-the-likelihood-principle" class="nav-link active" data-scroll-target="#introduction-the-likelihood-principle"><span class="header-section-number">1.1</span> Introduction: The Likelihood Principle</a>
  <ul class="collapse">
  <li><a href="#properties-of-maximum-likelihood-estimators" id="toc-properties-of-maximum-likelihood-estimators" class="nav-link" data-scroll-target="#properties-of-maximum-likelihood-estimators"><span class="header-section-number">1.1.1</span> Properties of Maximum Likelihood Estimators</a></li>
  <li><a href="#example-coin-flipping-bernoulli-trial" id="toc-example-coin-flipping-bernoulli-trial" class="nav-link" data-scroll-target="#example-coin-flipping-bernoulli-trial"><span class="header-section-number">1.1.2</span> Example: Coin Flipping (Bernoulli Trial)</a></li>
  <li><a href="#estimation-idea" id="toc-estimation-idea" class="nav-link" data-scroll-target="#estimation-idea"><span class="header-section-number">1.1.3</span> Estimation Idea</a></li>
  </ul></li>
  <li><a href="#numeric-optimization" id="toc-numeric-optimization" class="nav-link" data-scroll-target="#numeric-optimization"><span class="header-section-number">1.2</span> Numeric Optimization</a>
  <ul class="collapse">
  <li><a href="#newton-raphson-optimization" id="toc-newton-raphson-optimization" class="nav-link" data-scroll-target="#newton-raphson-optimization"><span class="header-section-number">1.2.1</span> Newton-Raphson Optimization</a></li>
  <li><a href="#sec-ConvNR" id="toc-sec-ConvNR" class="nav-link" data-scroll-target="#sec-ConvNR"><span class="header-section-number">1.2.2</span> Convergence of the Newton-Raphson Algorithm</a></li>
  <li><a href="#newton-raphson-algorithm-coin-flipping-example" id="toc-newton-raphson-algorithm-coin-flipping-example" class="nav-link" data-scroll-target="#newton-raphson-algorithm-coin-flipping-example"><span class="header-section-number">1.2.3</span> Newton-Raphson Algorithm: Coin-Flipping Example</a></li>
  </ul></li>
  <li><a href="#sec-LinRegNorm" id="toc-sec-LinRegNorm" class="nav-link" data-scroll-target="#sec-LinRegNorm"><span class="header-section-number">1.3</span> Linear Regression under Normality</a>
  <ul class="collapse">
  <li><a href="#sec-varMLE" id="toc-sec-varMLE" class="nav-link" data-scroll-target="#sec-varMLE"><span class="header-section-number">1.3.1</span> Variance of ML-Estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML}\)</span></a></li>
  <li><a href="#asymptotic-distribution-and-single-parameter-testing" id="toc-asymptotic-distribution-and-single-parameter-testing" class="nav-link" data-scroll-target="#asymptotic-distribution-and-single-parameter-testing"><span class="header-section-number">1.3.2</span> Asymptotic Distribution and Single Parameter Testing</a></li>
  </ul></li>
  <li><a href="#sec-MLAsymp" id="toc-sec-MLAsymp" class="nav-link" data-scroll-target="#sec-MLAsymp"><span class="header-section-number">1.4</span> Asymptotic Theory of Maximum-Likelihood Estimators</a></li>
  <li><a href="#cramérrao-lower-bound" id="toc-cramérrao-lower-bound" class="nav-link" data-scroll-target="#cramérrao-lower-bound"><span class="header-section-number">1.5</span> Cramér–Rao Lower Bound</a></li>
  <li><a href="#invariance-property-of-the-ml-estimator" id="toc-invariance-property-of-the-ml-estimator" class="nav-link" data-scroll-target="#invariance-property-of-the-ml-estimator"><span class="header-section-number">1.6</span> Invariance Property of the ML-Estimator</a>
  <ul class="collapse">
  <li><a href="#one-to-one-functions" id="toc-one-to-one-functions" class="nav-link" data-scroll-target="#one-to-one-functions">One-to-One Functions</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises">Exercises</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- LTeX: language=en-US -->
<!-- For updating: Elements of Statistical Learning and All of Statistics -->
<section id="introduction-the-likelihood-principle" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="introduction-the-likelihood-principle"><span class="header-section-number">1.1</span> Introduction: The Likelihood Principle</h2>
<p>The basic idea behind maximum likelihood estimation is very simple: Assume that the data is generated by some distribution with a certain (finite) set of unknown distribution parameters (e.g., the normal distribution with unknown mean and variance). Then find the distribution parameters for which it is most likely that the distribution has generated the data we actually observed.</p>
<p>In (classic) maximum likelihood estimation we must be rather specific about the process that generated the data. This is a trade-off: by imposing a fair amount of structure on the data, we get in return a very desirable estimator. The question remains, however, whether we have made the right decision about the general distribution/density function family.</p>
<section id="properties-of-maximum-likelihood-estimators" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="properties-of-maximum-likelihood-estimators"><span class="header-section-number">1.1.1</span> Properties of Maximum Likelihood Estimators</h3>
<p>Why do we like maximum likelihood as an estimation method? The answer is that: A maximum likelihood estimator <span class="math inline">\(\hat\theta_n\)</span> of some parameter, e.g.&nbsp;<span class="math inline">\(\theta_0\in\mathbb{R}\)</span>, is</p>
<ul>
<li><strong>Consistent:</strong><br>
<span class="math display">\[
\hat\theta_n\rightarrow_p\theta_0,\quad n\to\infty
\]</span></li>
<li><strong>Asymptotically normal:</strong> <span class="math display">\[
\sqrt{n}(\hat\theta_n-\theta_0) \stackrel{a}{\sim} \mathcal{N}(0, \sigma^2)
\]</span></li>
<li><strong>Asymptotically efficient:</strong> This means that no other consistent estimator has a lower asymptotic mean squared error than the maximum likelihood estimator.</li>
</ul>
<p>Likewise for multivariate parameter <span class="math inline">\(\theta_0\in\mathbb{R}^p.\)</span></p>
<p>Thus, maximum likelihood estimators can be very appealing, provided that the assumption on the general distribution family is correct.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ML-estimation requires fixing the family of distributions <span class="math inline">\(f(\cdot;\theta)\)</span>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <span class="math display">\[
X_1,\dots,X_n
\]</span> denote a (i.i.d.) random sample, such that <span class="math inline">\(X_i\overset{\text{i.i.d.}}{\sim} f\)</span>, for all <span class="math inline">\(i=1,\dots,n.\)</span></p>
<p>Classic ML-estimation requires us to fix the general family of density functions or probability mass functions <span class="math inline">\(f,\)</span> where <span class="math inline">\(f\)</span> is known up to an unknown parameter value <span class="math inline">\(\theta_0,\)</span> and where <span class="math inline">\(\theta_0\in\mathbb{R}^K\)</span> is a <em>finite</em> (<span class="math inline">\(1\leq K&lt;\infty\)</span>) dimensional parameter vector.</p>
<p><strong>Examples:</strong></p>
<ul>
<li><span class="math inline">\(f\)</span> being the probability mass function of the Bernoulli distribution <span class="math inline">\(\mathcal{Bern}(\theta)\)</span> with <span class="math display">\[
f(x;\theta_0)=
\left\{
\begin{array}{ll}
\theta_0,   &amp; \text{if } x=1\\
1-\theta_0, &amp; \text{if } x=0
\end{array}
\right.
\]</span> and <strong>unknown</strong> parameter <span class="math inline">\(0\leq \theta\leq 1.\)</span></li>
<li>The density function of the exponential distribution <span class="math display">\[
f(x;\theta_0)=\left\{
  \begin{matrix}
  \theta_0\exp(- \theta_0 x)&amp; \text{for }x\geq 0\\
  0                     &amp; \text{for }x &lt; 0\\
  \end{matrix}\right.
\]</span> with unknown rate parameter <span class="math inline">\(\theta_0&gt;0\)</span> and <span class="math inline">\(x\in\mathbb{R}.\)</span></li>
<li><span class="math inline">\(f\)</span> is the normal density <span class="math display">\[
f(x;\theta_0)=\frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{1}{2}\left(\frac{x-\mu_0}{\sigma_0}\right)^2\right)
\]</span> with <strong>unknown</strong> parameter vector <span class="math inline">\(\theta_0=(\mu_0,\sigma_0^2)^T\)</span> and <span class="math inline">\(x\in\mathbb{R}.\)</span></li>
</ul>
<p>This requirement (fixing the family of density functions) can be overly restrictive. In many applications we typically do not know the family of <span class="math inline">\(f.\)</span> To address this issue, the <strong>quasi maximum likelihood theory</strong> generalizes classic maximum likelihood estimation to cases where <span class="math inline">\(f\)</span> is misspecified (see <span class="citation" data-cites="White1982">White (<a href="#ref-White1982" role="doc-biblioref">1982</a>)</span>).</p>
</div>
</div>
</section>
<section id="example-coin-flipping-bernoulli-trial" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="example-coin-flipping-bernoulli-trial"><span class="header-section-number">1.1.2</span> Example: Coin Flipping (Bernoulli Trial)</h3>
<p>To introduce the main idea of maximum likelihood estimation, we use the simple example of a coin flipping experiment, where a <strong>possibly unfair</strong> <span class="math inline">\(\text{Coin}\)</span> can take the value <span class="math inline">\(H\)</span> (Head) or <span class="math inline">\(T\)</span> (Tail), <span class="math display">\[
\text{Coin}\in\{H,T\}.
\]</span> Such coin-flips can be modeled using Bernoulli random variables <span class="math display">\[
X\sim\mathcal{Bern}(\theta_0)
\]</span> where <span class="math display">\[
X=\left\{
    \begin{matrix}
    1 &amp; \text{if } \text{Coin}=H\\[2ex]
    0 &amp; \text{if } \text{Coin}=T
    \end{matrix}
    \right.
\]</span> The probability mass function of the Bernoulli distribution <span class="math inline">\(\mathcal{Bern}(\theta_0),\)</span> with <strong>unknown</strong> probability of success parameter <span class="math inline">\(0&lt;\theta_0&lt;1,\)</span> is given by <span class="math display">\[
f(x;\theta_0)=
\left\{
  \begin{array}{ll}
  \theta_0,&amp;\text{if } x=1\\
  1-\theta_0, &amp; \text{if } x=0
  \end{array}
\right.
\]</span> I.e., the probability that we get Head <span class="math inline">\(H\)</span> is <span class="math display">\[
\theta_0 = f(1;\theta_0) = P(X=1) = P(\text{Coin}=H),
\]</span> and the probability that we get Tail <span class="math inline">\(T\)</span> is <span class="math display">\[
1-\theta_0 = f(0;\theta_0) = P(X=0) = P(\text{Coin}=T).
\]</span></p>
<p>Our goal is to <strong>estimate the unknown</strong> <span class="math inline">\(\theta_0\)</span> using a random (i.i.d.) sample of size <span class="math inline">\(n\)</span> <span class="math display">\[
\{X_1,\dots,X_n\}
\]</span> with <span class="math display">\[
X_i=\left\{
    \begin{matrix}
    1 &amp; \text{if } \text{Coin}=H\text{ in $i$th coin flip}\\[2ex]
    0 &amp; \text{if } \text{Coin}=T\text{ in $i$th coin flip}
    \end{matrix}
    \right.
\]</span> such that <span class="math display">\[
X_i\overset{\text{i.i.d.}}{\sim}\mathcal{Bern}(\theta_0),\quad i=1,\dots,n.
\]</span> <!-- where $\mathcal{Bern}(\theta)$ denotes the Bernoulli distribution with unknown probability of success parameter $\theta.$  --></p>
<p>A <strong>given observed realization</strong> of the random sample <span class="math display">\[
\{X_{1,obs},X_{2,obs},\dots,X_{n,obs}\}=\{0,1,\dots,0\}
\]</span> consists of <span class="math inline">\(0\leq N_{H,obs}\leq n\)</span> <span class="math display">\[
N_{H,obs}=\sum_{i=1}^n X_{i,obs}
\]</span> many heads and <span class="math display">\[
0\leq n-N_{H,obs} \leq n
\]</span> many tails.</p>
<section id="the-log-likelihood-function" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-log-likelihood-function"><strong>The (Log-)Likelihood Function</strong></h4>
<p>How do we combine the information from the <span class="math inline">\(n\)</span> observations <span class="math display">\[
\{X_{1,obs},\dots,X_{n,obs}\}
\]</span> to estimate the unknown <span class="math inline">\(\theta_0\)</span>?</p>
<p>If the observations are realizations of an i.i.d. sample, then the joint probability of observing <span class="math inline">\(h\)</span> heads <span class="math inline">\(H\)</span> and <span class="math inline">\(n-h\)</span> tails <span class="math inline">\(T\)</span> in <span class="math inline">\(n\)</span> coin flips is: <span class="math display">\[
\begin{align*}
\mathcal{L}_{n,obs}(\theta)
&amp;=\prod_{i=1}^nf(X_{i,obs};\theta)\\[2ex]
%&amp;=\left(P(X=1)\right)^{N_{H,obs}}\left(P(X=0)\right)^{n-N_{H,obs}}\\[2ex]
%&amp;= \theta^{N_{H,obs}}(1-\theta)^{n-N_{H,obs}}  \\[2ex]
&amp;= \prod_{i=1}^n \theta^{X_{i,obs}}(1-\theta)^{1-X_{i,obs}},
\end{align*}
\]</span> where <span class="math inline">\(f(\,\cdot\,;\theta)\)</span> denotes here the probability mass function of the Bernoulli distribution with parameter candidate <span class="math inline">\(p=\theta.\)</span></p>
<p>The function <span class="math inline">\(\mathcal{L}_n(\theta)\)</span> is called the <strong>likelihood function</strong>. The likelihood function depends on the random sample and is thus itself random. If we want to emphasize that we look at a given realization, we write <span class="math inline">\(\mathcal{L}_{,obs}(\theta)\)</span>.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-LikelihoodFunction" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.1 (Likelihood Function)</strong></span> Let <span class="math display">\[
\{X_{1},\dots,X_{n}\}
\]</span> denote a random sample with <span class="math inline">\(X_i\overset{\text{i.i.d.}}{\sim} f\equiv f(\,\cdot\,;\theta)\)</span> for all <span class="math inline">\(i=1,\dots,n,\)</span> where <span class="math inline">\(\theta\)</span> denotes the unknown finite dimensional parameter vector of <span class="math inline">\(f.\)</span> Then, we call <span class="math display">\[
\mathcal{L}_{n,obs}(\theta)=\prod_{i=1}^n f(X_{i,obs};\theta),
\]</span> the (random) <strong>likelihood function</strong>. Let <span class="math display">\[
\{X_{1,obs},\dots,X_{n,obs}\}
\]</span> denote a (observed) realization of <span class="math inline">\(\{X_1,\dots,X_n\}\)</span>. Then, we call <span class="math display">\[
\mathcal{L}_{n,obs}(\theta)=\prod_{i=1}^n f(X_{i,obs};\theta),
\]</span> a (observed) realization of the <strong>likelihood function</strong>.</p>
<p>(Note: A definition for dependent data (e.g., time series) is also possible.)</p>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="estimation-idea" class="level3" data-number="1.1.3">
<h3 data-number="1.1.3" class="anchored" data-anchor-id="estimation-idea"><span class="header-section-number">1.1.3</span> Estimation Idea</h3>
<p>We estimate the unknown parameter <span class="math inline">\(\theta_0\)</span> by maximizing the likelihood of the observed data <span class="math inline">\(\{X_{1,obs},\dots,X_{n,obs}\}\)</span> over the range of possible parameter values.</p>
<ul>
<li>The value <span class="math inline">\(\hat\theta_{ML}\)</span> at which the likelihood function <span class="math inline">\(\mathcal{L}_n(\cdot)\)</span> is maximized is called the <strong>maximum likelihood (ML) estimator</strong></li>
<li>The value <span class="math inline">\(\hat\theta_{ML,obs}\)</span> at which the observed likelihood function <span class="math inline">\(\mathcal{L}_{n,obs}(\cdot)\)</span> is maximized is called the <strong>maximum likelihood (ML) estimate</strong>; i.e., <span class="math inline">\(\hat\theta_{ML,obs}\)</span> is a specific realization of the ML-estimator computed from the observed data <span class="math inline">\(\{X_{1,obs},\dots,X_{n,obs}\}.\)</span></li>
</ul>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-MLEstimator" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.2 (Maximum Likelihood (ML) Estimator)</strong></span> Let <span class="math display">\[
\{X_{1},\dots,X_{n}\}
\]</span> denote a random sample with <span class="math inline">\(X_i\overset{\text{i.i.d.}}{\sim} f\equiv f(\,\cdot\,;\theta)\)</span> for all <span class="math inline">\(i=1,\dots,n,\)</span> where <span class="math inline">\(\theta\)</span> denotes the unknown finite dimensional parameter vector of <span class="math inline">\(f.\)</span> Then, we call <span class="math display">\[
\begin{align*}
\hat{\theta}_{ML}
&amp;=\arg\max_{\theta\in\Theta} \mathcal{L}_n(\theta)\\[2ex]
&amp;=\arg\max_{\theta\in\Theta} \prod_{i=1}^n f(X_{i};\theta),
\end{align*}
\]</span> the Maximum Likelihood (ML) Estimator, where <span class="math inline">\(\Theta\)</span> denotes the <strong>parameter space</strong>.</p>
<p>(Note: A definition for dependent data (e.g., time series) is also possible.)</p>
</div>
</div>
</div>
</div>
<p>Thus, to derive the estimator for the unknown <span class="math inline">\(\theta_0\)</span> in our coin flip example, we need to maximize the likelihood function, <span class="math display">\[
\begin{align*}
\hat{\theta}_{ML}
&amp;=\arg\max_{\theta\in[0,1]} \mathcal{L}_n(\theta)\\[2ex]
&amp;=\arg\max_{\theta\in[0,1]} \prod_{i=1}^n f(X_{i};\theta)\\[2ex]
&amp;=\arg\max_{\theta\in[0,1]} \prod_{i=1}^n \theta^{X_{i}}(1-\theta)^{1-X_{i}}.
\end{align*}
\]</span></p>
<p>Usually it’s easier to work with sums rather than products—also for doing the asymptotics in <a href="#sec-MLAsymp" class="quarto-xref"><span>Section 1.4</span></a>. So we apply a monotonic transformation by taking the logarithm of the likelihood which leads to the <strong>log-likelihood function</strong>: <span class="math display">\[
\begin{align*}
\ell_n(\theta)
&amp;=\ln\mathcal{L}_n(\theta)\\[2ex]
&amp;=\ln\prod_{i=1}^n f(X_{i};\theta)\\[2ex]
&amp;=\sum_{i=1}^n \ln f(X_{i};\theta).
\end{align*}
\]</span> Since this is only a monotonic transformation, we have that <span class="math display">\[
\begin{align*}
\hat\theta_{ML}
&amp;=\arg\max_{\theta\in\Theta} \mathcal{L}_n(\theta)\\[2ex]
&amp;=\arg\max_{\theta\in\Theta} \ell_n(\theta).
\end{align*}
\]</span> <!-- but $\ell_n(\theta)$ gives a more simple structure simplifying the maximization problem.  --></p>
<div class="callout callout-style-default callout-note callout-titled" title="Log-likelihoods instead of the likelihoods">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Log-likelihoods instead of the likelihoods
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>From a standpoint of computational complexity, you can imagine that summing is less expensive than multiplication (although nowadays, these are almost equal).</p></li>
<li><p>More important: likelihoods would become very small and you will run out of your <a href="https://en.wikipedia.org/wiki/Floating-point_arithmetic">floating point</a> precision very quickly, yielding an underflow. That’s why it is way more convenient to use the logarithm of the likelihood. Simply try to calculate the likelihood by hand, using pocket calculator—it’s almost impossible.</p></li>
</ul>
</div>
</div>
<p>In our coin flipping example, taking the natural logarithm yields, <span class="math display">\[
\begin{align*}
\mathcal{L}_n(\theta) &amp;= \prod_{i=1}^n \theta^{X_{i}}(1-\theta)^{1-X_{i}} \\[2ex]
\Rightarrow\quad \ell_n(\theta)
&amp;=\ln\mathcal{L}_n(\theta)\\[2ex]
&amp;=\sum_{i=1}^n\left( X_{i} \ln(\theta) + (1-X_{i})\ln(1-\theta)\right).
\end{align*}
\]</span></p>
<p>The coin flip example is actually so simple that we can maximize <span class="math inline">\(\ell_n(\theta)\)</span> analytically. Computing the first derivative yields <span class="math display">\[
\begin{align*}
\ell'_n(\theta)&amp;=\sum_{i=1}^n \left(X_{i}\dfrac{1}{\theta} - (1-X_{i})\dfrac{1}{1-\theta}\right)\\[2ex]
&amp;=\dfrac{N_{H}}{\theta} - \dfrac{n-N_{H}}{1-\theta}
\end{align*}
\]</span> Setting the first derivative to zero determines the maximum likelihood estimator (MLE) <span class="math inline">\(\hat\theta_{ML}\)</span>: <span id="eq-MLECoinFlipp"><span class="math display">\[
\begin{array}{rrcl}
&amp;\ell_n'(\hat\theta_{ML})&amp;\overset{!}{=}&amp;0\\[2ex]
\Leftrightarrow&amp;\dfrac{N_{H}}{\hat\theta_{ML}} &amp;=&amp; \dfrac{n-N_{H}}{1-\hat\theta_{ML}} \\[2ex]
\Leftrightarrow&amp;N_{H}-N_{H}\hat\theta_{ML}  &amp;=&amp; n\hat\theta_{ML}-N_{H}\hat\theta_{ML}\\[2ex]
\Leftrightarrow&amp;\hat\theta_{ML}
&amp;=&amp;\dfrac{N_{H}}{n}\\[2ex]
&amp;&amp;=&amp;\dfrac{1}{n}\sum_{i=1}^n X_i
\end{array}
\tag{1.1}\]</span></span></p>
<p>Given observed data <span class="math inline">\(\{X_{1,obs},\dots,X_{n,obs}\},\)</span> a specific estimate of <span class="math inline">\(\theta_0\)</span> can thus be computed as <span class="math display">\[
\begin{align*}
\hat{\theta}_{ML,obs}=\dfrac{1}{n}\sum_{i=1}^n X_{i,obs}.
\end{align*}
\]</span></p>
<p>Usually, however, the log-likelihood function is <strong>way more complicated</strong> such that it is impossible to derive an explicit expression for the ML-estimator <span class="math inline">\(\hat\theta_{ML}.\)</span> In such cases, one needs to apply <strong>numeric optimization</strong> algorithms to compute the ML-estimates, <span class="math inline">\(\hat\theta_{ML,obs}.\)</span></p>
</section>
</section>
<section id="numeric-optimization" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="numeric-optimization"><span class="header-section-number">1.2</span> Numeric Optimization</h2>
<p>Usually, we are not so fortunate as to have an analytical solution for the MLE, and must rely on the computer to find the maximizing arguments of the log-likelihood function. Various methods exist for finding the maximum (or minimum) of a function.</p>
<!-- [numerically with the help of the computer](https://jaimemosg.github.io/EstimationTools/index.html) -->
<p><strong>General idea: Try to find the root of <span class="math inline">\(\ell'\)</span></strong></p>
<ol type="1">
<li>Start at some value, <span class="math inline">\(\theta_{(0)},\)</span> in the parameter space <span class="math inline">\(\Theta.\)</span></li>
<li>Search across the parameter space <span class="math inline">\(\Theta\)</span> using a step-wise procedure <span class="math display">\[
\theta_{(0)},\theta_{(1)},\dots,\theta_{(m)}
\]</span> until an updated parameter value <span class="math inline">\(\theta_{(m)}\)</span> is found that yields a derivative of the log likelihood that is effectively zero (i.e.&nbsp;smaller than some convergence/stopping criterion), <span class="math display">\[
\ell'(\theta_{(m)})\approx 0.
\]</span></li>
</ol>
<section id="newton-raphson-optimization" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="newton-raphson-optimization"><span class="header-section-number">1.2.1</span> Newton-Raphson Optimization</h3>
<p>One of the most-used methods for optimization is the Newton-Raphson method (or a variant of it). The Newton-Raphson method relies on Taylor-series approximations of the log-likelihood function.</p>
<p>In the following, we consider the univariate case <span class="math inline">\(\theta\in\mathbb{R}.\)</span> However, the multivariate case <span class="math inline">\(\theta\in\mathbb{R}^K\)</span> is treated likewise, but requires substituting first derivatives by gradients, second derivatives by the Hessian, etc.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Minimization and maximization are essentially the same problems, since minimizing a function <span class="math inline">\(f(x)\)</span> with respect to <span class="math inline">\(x\)</span> is equivalent to maximizing <span class="math inline">\(-f(x)\)</span> with respect to <span class="math inline">\(x.\)</span></p>
</div>
</div>
<p>Let <span class="math inline">\(f\)</span> be a two times differentiable function to be optimized (here maximized). The <strong>first- and second-order Taylor-series approximations</strong> of <span class="math inline">\(f\)</span> around the point <span class="math inline">\(\theta\)</span> are: <span class="math display">\[
\begin{align*}
\text{First-order:}\quad &amp;f(\theta+h)\approx \overbrace{f(\theta)+f'(\theta)h}^{\text{Taylor Polynomial of order 1}} \\
\text{Second-order:}\quad&amp; f(\theta+h)\approx \underbrace{f(\theta)+f'(\theta)h + \frac{1}{2} f''(\theta)h^2}_{\text{Taylor Polynomial of order 2}},
\end{align*}
\]</span> Locally, i.e.&nbsp;for <span class="math inline">\(|h|\approx 0,\)</span> (e.g.&nbsp;<span class="math inline">\(h=\pm 0.04\)</span>) the Taylor polynomials are very good approximations of <span class="math inline">\(f(\theta + h);\)</span> see <a href="#fig-taylorApprox" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-taylorApprox" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-taylorApprox-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Ch1_MaximumLikelihood_files/figure-html/fig-taylorApprox-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-taylorApprox-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.1: First- and second-order Taylor approximations of a function <span class="math inline">\(f\)</span> around <span class="math inline">\(\theta=1.\)</span>
</figcaption>
</figure>
</div>
</div>
</div>
<!-- ::: {.callout-important}
The first-order and the second-order Taylor polynomial can both be used to approximate $f.$

The second-order Taylor polynomial can be used to apprixmate $f'.$
::: -->
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-TaylorThm" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1.1 (Taylor’s Theorem)</strong></span> <br> Today, there are many different versions of Taylor’s theorem. We consider the following two:</p>
<p><strong>1. <a href="https://en.wikipedia.org/wiki/Giuseppe_Peano">Peano</a> form of the remainder term:</strong><br> Let <span class="math inline">\(f:\mathbb{R}\to\mathbb{R}\)</span> be <span class="math inline">\(k\)</span> times differentiable at <span class="math inline">\(x\in\mathbb{R}\)</span> and let <span class="math inline">\(h\in\mathbb{R}.\)</span> Then there exists a function <span class="math inline">\(P_{k,x}:\mathbb{R}\to\mathbb{R}\)</span> such that <span class="math display">\[
\begin{align*}
f(x+h) &amp;=
f(x)
+ \sum_{\ell=1}^k \frac{f^{(\ell)}(x)}{\ell!} h^\ell
+ P_{k,x}(h) \cdot h^k
\end{align*}
\]</span> with <span class="math display">\[
P_{k,x}(h)\to 0\quad\text{as}\quad |h|\to 0,
\]</span> where <span class="math inline">\(f^{(\ell)}(x)\)</span> denotes the <span class="math inline">\(\ell\)</span>th derivative of <span class="math inline">\(f\)</span> at <span class="math inline">\(x.\)</span></p>
<p><strong>2. <a href="https://en.wikipedia.org/wiki/Joseph-Louis_Lagrange">Lagrange</a> or Mean-value form of the remainder term:</strong><br> Let <span class="math inline">\(f:\mathbb{R}\to\mathbb{R}\)</span> be <span class="math inline">\(k+1\)</span> times differentiable on the open interval between <span class="math inline">\(x\)</span> and <span class="math inline">\(x+h,\)</span> with <span class="math inline">\(h\in\mathbb{R},\)</span> and let <span class="math inline">\(f^{(k)}\)</span> be continuous on the closed interval between <span class="math inline">\(x\)</span> and <span class="math inline">\(x+h,\)</span>. Then <span class="math display">\[
\begin{align*}
f(x+h) &amp;=
f(x)
+ \sum_{\ell=1}^k \frac{f^{(\ell)}(x)}{\ell!} h^\ell
+ M_{k,x}(h)
\end{align*}
\]</span> with <span class="math display">\[
M_{k,x}(h)=\frac{f^{(k+1)}(\xi)}{(k+1)!} h^{k+1}
\]</span> for some real number <span class="math inline">\(\xi\)</span> between <span class="math inline">\(x\)</span> and <span class="math inline">\(x+h.\)</span> This form of Taylor’s theorem is based on the mean-value <a href="#thm-MVT" class="quarto-xref">Theorem&nbsp;<span>1.2</span></a>. Note that <span class="math display">\[
M_{k,x}(h)\to 0\quad\text{as}\quad |h|\to 0.
\]</span></p>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Qualitative version using the small-<span class="math inline">\(o\)</span> notation:
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{align*}
f(x + h) &amp; =
f(x)
+ \sum_{\ell=1}^k \frac{f^{(\ell)}(x)}{\ell!} h^\ell
+ o\big(|h|^k\big),
\end{align*}
\]</span> where <span class="math inline">\(o\big(|h|^k\big)\)</span> denotes the family of real-valued functions, <span class="math inline">\(g(h)\)</span> say, that are of a <strong>strictly smaller <span class="math inline">\(o\)</span>rder of magnitude</strong> than the function <span class="math inline">\(|h|^k\)</span> as <span class="math inline">\(h\to 0;\)</span> i.e.<br>
<span class="math display">\[
\begin{align*}
&amp; o\big(|h|^k\big)\\[2ex]
&amp; =\left\{\text{Any function}\;g:\mathbb{R}\to\mathbb{R}\text{ such that }\frac{|g(h)|}{|h|^k}\to 0\;\text{ as }\; |h|\to 0\right\}.
\end{align*}
\]</span></p>
<p><strong>1. Note: Peano form of the remainder term:</strong> <span class="math display">\[
P_{k,x}(h)\cdot h^k=o\big(|h|^k\big)
\]</span> since <span class="math display">\[
\frac{|P_{k,x}(h)\;h^k|}{|h|^k}
%=\frac{|P_k(x+h)|\cdot |h|^k|}{|h|^k}
=|P_{k,x}(h)|\to 0\quad\text{as}\quad h\to 0.
\]</span></p>
<p><strong>2. Note: Mean-value form of the remainder term:</strong><br> <span class="math display">\[
M_{k,x}(h)=o\big(|h|^k\big)
\]</span> since <span class="math display">\[
\frac{|M_{k,x}(h)|}{|h|^k}=
\left|\frac{f^{(k+1)}(\xi)}{(k+1)!}\right|\cdot|h|\to 0\quad\text{as}\quad h\to 0.
\]</span></p>
</div>
</div>
</div>
</div>
</div>
</div>
<section id="optimization-idea" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="optimization-idea"><strong>Optimization Idea</strong></h4>
<p>Let <span class="math inline">\(\ell_n\)</span> be a log-likelihood function with continuous first, <span class="math inline">\(\ell_n',\)</span> and second, <span class="math inline">\(\ell_n'',\)</span> derivative.</p>
<p>To optimize the log-likelihood function <span class="math inline">\(\ell_n,\)</span> we try to find the root of <span class="math inline">\(\ell_n',\)</span> i.e.&nbsp;the value of <span class="math inline">\(\theta\in\Theta\)</span> such that <span class="math display">\[
\ell_n'(\theta)=0.
\]</span> That is, we try to find the value of <span class="math inline">\(\theta\)</span> that fulfills the <strong>first order condition</strong> of the optimization problem. We do so using a step-wise optimization approach, where each step has a smallish size <span class="math inline">\(h.\)</span></p>
<p><strong>Initialization:</strong> Let <span class="math inline">\(\theta_{(0)}\in\Theta\)</span> be our first guess of the root of <span class="math inline">\(\ell'_n.\)</span></p>
<p><strong><span class="math inline">\(h\)</span>-Steps:</strong> Typically, our guess is not perfect and thus <span class="math inline">\(\ell_n'(\theta_{(0)})\neq 0.\)</span> Therefore, we want to move from <span class="math inline">\(\theta_{(0)}\)</span> to a new root-candidate <span class="math inline">\(\theta_{(1)}\)</span> by doing an <span class="math inline">\(h\)</span>-step update <span class="math display">\[
\theta_{(1)} = \theta_{(0)} + h.
\]</span></p>
<!-- 1. We select some starting value $\theta_0.$ 
2. Optimize the second-order Taylor polynomial of $f$ around $\theta_0$ with respect to $h.$ 
3. In each of the following steps, we optimize new second-order Taylor polynomials of $f$ at those values $\theta,$ for which the previous second-order Taylor polynomial was maximal.  -->
<!-- **Implementation-Idea:** The second-order Taylor-series approximation gives -->
<p>The first-order Taylor-series approximation of <span class="math inline">\(\ell_n'\)</span> around our first guess <span class="math inline">\(\theta_{(0)}\)</span> gives <span class="math display">\[
\begin{align*}
\ell_n'(\theta_{(0)} + h) &amp; \approx \ell_n'(\theta_{(0)}) + \ell_n''(\theta_{(0)})h
\end{align*}
\]</span> Thus, to find the <span class="math inline">\(h\)</span>-step that brings us closer to the root of <span class="math inline">\(\ell_n',\)</span> we can (approximatively) use the <span class="math inline">\(h\)</span>-step that brings us to the root of its first-order approximation, i.e. <span class="math display">\[
\begin{align*}
\ell_n'(\theta_{(0)}) + \ell_n''(\theta_{(0)}) h_{(0)} = 0\\[2ex]
\Rightarrow h_{(0)} = -\frac{\ell_n'(\theta_{(0)})}{\ell_n''(\theta_{(0)})}.
\end{align*}
\]</span> Based on this <span class="math inline">\(h\)</span>-step, the new root-candidate is <span class="math display">\[
\begin{align*}
\theta_{(1)}
&amp; = \theta_{(0)} + h_{(0)}\\[2ex]
&amp; = \theta_{(0)} - \frac{\ell_n'(\theta_{(0)})}{\ell_n''(\theta_{(0)})}.
\end{align*}
\]</span> Likewise, the <span class="math inline">\(m\)</span>th root-candidate is <span class="math display">\[
\begin{align*}
\theta_{(m)}
&amp; = \theta_{(m-1)} + h_{(m-1)}\\[2ex]
&amp; = \theta_{(m-1)} - \frac{\ell_n'(\theta_{(m-1)})}{\ell_n''(\theta_{(m-1)})};
\end{align*}
\]</span> see also <a href="#fig-NR" class="quarto-xref">Figure&nbsp;<span>1.2</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-NR" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-NR-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Ch1_MaximumLikelihood_files/figure-html/fig-NR-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-NR-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.2: The <span class="math inline">\(m\)</span>th update step in the Newton-Raphson root-finding algorithm.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-ConvNR" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="sec-ConvNR"><span class="header-section-number">1.2.2</span> Convergence of the Newton-Raphson Algorithm</h3>
<p>Let <span class="math inline">\(\theta_{root}\)</span> denote the root of <span class="math inline">\(\ell_n';\)</span> i.e.&nbsp; <span class="math display">\[
\ell_n'(\theta_{root})=0.
\]</span> We aim to find <span class="math inline">\(\theta_{root}\)</span> using the Newton-Raphson algorithm and call our best approximation of <span class="math inline">\(\theta_{root}\)</span> the maximum likelihood estimate; i.e.&nbsp;<span class="math inline">\(\hat{\theta}_{ML}\approx\theta_{root}.\)</span></p>
<p>Let <span class="math display">\[
e_{(0)}=\theta_{root}-\theta_{(0)}
\]</span> denote the start value error and let <span class="math display">\[
I=[\theta_{root}-|e_{(0)}|, \theta_{root}+|e_{(0)}|]
\]</span> denote the start value error neighborhood around <span class="math inline">\(\theta_{root}.\)</span></p>
<p>One can shown that if <span class="math inline">\(\ell_n'\)</span> is “well behaved” over <span class="math inline">\(I;\)</span> i.e.&nbsp;</p>
<ul>
<li>if <span class="math inline">\(\ell_n''(\theta)\neq 0\)</span> for all <span class="math inline">\(\theta\in I\)</span> and</li>
<li>if <span class="math inline">\(\ell_n'''(\theta)\)</span> is finite and continuous for all <span class="math inline">\(\theta\in I,\)</span></li>
</ul>
<p>and if our first guess <span class="math inline">\(\theta_{(0)}\)</span> is “close enough;” i.e.&nbsp;</p>
<ul>
<li>if <span class="math inline">\(M|e_{(0)}|&lt;1,\)</span> where <span class="math display">\[
M=\frac{1}{2}\left(\sup_{\theta\in I}|\ell_n'''(\theta)|\right)\left(\sup_{\theta\in I}\frac{1}{|\ell_n''(\theta)|}\right)\geq 0,
\]</span></li>
</ul>
<p>then <span class="math inline">\(\theta_{(m)}\)</span> will converge to <span class="math inline">\(\theta_{root}\)</span> as <span class="math inline">\(m\to\infty.\)</span></p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Unfortunately, we typically don’t know if <span class="math inline">\(\ell_n'\)</span> is “well behaved” and we usually don’t know whether our first guess is “close enough”. So, typically we cannot guarantee convergence of the Newton-Raphson algorithm. 😭 <!-- Exercise: Let this be proofen: https://en.wikipedia.org/wiki/Newton%27s_method --></p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>For problems that are globally concave, the starting value <span class="math inline">\(\theta_0\)</span> doesn’t matter. For more complex problems, however, the Newton-Raphson algorithm can get stuck into a local maximum. In such cases, it is usually a good idea to <strong>try multiple starting values</strong>.</p></li>
<li><p>In practice, the implementation of the Newton-Raphson algorithm can be tricky. We may have <span class="math inline">\(\ell_n''(\theta_{(m)})=0,\)</span> in which case the function looks locally like a straight line, with no solution to the Taylor series approximation <span class="math display">\[
\begin{align*}
\ell_n'(\theta_{(m)} + h) &amp; \approx \ell_n'(\theta_{(m)}) + \ell_n''(\theta_{(m)})h = \ell_n'(\theta_{(m)}).
\end{align*}
\]</span> In this case a simple strategy is to move a small step in the direction which decreases the function value, based only on <span class="math inline">\(\ell_n'(\theta_m).\)</span></p></li>
<li><p>In other cases where <span class="math inline">\(\theta_{(m)}\)</span> is too far from the true root <span class="math inline">\(\theta_{root}\)</span>, the Taylor approximation may be so inaccurate that <span class="math inline">\(\ell_n(\theta_{(m+1)})\)</span> is actually <em>more distant</em> from zero than <span class="math inline">\(\ell_n(\theta_{(m)}).\)</span> When this happens one may replace <span class="math inline">\(\theta_{(m+1)}\)</span> with <span class="math inline">\((\theta_{(m+1)}+\theta_{(m)})/2\)</span> (or some other value between <span class="math inline">\(\theta_{(m)}\)</span> and <span class="math inline">\(\theta_{(m+1)}\)</span>) in the hope that a smaller step will produce a better result.</p></li>
</ul>
</div>
</div>
<p><strong>Stopping Criterion:</strong> Since we are expecting that <span class="math inline">\(\ell_n'(\theta_{(m)})\to 0,\)</span> as <span class="math inline">\(m\to\infty,\)</span> a good stopping condition for the Newton-Raphson algorithm is <span class="math display">\[
|\ell_n'(\theta_{(m)})|\leq \varepsilon
\]</span> for some (small) tolerance <span class="math inline">\(\varepsilon&gt;0.\)</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pseudo-Code: Newton-Raphson Algorithm
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{array}{ll}
\texttt{\textbf{select }} \theta_{(0)}\in\Theta\;\;\text{ and}&amp;\varepsilon&gt;0 \\[2ex]
\texttt{\textbf{let }} m=0         &amp;  \\
\texttt{\textbf{while }}  | \ell_n'(\theta_{(m)}) | &gt;\varepsilon &amp; \texttt{\textbf{do}}\\
&amp;\left[
                                    \begin{array}{l}\texttt{\textbf{let }} m = m+1 \\
                                    \texttt{\textbf{let }} \theta_{(m)} = \theta_{(m-1)} - \frac{\ell_n'(\theta_{(m-1)})}{\ell_n''(\theta_{(m-1)})} \\
                                    \end{array} \right.\\
\texttt{\textbf{let }}\hat\theta_{ML}=\theta_{(m)} &amp; \\
\texttt{\textbf{return }} \hat\theta_{ML} &amp;  \\
\end{array}
\]</span></p>
</div>
</div>
</section>
<section id="newton-raphson-algorithm-coin-flipping-example" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="newton-raphson-algorithm-coin-flipping-example"><span class="header-section-number">1.2.3</span> Newton-Raphson Algorithm: Coin-Flipping Example</h3>
<p>Let’s return to our earlier coin flipping example.</p>
<p>If we observe, for instance, only one head <span class="math inline">\(N_{H,obs}=1\)</span> for a sample size of <span class="math inline">\(n=5,\)</span> we already know from <a href="#eq-MLECoinFlipp" class="quarto-xref">Equation&nbsp;<span>1.1</span></a> that <span class="math display">\[
\hat\theta_{ML}=\frac{N_{H,obs}}{n}=\frac{1}{5}=0.2,
\]</span> but let us, nevertheless, apply the Newton-Raphson algorithm.</p>
<p>The first and second derivatives of <span class="math display">\[
\ell_{n,obs}(\theta)=\sum_{i=1}^n\big(X_{i,obs} \ln(\theta) + (1-X_{i,obs})\ln(1-\theta)\big)
\]</span> are <span class="math display">\[
\begin{align*}
\ell_{n,obs}'(\theta)&amp;=\dfrac{N_{H,obs}}{\theta} - \dfrac{n-N_{H,obs}}{1-\theta} \\[2ex]
\ell_{n,obs}''(\theta) &amp;= -\dfrac{N_{H,obs}}{\theta^2} + \dfrac{n}{(1-\theta)^2}(-1)-\dfrac{N_{H,obs}}{(1-\theta)^2}(-1)\\[2ex]
&amp;= -\dfrac{N_{H,obs}}{\theta^2} - \dfrac{n-N_{H,obs}}{(1-\theta)^2}.
\end{align*}
\]</span></p>
<p>We consider a sample size of <span class="math inline">\(n=5\)</span> with the following observed outcome:</p>
<ul>
<li>One Head: <span class="math inline">\(\quad N_{H,obs}=1\)</span></li>
<li>Four Tails: <span class="math inline">\(\quad n-N_{H,obs}=4\)</span></li>
</ul>
<p>Setting <span class="math inline">\(\varepsilon=10^{-10}\)</span> as our stopping criterion and <span class="math inline">\(\theta_{(0)}=0.4\)</span> as our starting value allows us to run the Newton-Raphson algorithm which gives us the results shown in <a href="#tbl-NR" class="quarto-xref">Table&nbsp;<span>1.1</span></a>. The numeric optimization solution is <span class="math inline">\(\hat\theta_{ML} = 0.2\)</span> which equals the analytic solution.</p>
<div id="tbl-NR" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-NR-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1.1: Result of applying the Newton Raphson optimization algorithm to our coin flipping example for given data with <span class="math inline">\(N_{H,obs}=1,\)</span> sample size <span class="math inline">\(n=5,\)</span> starting value <span class="math inline">\(\theta_{(0)}=0.4,\)</span> and convergence criterion <span class="math inline">\(\varepsilon=10^{-10}.\)</span>
</figcaption>
<div aria-describedby="tbl-NR-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 25%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th><span class="math inline">\(m\)</span></th>
<th><span class="math inline">\(\hat\theta_{(m)}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(h_{{(m)}}=\frac{-\ell_{n,obs}'(\hat\theta_{(m)})}{\ell_{n,obs}''(\hat\theta_{(m)})}\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\ell_{n,obs}'(\hat\theta_{(m)})\gtrless \varepsilon\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(0\)</span></td>
<td><span class="math inline">\(0.40\)</span></td>
<td style="text-align: center;"><span class="math inline">\(-2.4\cdot 10^{-1}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{red}-4.2 &gt; \varepsilon}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(0.16\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phantom{-}3.3\cdot 10^{-2}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{red}\phantom{-}1.5 &gt; \varepsilon}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(2\)</span></td>
<td><span class="math inline">\(0.19\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phantom{-}6.6\cdot 10^{-3}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{red}\phantom{-}2.2\cdot 10^{-1} &gt; \varepsilon}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(3\)</span></td>
<td><span class="math inline">\(0.19\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phantom{-}1.7\cdot 10^{-4}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{red}\phantom{-}5.4\cdot 10^{-3} &gt; \varepsilon}\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(4\)</span></td>
<td><span class="math inline">\(0.19\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phantom{-}1.1\cdot 10^{-7}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{red}\phantom{-}3.5\cdot 10^{-6} &gt; \varepsilon}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(5\)</span></td>
<td><span class="math inline">\(0.20\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\phantom{-}4.8\cdot 10^{-14}\)</span></td>
<td style="text-align: right;"><span class="math inline">\({\color{darkgreen}\phantom{-}1.5\cdot 10^{-12} &lt; \varepsilon}\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="sec-LinRegNorm" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="sec-LinRegNorm"><span class="header-section-number">1.3</span> Linear Regression under Normality</h2>
<p>Now, let’s return to the linear regression model <span id="eq-LinMod"><span class="math display">\[
Y_i=X_i^T\beta_0 + \varepsilon_i,\quad  i=1,\dots,n,
\tag{1.2}\]</span></span> where <span class="math inline">\(Y_i\in\mathbb{R}\)</span> denotes the response (or “dependent”) variable, <span class="math display">\[
\beta_0\in\mathbb{R}^K
\]</span> denotes the vector of unknown slope parameters, and <span class="math display">\[
X_i:=(\underbrace{X_{i1}}_{=1},X_{i2},\ldots,X_{ip})^T\in\mathbb{R}^K
\]</span> denotes the vector of predictor variables, where the (i.i.d.) random sample<br>
<span class="math display">\[
(Y_1,X_1), (Y_2,X_2), \dots, (Y_n,X_n)
\]</span> follows a <strong>random design with homoskedastic errors</strong> (see <a href="#def-RandomDesign" class="quarto-xref">Definition&nbsp;<span>1.3</span></a>).</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-RandomDesign" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.3 (Random Design (Regression Analysis))</strong></span> <br></p>
<p>A <strong>random desgin</strong> in regression analysis is given by the following setup:</p>
<p>Let <span class="math display">\[
(Y_1,X_1), (Y_2,X_2), \dots, (Y_n,X_n)
\]</span> or equivalently <span class="math display">\[
(X_1,\varepsilon_1), (X_2,\varepsilon_2), \dots, (X_n,\varepsilon_n)
\]</span> denote a (i.i.d.) random sample with <span class="math inline">\(\mathbb{E}(\varepsilon_i|X_i)=0\)</span>, intertable <span class="math inline">\((K\times K)\)</span> matrix <span class="math inline">\(\mathbb{E}(X_iX_i^T)=\Sigma_{X^TX}\)</span>, <span class="math inline">\(i=1,\dots,n,\)</span> and with either</p>
<ul>
<li><strong>homoskedastic</strong> errors: <span class="math inline">\(0&lt;\mathbb{E}(\varepsilon_i^2|X_i)=\sigma^2_0&lt;\infty\)</span></li>
</ul>
<p>or</p>
<ul>
<li><strong>heteroskedastic</strong> errors: <span class="math inline">\(0&lt;\mathbb{E}(\varepsilon_i^2|X_i)=\sigma^2_0(X_i)&lt;\infty\)</span>, for a strictly positive and finite variance function <span class="math inline">\(\sigma^2_0(\cdot).\)</span></li>
</ul>
</div>
</div>
</div>
</div>
<p>For the following, it is convenient to write <a href="#eq-LinMod" class="quarto-xref">Equation&nbsp;<span>1.2</span></a> using matrix notation <span class="math display">\[
\begin{eqnarray*}
  \underset{(n\times 1)}{Y}&amp;=&amp;\underset{(n\times K)}{X}\underset{(K\times 1)}{\beta_0} + \underset{(n\times 1)}{\varepsilon},
\end{eqnarray*}
\]</span> where <span class="math display">\[
\begin{equation*}
Y=\left(\begin{matrix}Y_1\\ \vdots\\Y_n\end{matrix}\right),\quad X=\left(\begin{matrix}X_{11}&amp;\dots&amp;X_{1K}\\\vdots&amp;\ddots&amp;\vdots\\ X_{n1}&amp;\dots&amp;X_{nK}\\\end{matrix}\right),\quad\text{and}\quad \varepsilon=\left(\begin{matrix}\varepsilon_1\\ \vdots\\ \varepsilon_n\end{matrix}\right).
\end{equation*}
\]</span></p>
<p>Under <strong>normally distributed and homoskedastic</strong> error terms, <span class="math inline">\(\varepsilon_i,\)</span> we have that <span class="math display">\[
\begin{align}
\underset{(n\times 1)}{\varepsilon} &amp;\sim \mathcal{N}_n\left(0, \sigma_0^2I_n\right)\\[2ex]
\Rightarrow\quad
(Y-X\beta_0)|X &amp;\sim \mathcal{N}_n\left(0, \sigma^2_0I_n\right).
\end{align}
\]</span> That is, for each <span class="math inline">\(i=1,\dots,n,\)</span> we have that <span id="eq-OLSnormAss"><span class="math display">\[
\begin{align}
(Y_i-X_i^T\beta_0)|X_i &amp;\sim \mathcal{N}\left(0, \sigma^2_0\right)\\[2ex]
\Rightarrow\quad
Y_i|X_i &amp;\sim \mathcal{N}\left(X_i^T\beta_0, \sigma^2_0\right)
\end{align}
\tag{1.3}\]</span></span></p>
<!-- We could also choose another distributional assumption for $\varepsilon,$ but the classical ML estimation theory requires us to assumed the correct error distribution. Luckily, the quasi maximum likelihood theory of @White1982 shows that false distributional assumptions are typically not problematic. -->
<!-- ::: {.callout-note}
The requirement to make a (correct) distributional assumption is much more restrictive than requirements for analyzing the OLS estimator under standard large sample inference. However, taking into account specific distributional assumptions allows us to consider also more complicated non-linear regression models such as, for instance, logistic regression. 
:::pe -->
<!-- \begin{itemize} -->
<!-- \item The $\varepsilon$'s are jointly normally distributed. -->
<!-- \item The $\varepsilon$'s are independent of one another. -->
<!-- \item The $\varepsilon$'s are identically distributed, i.e. homoskedastic. -->
<!-- \end{itemize} -->
<p>Under <a href="#eq-OLSnormAss" class="quarto-xref">Equation&nbsp;<span>1.3</span></a>, we have <span class="math display">\[
f(Y_i|X_i;\beta_0^T,\sigma_0^2)=
\frac{1}{(2\pi\sigma^2)^{1/2}}\exp\left(-\frac{(Y_i-X_i^T\beta_0)^2}{2\sigma_0^2}\right),
\]</span> where <span class="math display">\[
\theta_0=(\beta_0^T,\sigma_0^2)^T\in\mathbb{R}^K\times\mathbb{R}_{&gt;0}
\]</span> denotes the <span class="math inline">\(((K+1)\times 1)\)</span> dimensional unknown parameter vector.</p>
<p>This allows us to setup the likelihood function, <span class="math display">\[
\begin{align*}
\mathcal{L}_n(\beta^T,\sigma^2)
&amp; =\prod_{i=1}^n f(Y_i|X_i;\beta^T,\sigma^2)\\[2ex]
&amp; =\prod_{i=1}^n \frac{1}{(2\pi\sigma^2)^{1/2}}\exp\left(-\frac{(Y_i-X_i^T\beta)^2}{2\sigma^2}\right)\\[2ex]
&amp; =\left(\frac{1}{(2\pi\sigma^2)^{1/2}}\right)^{n}\exp\left(-\frac{\sum_{i=1}^n (Y_i-X_i^T\beta)^2}{2\sigma^2}\right)\\[2ex]
%&amp; =\dfrac{1}{(2\pi \sigma^2)^{n/2}} \exp\left(-\frac{\varepsilon'\varepsilon}{2\sigma^2}\right)\\[2ex]
&amp; =(2\pi)^{-n/2} \cdot (\sigma^2)^{-n/2}\cdot  \exp\left(-\frac{(Y-X\beta)^T(Y-X\beta)}{2\sigma^2}\right),\\[2ex]
\end{align*}
\]</span> <!-- The multivariate density for $\varepsilon=(\varepsilon_1,\dots,\varepsilon_n)^T$ is then
$$
\begin{equation*}
f(\varepsilon)=\dfrac{1}{(2\pi \sigma^2)^{n/2}} \exp\left(-\frac{\varepsilon'\varepsilon}{2\sigma^2}\right).
\end{equation*}
$$ --> <!-- Noting that $\varepsilon=Y-X\beta$, we get the  --> and the log-likelihood function, <span class="math display">\[
\begin{align*}
\ell_n(\beta^T,\sigma^2)&amp; =-\dfrac{n}{2} \ln(2\pi) - \dfrac{n}{2}\ln(\sigma^2) - \dfrac{1}{2 \sigma^2}(Y-X\beta)^T(Y-X\beta).
\end{align*}
\]</span> <!-- with $K+1$ unknown parameters: 

* $\beta=(\beta_1,\dots,\beta_K)^T\in\mathbb{R}^K$ and 
* $\sigma^2\in\mathbb{R}_{>0}.$ --></p>
<p>Taking first derivatives gives <span class="math display">\[
\begin{align*}
\underset{(K\times 1)}{\dfrac{\partial \ell_n}{\partial \beta}(\beta^T,\sigma^2)}    
&amp;= - \dfrac{1}{\sigma^2}(-X^TY + X^TX\beta)\\[2ex]
\underset{(1\times 1)}{\dfrac{\partial \ell_n}{\partial \sigma^2}(\beta^T,\sigma^2)}
%&amp;= -\dfrac{n}{2\sigma^2}+ \dfrac{1}{2\sigma^4}(Y-X\beta)^T(Y-X\beta)
&amp;=-\frac{n}{2 \sigma^{2}}+\left[\frac{1}{2}(Y-X\beta)^T(Y-X\beta)\right]\frac{1}{\left(\sigma^{2}\right)^{2}}\\
%&amp;=\frac{1}{2 \sigma^{2}}\left[\frac{1}{\sigma^{2}} (Y-X\beta)^T(Y-X\beta)-n\right]
\end{align*}
\]</span> Putting the above derivative functions into one column vector yields the <span class="math inline">\(((K+1)\times 1)\)</span>-dimensional <strong>gradient</strong> called <strong>score function</strong> in ML-theory: <span id="eq-LinRegScoreFun"><span class="math display">\[
\nabla\ell_n(\theta^T)=
\left(\begin{matrix}
\dfrac{\partial \ell_n}{\partial \beta}(\beta^T,\sigma^2)\\
\dfrac{\partial \ell_n}{\partial \sigma^2}(\beta^T,\sigma^2)
\end{matrix}\right)
\tag{1.4}\]</span></span></p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-ScoreFunction" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.4 (Score Function)</strong></span> More generally, let <span class="math inline">\(\ell_n(\theta)\)</span> denote the log-likelihood function evaluated at a <span class="math inline">\(p\)</span>-dimensional parameter vector <span class="math inline">\(\theta=(\theta_1,\dots,\theta_p)^T.\)</span></p>
<p>Then the <span class="math inline">\((p\times 1)\)</span> dimensional gradient <span class="math display">\[
\nabla\ell_n(\theta^T)=\left(\begin{matrix}
  \dfrac{\partial \ell_n}{\partial \theta_1}(\theta^T)\\ \vdots\\
  \dfrac{\partial \ell_n}{\partial \theta_p}(\theta^T)
  \end{matrix}
  \right)
\]</span> is called the <strong>score-function</strong>.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The score function is <strong>random</strong>, since it depends on the random sample. For a given set of observed data, we compute one realization of the score function.</p>
<p>At the <strong>true parameter</strong> vector <span class="math inline">\(\theta_0\in\mathbb{R}^p,\)</span> the score function satisfies <span class="math display">\[
\mathbb{E}\left(\dfrac{\partial \ell_n}{\partial \theta_j}(\theta_0')\right)=0
\]</span> for all <span class="math inline">\(j=1,\dots,p;\)</span> i.e.&nbsp; <span class="math display">\[
\mathbb{E}\left(\nabla\ell_n(\theta^T)\right)=\left(\begin{matrix}
  \mathbb{E}\left(\dfrac{\partial \ell_n}{\partial \theta_1}(\theta^T)\right)\\ \vdots\\
  \mathbb{E}\left(\dfrac{\partial \ell_n}{\partial \theta_p}(\theta^T)\right)
  \end{matrix}
  \right) = \underset{(p\times 1)}{0}
\]</span> We prove this below in <a href="#sec-MLAsymp" class="quarto-xref"><span>Section 1.4</span></a>.</p>
</div>
</div>
<p>Setting the score function in <a href="#eq-LinRegScoreFun" class="quarto-xref">Equation&nbsp;<span>1.4</span></a> equal to zero yields a system of <span class="math inline">\(K+1\)</span> equations with <span class="math inline">\(K+1\)</span> unknowns, which identifies the ML-estimators, <span class="math display">\[
\begin{align*}
&amp;\nabla\ell_n(\hat\theta^T_{ML})
=
\left(\begin{matrix}
\dfrac{\partial \ell_n}{\partial \beta}(\hat\beta^T_{ML},s_{ML}^2)\\
\dfrac{\partial \ell_n}{\partial \sigma^2}(\hat\beta^T_{ML},s_{ML}^2),
\end{matrix}\right)=\\[2ex]
&amp;=
\left(\begin{matrix}
- \dfrac{1}{s_{ML}^2}(-X^TY + X^TX\hat\beta_{ML})\\
-\frac{n}{2 s_{ML}^2}+\left[\frac{1}{2}(Y-X\hat\beta_{ML})^T(Y-X\hat\beta_{ML})\right]\frac{1}{\left(s_{ML}^2\right)^{2}}
\end{matrix}\right)
\overset{!}{=} \underset{((K+1)\times 1)}{0}
\end{align*}
\]</span> and which we can solve for the maximum likelihood estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML}.\)</span></p>
<p>Solving for <span class="math inline">\(\hat\beta_{ML}:\)</span> <span class="math display">\[
\begin{align*}
%&amp; \dfrac{\partial \ell_n}{\partial \beta}(\hat\beta_{ML}',s^2_{ML}) \overset{!}{=}0\\[2ex]\Leftrightarrow\quad
&amp; - \dfrac{1}{s_{ML}^2}(-X^TY + X^TX\hat\beta_{ML})  \overset{!}{=}0\\[2ex]
\Rightarrow\quad &amp; \hat\beta_{ML}=(X^TX)^{-1}X^TY\\[2ex]
\end{align*}
\]</span> Solving for <span class="math inline">\(s^2_{ML}:\)</span> <span class="math display">\[
\begin{align*}
%&amp; \dfrac{\partial \ell_n}{\partial \sigma^2}(\hat\beta_{ML}',s^2_{ML}) \overset{!}{=}0\\[2ex]\Leftrightarrow\quad
&amp;-\frac{n}{2 s_{ML}^2}+\left[\frac{1}{2}(Y-X\hat\beta_{ML})^T(Y-X\hat\beta_{ML})\right]\frac{1}{\left(s_{ML}^2\right)^{2}}  \overset{!}{=}0\ \\[2ex]
\Rightarrow\quad  &amp;
s_{ML}^2 =\dfrac{1}{n}(Y-X\hat\beta_{ML})^T(Y-X\hat\beta_{ML})\\[2ex]
&amp;\phantom{s_{ML}^2}=\dfrac{1}{n}\sum_i^n \hat\varepsilon_i^2,
\end{align*}
\]</span> where <span class="math inline">\(\hat\varepsilon_i = Y_i - X_i^T\hat{\beta}_{ML}.\)</span></p>
<p><strong>Observations:</strong></p>
<ul>
<li><p><span class="math inline">\(\hat\beta_{ML}\)</span> equals the OLS estimator <span class="math inline">\(\hat\beta=(X^TX)^{-1}X^TY.\)</span> <br> Since the ML estimator <span class="math inline">\(\hat\beta_{ML}\)</span> is here equivalent to the OLS estimator we can use the classic inference machinery (<span class="math inline">\(t\)</span>-test, <span class="math inline">\(F\)</span>-test, confidence intervals) developed for the classic OLS estimator (see your econometrics class).</p></li>
<li><p><span class="math inline">\(s_{ML}^2\)</span> differs from the unbiased variance estimator <span class="math inline">\(s_{UB}^2=\frac{1}{n-K}\hat{\varepsilon}_i^2.\)</span></p></li>
</ul>
<section id="sec-varMLE" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="sec-varMLE"><span class="header-section-number">1.3.1</span> Variance of ML-Estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML}\)</span></h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Computing the Asymptotic Variance
</div>
</div>
<div class="callout-body-container callout-body">
<p>To compute the <strong>asymptotic variance</strong> of the ML-estimators <span class="math inline">\(\hat\beta_{ML}\)</span> and <span class="math inline">\(s^2_{ML},\)</span> we need to</p>
<ol type="1">
<li>compute the Hessian matrix (i.e.&nbsp;all second partial derivatives) of <span class="math inline">\(\ell_n,\)</span><br>
</li>
<li>take the expectation of this Hessian matrix and multiply it by <span class="math inline">\(-1/n\)</span>, which gives us the <strong>Fisher Information matrix</strong>.</li>
<li>Inverting the Fisher information matrix give the <strong>asymptotic variance</strong> expression.</li>
</ol>
</div>
</div>
<p>Let’s do this preliminary work in the following:</p>
<ul>
<li><p>Partial second derivatives with respect to <span class="math inline">\(\beta:\)</span> <span class="math display">\[
\begin{align*}
\underset{(K\times 1)}{\dfrac{\partial \ell_n}{\partial \beta}(\beta^T,\sigma^2)}    
&amp;= - \dfrac{1}{\sigma^2}(-X^TY + X^TX\beta)\\[2ex]
\Rightarrow\quad
\underset{(K\times K)}{\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta^T}(\beta^T,\sigma^2)}
&amp;= - \dfrac{1}{\sigma^2}(X^TX)
\end{align*}
\]</span> <span class="math display">\[
\begin{align*}
\Rightarrow\quad
&amp;-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta^T}(\beta^T,\sigma^2)\right)\\[2ex]
&amp;=  -\frac{1}{n}\cdot \left(-\dfrac{1}{\sigma^2} \mathbb{E}(X^TX)\right)\\[2ex]
&amp;=  -\frac{1}{n}\cdot \left(-\dfrac{n}{\sigma^2} \Sigma_{X^TX}\right)\\[2ex]
&amp;=  \dfrac{1}{\sigma^2} \Sigma_{X^TX},
\end{align*}
\]</span> where<br>
<span class="math display">\[
\mathbb{E}\left(X^TX\right)
=\mathbb{E}\left(\sum_{i=1}^nX_iX_i^T\right)
=n\underbrace{\mathbb{E}\left(X_iX_i^T\right)}_{=:\Sigma_{X^TX}} = n\Sigma_{X^TX}.
\]</span></p></li>
<li><p>Second derivative with respect to <span class="math inline">\(\sigma^2:\)</span> <span class="math display">\[
\begin{align*}
\underset{(1\times 1)}{\dfrac{\partial \ell_n}{\partial \sigma^2}(\beta^T,\sigma^2)}
&amp;=-\frac{n}{2 \sigma^{2}}+\frac{1}{2}\frac{(Y-X\beta)^T(Y-X\beta)}{\left(\sigma^{2}\right)^{2}}\\[2ex]
\Rightarrow\quad\underset{(1\times 1)}{\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta^T,\sigma^2)}
&amp;=\frac{n}{2 \left(\sigma^{2}\right)^2}-\dfrac{(Y-X\beta)^T(Y-X\beta)}{\left(\sigma^{2}\right)^{3}} \\[2ex]
&amp;=\frac{n}{2\sigma^{4}}-\frac{\sum_{i=1}^n\varepsilon_i^2}{\sigma^{6}} \\[2ex]
\end{align*}
\]</span> <span class="math display">\[
\begin{align*}
\Rightarrow\quad
&amp;-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta^T,\sigma^2)\right)\\[2ex]
&amp;=-\frac{1}{n}\cdot \left(\frac{n}{2\sigma^{4}}-\frac{\mathbb{E}\left(\sum_{i=1}^n\varepsilon_i^2\right)}{\sigma^{6}} \right)\\[2ex]
&amp;=-\frac{1}{n}\cdot \left(\frac{n}{2\sigma^{4}}-\frac{n\sigma^2}{\sigma^{6}}\right)\\[2ex]
&amp;=\left(-\frac{1}{2\sigma^{4}}+\frac{1}{\sigma^{4}}\right)\\[2ex]
&amp;=\frac{1}{2\sigma^{4}}\\[2ex]
\end{align*}
\]</span></p></li>
<li><p>First derivative with respect to <span class="math inline">\(\beta,\)</span> second derivative with respect to <span class="math inline">\(\sigma^2:\)</span> <span class="math display">\[
\begin{align*}
\underset{(K\times 1)}{\dfrac{\partial \ell_n}{\partial \beta}(\beta^T,\sigma^2)}    
&amp;= - \dfrac{1}{\sigma^2}(-X^TY + X^TX\beta)\\[2ex]
&amp;= \dfrac{1}{\sigma^2}(X^T)(Y - X\beta)\\[2ex]
&amp;= \dfrac{1}{\sigma^2}X^T\varepsilon\\[2ex]
\end{align*}
\]</span></p></li>
</ul>
<p><span class="math display">\[
\begin{align*}
\Rightarrow\quad
\underset{(K\times 1)}{\dfrac{\partial^2 \ell_n}{\partial \beta \partial \sigma^2}(\beta^T,\sigma^2)}
=   \left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta^T}(\beta^T,\sigma^2)\right)^T
&amp; = -\frac{X^T\varepsilon}{\sigma^4}\\
\end{align*}
\]</span> <span class="math display">\[
\begin{align*}
\Rightarrow\quad
&amp;-\frac{1}{n}\cdot  \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \sigma^2}(\beta^T,\sigma^2)\right)\\[2ex]
&amp;=-\frac{1}{n}\cdot\left(\mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta^T,\sigma^2)\right)\right)^T\\[2ex]
&amp;=\frac{1}{n}\cdot\frac{\mathbb{E}(X^T\varepsilon)}{\sigma^4}\\[2ex]
&amp;=\frac{1}{n}\cdot\frac{\mathbb{E}(\mathbb{E}(X^T\varepsilon|X))}{\sigma^4}\\[2ex]
&amp;=\frac{1}{n}\cdot\frac{\mathbb{E}(X^T\mathbb{E}(\varepsilon|X))}{\sigma^4}\\[2ex]
&amp;=\frac{1}{n}\cdot 0=0,
\end{align*}
\]</span> since <span class="math inline">\(\mathbb{E}(\varepsilon|X)=0\)</span> is an <span class="math inline">\((n\times 1)\)</span> zero vector.</p>
<p>Collecting the above results, allows us to write down the expression for <span class="math inline">\((-1/n)\)</span> times the expectation of the <strong>Hessian matrix</strong> of <span class="math inline">\(\ell_n\)</span> which yields the <strong>Fisher Information (Matrix):</strong></p>
<p><span class="math display">\[
\begin{align*}
&amp;\mathcal{I}(\theta) :=\; -\frac{1}{n}\cdot\mathbb{E}\left(H_{\ell_n}(\beta^T,\sigma^2)\right)\\[2ex]
&amp;=
-\frac{1}{n}\cdot \mathbb{E}
\left[\begin{array}{cc}
\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta^T}(\beta^T,\sigma^2)\right) &amp;
\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \sigma^2 }(\beta^T,\sigma^2)\right)\\
\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta^T}(\beta^T,\sigma^2)\right) &amp;
\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta^T,\sigma^2) \right)
\end{array}\right]\\[2ex]
&amp;=\left[\begin{array}{cc}
\underset{(K\times K)}{\frac{1}{\sigma^2}\Sigma_{X^TX}}
&amp;
\underset{(K\times 1)}{0}\\
\underset{(1\times K)}{0} &amp;
\underset{(1\times 1)}{\frac{1}{2\sigma^4}}
\end{array}\right]
\end{align*}
\]</span></p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="def-FisherInformMat" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1.5 (Fisher Information Matrix)</strong></span> The matrix <span class="math display">\[
\mathcal{I}(\theta) := -\frac{1}{n}\cdot\mathbb{E}\left(H_{\ell_n}(\theta)\right)
\]</span> is called <strong>Fisher Information Matrix</strong>.</p>
</div>
</div>
</div>
</div>
<section id="asymptotic-variance-and-fisher-information-matrix" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="asymptotic-variance-and-fisher-information-matrix"><strong>Asymptotic Variance and Fisher Information Matrix</strong></h4>
<p>The asymptotic variance of the MLE <span class="math display">\[
\hat{\theta}_{ML}=\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)
\]</span> is given by the <strong>inverse of the Fisher information matrix</strong> evaluated at the true parameter values <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\sigma^2_0.\)</span> <span class="math display">\[
\begin{align*}
&amp;AVar\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)
=\lim_{n\to\infty} n Var\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)\\[2ex]
&amp;=\left(\mathcal{I}(\beta^T_0,\sigma^2_0)\right)^{-1}\\[2ex]
&amp;=\left(-\frac{1}{n}\cdot\mathbb{E}\left(H_{\ell_n}(\beta^T_0,\sigma^2_0)\right)\right)^{-1}\\[2ex]
&amp;=
\left[\begin{array}{cc}
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta^T}(\beta^T_0,\sigma^2_0)\right) &amp;
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \sigma^2}(\beta^T_0,\sigma^2_0)\right)\\
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta^T}(\beta^T_0,\sigma^2_0)\right) &amp;
-\frac{1}{n}\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta^T_0,\sigma^2_0) \right)
\end{array}\right]^{-1}\\[2ex]
&amp;=\left[\begin{array}{cc}
\underset{(K\times K)}{\frac{1}{\sigma^2_0}\Sigma_{X^TX}}
&amp;
\underset{(K\times 1)}{0}\\
\underset{(1\times K)}{0} &amp;
\underset{(1\times 1)}{\frac{1}{2\sigma^4_0}}
\end{array}\right]^{-1}\\[2ex]
&amp;=\left[\begin{array}{cc}
\underset{(K\times K)}{\sigma^2_0\Sigma_{X^TX}^{-1}}
&amp;
\underset{(K\times 1)}{0}\\
\underset{(1\times K)}{0} &amp;
\underset{(1\times 1)}{2\sigma^4_0}
\end{array}\right]
\end{align*}
\]</span></p>
<!-- where $\mathcal{I}(\beta^T,\sigma^2)$ is called the **Fisher information matrix**. 

From our above derivations we know that
$$
\begin{align*}
&\mathcal{I}\left(\beta, \sigma^2\right)\\[2ex]
&=
\left[\begin{array}{cc}
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \beta\partial \beta^T}(\beta^T,\sigma^2)\right) & 
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta^T,\sigma^2)\right)\\
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2 \partial \beta}(\beta^T,\sigma^2)\right) & 
(-1)\cdot \mathbb{E}\left(\dfrac{\partial^2 \ell_n}{\partial \sigma^2\partial \sigma^2}(\beta^T,\sigma^2) \right)
\end{array}\right]\\[2ex]
% &=
% \left[\begin{array}{cc}
% \frac{1}{\sigma^2}E(X^TX) & 0 \\
% 0 & \frac{n}{2\sigma^4}
% \end{array}\right]\\[2ex]
&=
\left[\begin{array}{cc}
\dfrac{n}{\sigma^2}\Sigma_{X^TX} & 0 \\[2ex]
0 & \ \dfrac{n}{2\sigma^4}
\end{array}\right],
\end{align*}
$$ -->
<p>That is, <span id="eq-FIMVar"><span class="math display">\[
\begin{align*}
AVar\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)
&amp;=\lim_{n\to\infty} n Var\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right)\\[2ex]
&amp;=
\left[\begin{array}{cc}
\sigma^2_0\Sigma_{X^TX}^{-1} &amp; 0 \\[2ex]
0 &amp; \ 2\sigma^4_0
\end{array}\right].
\end{align*}
\tag{1.5}\]</span></span></p>
<!-- While the upper left element of the Fisher information matrix is easily seen, the derivation of the lower right element is rather tedious and thus omitted.
[^1]: See [https://www.statlect.com/fundamentals-of-statistics/linear-regression-maximum-likelihood](https://www.statlect.com/fundamentals-of-statistics/linear-regression-maximum-likelihood) for more details. -->
<!-- Taking the inverse of the Fisher information matrix $\mathcal{I}\left(\beta, \sigma^2\right)$ gives the variance-covariance matrix of the vector of estimators $(\hat\beta_{ML}, s_{ML}^2)$
$$
\begin{align*}
Var\left(\begin{array}{c}\hat\beta_{ML} \\ s_{ML}^2\end{array}\right) 
& \approx \left(\mathcal{I}\left(\beta, \sigma^2\right)\right)^{-1}\\[2ex]
& =
\left[\begin{array}{cc}
\dfrac{\sigma^2}{n}\Sigma_{X^TX}^{-1} & 0 \\
0 & \ \dfrac{2\sigma^4}{n}
\end{array}\right],
\end{align*}
$${#eq-FIMVar}
where the approximation error becomes small as $n\to\infty.$ That is, 
$$
n Var\left(\hat\beta_{ML}\right) \to \sigma^2\Sigma_{X^TX}^{-1}\quad\text{as}\quad n\to\infty,
$$
and
$$
n Var\left(s_{ML}^2\right) \to 2\sigma^4\quad\text{as}\quad n\to\infty.
$$


Given this result, it is easy to see that 
$$
Var(\hat\beta_{ML}) \to 0\quad\text{and}\quad Var(s_{ML}^2) \to 0
$$ 
as $n\to\infty$. -->
<p>Of course, the variance expressions in <a href="#eq-FIMVar" class="quarto-xref">Equation&nbsp;<span>1.5</span></a> contain unknown quantities and thus are not directly usable in practice. However, we can plug in estimates of the unknown quantities; namely <span class="math display">\[
s_{ML}^2                         \quad\text{for}\quad \sigma^2_0
\]</span> and <span class="math display">\[
S_{X^TX}^{-1}=\left(\frac{1}{n}\sum_{i=1}^nX_i X_i^T\right)^{-1} \quad \text{for}\quad \Sigma_{X^TX}^{-1}.
\]</span></p>
<p>This leads to estimators of the asymptotic variances of <span class="math inline">\(\hat{\beta}_{ML}\)</span> and <span class="math inline">\(s_{ML}^2:\)</span> <span class="math display">\[
\begin{align}
\widehat{AVar}(\hat{\beta}_{ML})
&amp;=s_{ML}^2 S_{X^TX}^{-1}\\[2ex]
&amp;=s_{ML}^2 \left(\frac{1}{n}\sum_{i=1}^nX_i X_i^T\right)^{-1}\\[2ex]
\widehat{AVar}(s^2_{ML})
&amp;=2\left(s_{ML}^2\right)^2
\end{align}
\]</span> and thus to estimators of the variances of <span class="math inline">\(\hat{\beta}_{ML}\)</span> and <span class="math inline">\(s_{ML}^2:\)</span> <span class="math display">\[
\begin{align}
\widehat{Var}(\hat{\beta}_{ML})
=\frac{1}{n}\widehat{AVar}(\hat{\beta}_{ML})
&amp;=s_{ML}^2 \frac{1}{n}S_{X^TX}^{-1}\\[2ex]
&amp;=s_{ML}^2 \left(\sum_{i=1}^nX_i X_i^T\right)^{-1}\\[2ex]
\widehat{Var}(s^2_{ML})
=\frac{1}{n}\widehat{AVar}(s^2_{ML})
&amp;=\frac{1}{n}2\left(s_{ML}^2\right)^2.
\end{align}
\]</span></p>
<!-- ### Consistency of $\hat\beta_{ML}$ and $s_{ML}^2$ {#sec-MLconsistency}

If $E[\varepsilon|X]=0$ (strict exogeneity, follows from the random design (@def-RandomFixedDesign) assumption), then the bias of $\hat\beta$ is zero since $E[\hat\beta_{ML}]=\beta$
$$
\begin{align*}
E[\hat\beta_{ML}]&=E[(X^TX)^{-1}X^T(X\beta + \varepsilon)] \\
                 &=E[E[(X^TX)^{-1}X^T(X\beta + \varepsilon)|X]] \\
                 &=E[E[(X^TX)^{-1}X^TX\beta|X]] + E[E[(X^TX)^{-1}X^T\varepsilon|X]] \\
                 &=E[E[\beta|X]] + E[(X^TX)^{-1}X^TE[\varepsilon|X]] \\
                 &=        \beta + E[(X^TX)^{-1}X^TE[\varepsilon|X]] \\
                 &=        \beta  \\
\Leftrightarrow E[\hat\beta_{ML}]-\beta&=\operatorname{Bias}(\hat\beta_{ML})=0
\end{align*}
$$
Of course, from this it also follows that the squared bias is equal to zero 
$$
\text{Bias}^2(\hat\beta_{ML})=0.
$$  
This implies that the mean square error (MSE) of the ML estimator $\hat\beta_{ML}$ equals the variance of the ML estimator $\hat\beta_{ML}$: 
$$
\operatorname{MSE}(\hat\beta_{ML})=\underbrace{E[(\hat\beta_{ML}-\beta)^2]=Var(\hat\beta_{ML})}_{\text{MSE}(\hat\beta_{ML})=Var(\hat\beta_{ML})\text{ since }\hat\beta_{ML}\text{ is unbiased.}}\to 0\quad\text{as}\quad n\to\infty.
$$
Since convergence in mean square implies convergence in probability, we have established that the ML-estimator $\hat\beta_{ML}$ is a (weakly) consistent estimator of $\beta$
$$
\hat\beta_{ML}\to_p \beta\quad\text{as}\quad n\to\infty.
$$

Moreover, one can also show that $s_{ML}^2$ is a biased but *asymptotically unbiased* estimator, that is 
$$
\left(\operatorname{Bias}(s^2_{ML})\right)^2\to 0
$$ 
as $n\to\infty$. Together with the result that $Var(s^2_{ML})\to 0$ as $n\to\infty$ we have that
$$
\begin{align*}
\operatorname{MSE}(s^2_{ML})&=E[(s^2_{ML}-\sigma^2)^2]\\
&=\operatorname{Bias}^2(s^2_{ML})+Var(s^2_{ML})\to 0\quad\text{as}\quad n\to\infty.
\end{align*}
$$
Again, since convergence in mean square implies convergence in probability, we have established that the ML-estimator $s^2_{ML}$ is a (weakly) consistent estimator of $\sigma^2$
$$
s^2_{ML}\to_p \sigma^2\quad\text{as}\quad n\to\infty.
$$ -->
<!-- In practice, however, one usually works with the unbiased (and consistent) alternative $s_{UB}^2=\dfrac{1}{n-K}\sum_{i=1}^n \hat{\varepsilon}_i^2$ even though one can show that $\operatorname{MSE}(s^2_{ML})<\operatorname{MSE}(\hat\sigma^2_{UB})$ for sufficiently large $n$. -->
</section>
</section>
<section id="asymptotic-distribution-and-single-parameter-testing" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="asymptotic-distribution-and-single-parameter-testing"><span class="header-section-number">1.3.2</span> Asymptotic Distribution and Single Parameter Testing</h3>
<p>It follows from asymptotic maximum likelihood theory (see <a href="#sec-MLAsymp" class="quarto-xref"><span>Section 1.4</span></a>) that the probability distribution of the vector of parameter estimates <span class="math display">\[
\begin{pmatrix}
\hat\beta_{ML,n}\\
\hat s_{ML,n}^2
\end{pmatrix}
\]</span> can be approximated (for largish <span class="math inline">\(n\)</span>) by the following multivariate normal distribution <span class="math display">\[
\begin{align*}
\sqrt{n}\left(
\hat\theta_{ML,n}-\theta_0
\right)
&amp;\to_d
\mathcal{N}_{p}\left(
0,
\left(\mathcal{I}(\beta^T_0,\sigma^2_0)\right)^{-1}
\right)\\[2ex]
\sqrt{n}\left(
\begin{pmatrix}
\hat\beta_{ML}\\
\hat s_{ML}^2
\end{pmatrix}-
\begin{pmatrix}
\beta_0\\
\sigma_0^2
\end{pmatrix}\right)
&amp;\to_d
\mathcal{N}_{K+1}\left(\begin{pmatrix}
0\\
0
\end{pmatrix},
\begin{pmatrix}
\sigma_0^2\Sigma_{X^TX} &amp; 0\\
0 &amp; 2\sigma_0^4
\end{pmatrix}
\right)\\[2ex]
\Leftrightarrow
\begin{pmatrix}
\hat\beta_{ML}\\
\hat s_{ML}^2
\end{pmatrix}
&amp;\overset{a}{\sim}
\mathcal{N}_{K+1}\left(
\begin{pmatrix}
\beta_0\\
\sigma_0^2
\end{pmatrix},
\begin{pmatrix}
\frac{1}{n}\sigma_0^2\Sigma_{X^TX} &amp; 0\\
0 &amp; \frac{1}{n}2\sigma_0^4
\end{pmatrix}
\right)
\end{align*}
\]</span></p>
<p>Plugging-in estimators for the unknown variance components, i.e.</p>
<ul>
<li><span class="math inline">\(s_{ML}^2 \frac{1}{n}S_{X^TX}^{-1}\quad\)</span> for <span class="math inline">\(\quad\sigma_0^2 \frac{1}{n} \Sigma_{X^TX}\)</span></li>
</ul>
<p>and</p>
<ul>
<li><span class="math inline">\(\frac{1}{n}2\left(s_{ML}^2\right)^2\quad\)</span> for <span class="math inline">\(\quad\frac{1}{n}2\sigma_0^4\)</span></li>
</ul>
<p>allows using this asymptotic normality result in testing.</p>
<section id="single-parameter-testing" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="single-parameter-testing"><strong>Single Parameter Testing</strong></h4>
<p>For instance, we can do a single-parameter test for</p>
<p><span class="math display">\[
\begin{align*}
H_0\colon \beta_{0,k} &amp; =   \beta_{0,k}^{(0)}\\
H_1\colon \beta_{0,k} &amp;\neq \beta_{0,k}^{(0)},\\
\end{align*}
\]</span> where <span class="math inline">\(\beta_{0,k}^{(0)}\)</span> denotes the null-hypothetical value (typically, <span class="math inline">\(\beta_{0,k}^{(0)}=0\)</span>), using the Wald statistic <span class="math display">\[
T_{\beta_{0,k},n}=\frac{\hat\beta_{ML,k} - 0}{\sqrt{s_{ML}^2 \frac{1}{n}\left[S_{X^TX}^{-1}\right]_{(k,k)}}}\overset{H_0}{\to_d}
\mathcal{N}(0,1)\quad \text{as}\quad n\to\infty.
\]</span></p>
<p>Likewise, for <span class="math display">\[
\begin{align*}
H_0\colon \sigma_0^2 &amp; = (\sigma_0^{(0)})^2\\
H_1\colon \sigma_0^2 &amp;\neq (\sigma_0^{(0)})^2,\\
\end{align*}
\]</span> where <span class="math inline">\((\sigma_0^{(0)})^2\)</span> denotes the null-hypothetical value, using the Wald statistic <span class="math display">\[
T_{\sigma_0,n}=\frac{s_{ML}^2 - (\sigma_0^{(0)})^2}{\sqrt{\frac{1}{n}2\left(s_{ML}^2\right)^2}}\overset{H_0}{\to_d}
\mathcal{N}(0,1)\quad \text{as}\quad n\to\infty.
\]</span></p>
<p><strong>Testing:</strong> We reject <span class="math inline">\(H_0,\)</span> if the observed value <span class="math inline">\(T_{n,obs},\)</span> computed from the observed realization of the random sample, is in absolute values larger than the <span class="math inline">\((1-\alpha/2)\)</span>-qantile of the standard normal distribution; i.e.&nbsp;if <span class="math display">\[
|T_{n,obs}| &gt; z_{1-\alpha/2},
\]</span> where <span class="math inline">\(\alpha\in(0,1)\)</span> denotes the chosen significance level, such as <span class="math inline">\(\alpha=0.01.\)</span></p>
</section>
</section>
</section>
<section id="sec-MLAsymp" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="sec-MLAsymp"><span class="header-section-number">1.4</span> Asymptotic Theory of Maximum-Likelihood Estimators</h2>
<p>In the following, we consider the asymptotic distribution of ML-estimators.</p>
<p>We only consider the simplest situation: Assume a random sample<br>
<span class="math display">\[
X_1,\dots,X_n\overset{\text{i.i.d.}}{\sim}X,
\]</span> where <span class="math inline">\(X\in\mathbb{R}\)</span> is a univariate random variable with density function <span class="math display">\[f(x;\theta_0),
\]</span> where the true (unknown, univariate) parameter <span class="math inline">\(\theta_0\in\Theta\)</span> is an interior point of a compact parameter interval <span class="math display">\[\Theta=[\theta_l,\theta_u]\subset\mathbb{R}.
\]</span> <strong>Note:</strong> <span class="math inline">\(\theta_0\)</span> is an “interior point” of <span class="math inline">\(\Theta\)</span> if <span class="math inline">\(\theta_l&lt;\theta_0&lt;\theta_u.\)</span></p>
<p>Moreover, we consider the following setup.</p>
<ul>
<li>Likelihood function: <span class="math display">\[
\mathcal{L}_n(\theta)=\prod_{i=1}^n f(X_i;\theta)
\]</span></li>
<li>Log-likelihood function: <span class="math display">\[
\ell_n(\theta)=\ln\mathcal{L}(\theta)=\sum_{i=1}^n \ln f(X_i;\theta)
\]</span></li>
<li>Maximum-likelihood estimator <span class="math inline">\(\hat{\theta}_n\)</span> <span class="math display">\[
\hat{\theta}_n=\arg\max_{\theta\in\Theta}\ell_n(\theta)
\]</span></li>
<li>The maximum-likelihood estimator <span class="math inline">\(\hat{\theta}_n\)</span> maximizes <span class="math inline">\(\ell_n(\theta)\)</span> uniquely such that <span class="math display">\[
\ell_n'(\hat\theta_n)=0\quad\text{and}\quad\ell_n''(\hat\theta_n)&lt;0
\]</span></li>
<li>It is assumed that the partial derivatives <span class="math display">\[
\frac{\partial}{\partial\theta}f(x;\theta)\quad\text{and}\quad \frac{\partial^2}{\partial\theta^2}f(x;\theta)
\]</span> exist and that these partial derivatives can be passed under the integral such that <span class="math display">\[
\begin{align*}
\frac{\partial}{\partial\theta}\int f(x;\theta)dx
&amp;=\int\frac{\partial}{\partial\theta} f(x;\theta)dx\\
\frac{\partial^2}{\partial\theta^2}\int f(x;\theta)dx
&amp;=\int\frac{\partial^2}{\partial\theta^2} f(x;\theta)dx
\end{align*}
\]</span> for all <span class="math inline">\(\theta\in\Theta.\)</span></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<p>An <strong>example</strong> that fits into the above setup is the density of the exponential distribution <span class="math display">\[
f(x;\theta)=\left\{
    \begin{matrix}
    \theta\exp(- \theta x)&amp; \text{for }x\geq 0\\
    0                     &amp; \text{for }x &lt; 0\\
    \end{matrix}\right.
\]</span> with unknown rate parameter <span class="math inline">\(\theta&gt;0.\)</span></p>
<p>Or, more generally, the densities of the one-parameter, <span class="math inline">\(\theta\in\Theta\subset\mathbb{R},\)</span> exponential family<br>
<span class="math display">\[
f(x;\theta)=h(x)\exp(\eta(\theta) T(x) - B(\theta))
\]</span> where <span class="math inline">\(h:\)</span> <span class="math inline">\(\mathbb{R}\to\mathbb{R},\)</span> <span class="math inline">\(T:\)</span> <span class="math inline">\(\mathbb{R}\to\mathbb{R},\)</span> <span class="math inline">\(\eta:\)</span> <span class="math inline">\(\Theta\to\mathbb{R},\)</span> and <span class="math inline">\(B:\)</span> <span class="math inline">\(\Theta\to\mathbb{R}.\)</span></p>
</div>
</div>
<p>The derivation of the asymptotic distribution of the ML estimator, <span class="math inline">\(\hat\theta_n,\)</span> relies on a Taylor expansion of the derivative of the log-likelihood function, <span class="math display">\[
\ell_n'(\cdot),
\]</span> around <span class="math inline">\(\theta_0\)</span> (see <a href="#eq-MVT" class="quarto-xref">Equation&nbsp;<span>1.6</span></a>). To derive this expression, we use the mean value theorem (<a href="#thm-MVT" class="quarto-xref">Theorem&nbsp;<span>1.2</span></a>).</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<div id="thm-MVT" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1.2 (Mean Value Theorem)</strong></span> <em>Let <span class="math inline">\(f\)</span> be continuous over the closed interval <span class="math inline">\([a,b]\)</span> and differentiable over the open interval <span class="math inline">\((a,b).\)</span> Then, there exists at least one point <span class="math inline">\(c\in(a,b)\)</span> such that</em> <span class="math display">\[
f'(c) = \frac{f(b)-f(a)}{b-a}
\]</span> <em>or equivalently</em> <span class="math display">\[
f(b)=f(a) + f'(c)(b-a).
\]</span></p>
</div>
</div>
</div>
</div>
<p>By the Mean Value Theorem (<a href="#thm-MVT" class="quarto-xref">Theorem&nbsp;<span>1.2</span></a>), we know that <span id="eq-MVT"><span class="math display">\[
\ell_n'(\hat{\theta}_n)=\ell_n'(\theta_0)+\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0)
\tag{1.6}\]</span></span> for some <span class="math inline">\(\psi_n\)</span> between <span class="math inline">\(\hat{\theta}_n\)</span> and <span class="math inline">\(\theta_0;\)</span> i.e.</p>
<ul>
<li><span class="math inline">\(\psi_n\in(\theta_0,\hat{\theta}_n)\quad\)</span> if <span class="math inline">\(\quad\theta_0&lt;\hat{\theta}_n\)</span></li>
<li><span class="math inline">\(\psi_n\in(\hat{\theta}_n,\theta_0)\quad\)</span> if <span class="math inline">\(\quad\hat{\theta}_n&lt;\theta_0\)</span></li>
</ul>
<blockquote class="blockquote">
<p>Note: <a href="#eq-MVT" class="quarto-xref">Equation&nbsp;<span>1.6</span></a> is simply the first-order version of the mean-value form of Taylor’s theorem (<a href="#thm-TaylorThm" class="quarto-xref">Theorem&nbsp;<span>1.1</span></a>).</p>
</blockquote>
<p>Since <span class="math inline">\(\hat{\theta}_n\)</span> maximizes the log-Likelihood function it follows that <span class="math display">\[
\ell_n'(\hat{\theta}_n)=0.
\]</span> Together with <a href="#eq-MVT" class="quarto-xref">Equation&nbsp;<span>1.6</span></a>, this implies that <span class="math display">\[
\overbrace{\ell_n'(\hat{\theta}_n)}^{=0}=\ell_n'(\theta_0)+\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0)
\]</span> <span id="eq-ml2"><span class="math display">\[
\Rightarrow\quad \ell_n'(\theta_0)=-\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0).
\tag{1.7}\]</span></span> Now, note that necessarily <span class="math display">\[
\int_{-\infty}^{\infty} f(x;\theta)dx=1
\]</span> for <em>all possible values</em> of <span class="math inline">\(\theta\in\Theta,\)</span> since <span class="math inline">\(f\)</span> is a density function.</p>
<p>Therefore, <span class="math display">\[
\begin{align*}
\frac{\partial}{\partial \theta}\underbrace{\int_{-\infty}^{\infty} f(x;\theta)dx}_{=1}&amp;=\frac{\partial}{\partial \theta}1 = 0,\quad\text{for all}\quad\theta\in\Theta.
\end{align*}
\]</span> Using that we can here pass the partial derivative under the integral sign, we thus have <span id="eq-zero1"><span class="math display">\[
\int_{-\infty}^{\infty} \frac{\partial}{\partial \theta}f(x;\theta)dx
=\frac{\partial}{\partial \theta}\int_{-\infty}^{\infty} f(x;\theta)dx
=0
\tag{1.8}\]</span></span> for all <span class="math inline">\(\theta\in\Theta.\)</span></p>
<p>Likewise, <span class="math display">\[
\begin{align*}
\frac{\partial^2}{\partial \theta^2}\underbrace{\int_{-\infty}^{\infty} f(x;\theta)dx}_{=1}&amp;=\frac{\partial^2}{\partial \theta^2}1 = 0,\quad\text{for all}\quad\theta\in\Theta.
\end{align*}
\]</span> Using again that we can here pass the partial derivative under the integral sign, we thus have <span id="eq-zero2"><span class="math display">\[
\int_{-\infty}^{\infty} \frac{\partial^2}{\partial \theta^2}f(x;\theta)dx
=\frac{\partial^2}{\partial \theta^2}\int_{-\infty}^{\infty} f(x;\theta)dx
=0
\tag{1.9}\]</span></span> for all <span class="math inline">\(\theta\in\Theta.\)</span></p>
<p>Using <a href="#eq-zero1" class="quarto-xref">Equation&nbsp;<span>1.8</span></a> and <a href="#eq-zero2" class="quarto-xref">Equation&nbsp;<span>1.9</span></a>, we can now show that the average <span class="math display">\[
\frac{1}{n}\ell_n'(\theta_0)=\frac{1}{n}\underbrace{\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)}_{\ell_n'(\theta_0)}
\]</span> is <strong>asymptotically normal</strong>. This is done in the following by checking the three conditions for applying the Lindeberg-Lévy central limit theorem.</p>
<p>Firstly, the average <span class="math display">\[
\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)
\]</span> is taken over i.i.d. random variables: <span class="math display">\[
\frac{\partial}{\partial \theta} \ln f(X_1;\theta_0),\dots,\frac{\partial}{\partial \theta} \ln f(X_n;\theta_0)\overset{\text{i.i.d.}}{\sim}\frac{\partial}{\partial \theta} \ln f(X;\theta_0)
\]</span></p>
<p>Secondly, for the mean one gets: <span id="eq-Mean"><span class="math display">\[
\begin{align*}
\mathbb{E}\left(\frac{1}{n}\ell_n'(\theta_0)\right)
&amp;=\mathbb{E}\left(\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)\right)\\[2ex]
&amp;=\frac{n}{n}\mathbb{E}\left(\frac{\partial}{\partial \theta} \ln f(X;\theta_0)\right)\quad[\text{i.i.d.}]\\[2ex]
&amp;=\mathbb{E}\left(\frac{\frac{\partial}{\partial \theta}f(X;\theta_0)}{f(X;\theta_0)}\right)\quad[\text{chain rule}]\\[2ex]
&amp;=\int_{-\infty}^{\infty} \frac{\frac{\partial}{\partial \theta}  f(x;\theta_0)}
{f(x;\theta_0)}f(x;\theta_0)dx\quad[\text{Def. of $\mathbb{E}$}]\\[2ex]
&amp;=\int_{-\infty}^{\infty} \frac{\partial}{\partial \theta}  f(x;\theta_0)dx\\[2ex]
&amp;=0,
\end{align*}
\tag{1.10}\]</span></span> where the last step follows from <a href="#eq-zero1" class="quarto-xref">Equation&nbsp;<span>1.8</span></a>.</p>
<p>Thirdly, for the variance one gets: <span class="math display">\[
\begin{align*}
Var\left(\frac{1}{n}\ell_n'(\theta_0)\right)
&amp;=Var\left(\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)\right)\\
&amp;=\frac{1}{n}Var\left(\frac{\partial}{\partial \theta} \ln f(X;\theta_0)\right)\quad[\text{i.i.d.}]\\
&amp;=\frac{1}{n}Var\left(\frac{\frac{\partial}{\partial \theta} f(X;\theta_0)}{f(X;\theta)}\right)\quad[\text{chain rule}]\\
&amp;=\frac{1}{n}\mathbb{E}\left(\left(\frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}{f(X;\theta_0)}\right)^2\right)\\
&amp;=\frac{1}{n}\mathcal{I}(\theta_0),
\end{align*}
\]</span> where the simplification of the variance expression to a second moment expression follows from <a href="#eq-Mean" class="quarto-xref">Equation&nbsp;<span>1.10</span></a>. <br></p>
<blockquote class="blockquote">
<p>We can write the last expression using the Fisher Information <span class="math inline">\(\mathcal{I}(\theta_0)-\frac{1}{n}\mathbb{E}(\ell_n''(\theta_0))\)</span> since below in <a href="#eq-FisherInfoDeriv" class="quarto-xref">Equation&nbsp;<span>1.12</span></a> we’ll see that <span class="math display">\[
\begin{align*}
\mathbb{E}\left(\left(\frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}{f(X;\theta_0)}\right)^2\right)
&amp; =-\frac{1}{n}\mathbb{E}(\ell_n''(\theta_0)) = \mathcal{I}(\theta_0).
\end{align*}
\]</span></p>
</blockquote>
<!-- , where we found that 
$$
\mathbb{E}\left(\frac{\partial}{\partial \theta} \ln f(X_i;\theta_0)\right)=0.
$$  
-->
<p>Thus, we can apply the <strong>Lindeberg-Lévy central limit theorem</strong> from which it follows that <span class="math display">\[
\frac{\frac{1}{n}\ell_n'(\theta_0)-\overbrace{\mathbb{E}\left(\frac{1}{n}\ell_n'(\theta_0)\right)}^{=0}}{\sqrt{\frac{1}{n}\mathcal{I}(\theta_0)} } = \frac{\ell_n'(\theta_0)}{\sqrt{n\mathcal{I}(\theta_0)} } \to_d \mathcal{N}(0,1)
\]</span> as <span class="math inline">\(n\to\infty.\)</span></p>
<p>By our mean value expression in <a href="#eq-ml2" class="quarto-xref">Equation&nbsp;<span>1.7</span></a> <span class="math display">\[
\ell_n'(\theta_0)=-\ell_n''(\psi_n)(\hat{\theta}_n-\theta_0)
\]</span> we thus have <span class="math display">\[
\frac{-\ell_n''(\psi_n)}{\sqrt{n \mathcal{I}(\theta_0)}}\left(\hat{\theta}_n-\theta_0\right) \to_d \mathcal{N}(0,1),
\]</span> which is equivalent to <span id="eq-MLNorm"><span class="math display">\[
\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)\;\sqrt{n}\left(\hat{\theta}_n-\theta_0\right) \to_d \mathcal{N}(0,1).
\tag{1.11}\]</span></span> The <span class="math inline">\(\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\)</span>-part in <a href="#eq-MLNorm" class="quarto-xref">Equation&nbsp;<span>1.11</span></a> is our object of interest.</p>
<p>The further analysis requires us to study the asymptotic behavior of<br>
<span class="math display">\[
-\frac{1}{n}\ell_n''(\psi_n)
\]</span> which will help us to understand the behavior of <span class="math inline">\(\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)\)</span> in <a href="#eq-MLNorm" class="quarto-xref">Equation&nbsp;<span>1.11</span></a>.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before we consider <span class="math inline">\(-\frac{1}{n}\ell_n''(\psi_n),\)</span> we begin with studying the mean and the variance of the simpler statistic <span class="math display">\[
-\frac{1}{n}\ell_n''(\theta_0)
\]</span> with <span class="math inline">\(\psi_n\)</span> replaced by <span class="math inline">\(\theta_0.\)</span></p>
</div>
</div>
<p>First, the mean of <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0):\)</span> <span class="math display">\[
\begin{align*}
-\frac{1}{n}\ell_n''(\theta_0)
&amp;=-\frac{1}{n}\sum_{i=1}^n\frac{\partial^2}{\partial \theta\partial \theta}\ln f(X_i;\theta_0)\\[2ex]
&amp;=-\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta}\left(\frac{\partial}{\partial\theta}\ln f(X_i;\theta_0)\right)\\[2ex]
&amp;=-\frac{1}{n}\sum_{i=1}^n\frac{\partial}{\partial \theta}\left(\frac{\frac{\partial}{\partial \theta}f(X_i;\theta_0)}{f(X_i;\theta_0)}\right)\quad[\text{chain rule}]
\end{align*}
\]</span> Applying the quotient rule yields <span class="math display">\[
\begin{align*}
-\frac{1}{n}\ell_n''(\theta_0)
&amp;=-\frac{1}{n}\sum_{i=1}^n
\left(
\frac{\left(\frac{\partial^2}{\partial \theta\partial \theta}f(X_i;\theta_0)\right) f(X_i;\theta_0)-\frac{\partial}{\partial\theta}f(X_i;\theta_0)\frac{\partial}{\partial\theta} f(X_i;\theta_0)}{\left(f(X_i;\theta_0)\right)^2}\right)\\[2ex]
&amp;=-\frac{1}{n}\sum_{i=1}^n
\left(
\frac{\frac{\partial^2}{\partial \theta^2}  f(X_i;\theta_0)}
{f(X_i;\theta_0)}-\left( \frac{\frac{\partial}{\partial \theta}  f(X_i;\theta_0)}
{f(X_i;\theta_0)}\right)^2  
\right).
\end{align*}
\]</span> Taking the mean of <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0)\)</span> yields that <span class="math display">\[
\begin{align*}
\mathbb{E}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)
&amp;=\frac{n}{n}\mathbb{E}\left(-\frac{\frac{\partial^2}{\partial \theta^2}  f(X;\theta_0)}
{f(X;\theta_0)}+\left( \frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}
{f(X;\theta_0)}\right)^2\right)\quad[\text{i.i.d.}]\\[2ex]
&amp;=\frac{n}{n}\mathbb{E}\left(-\frac{\frac{\partial^2}{\partial \theta^2}  f(X;\theta_0)}{f(X;\theta_0)}\right)+\mathbb{E}\left(\left( \frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}
{f(X;\theta_0)}\right)^2\right)
\end{align*}
\]</span> From <a href="#eq-Mean" class="quarto-xref">Equation&nbsp;<span>1.10</span></a>, we know that <span class="math inline">\(\mathbb{E}\left(-\frac{\frac{\partial^2}{\partial \theta^2}  f(X;\theta_0)}{f(X;\theta_0)}\right)=0\)</span> thus <span class="math display">\[
\begin{align*}
\underbrace{\mathbb{E}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)}_{=\mathcal{I}(\theta_0)}
&amp;=0 + \mathbb{E}\left(\left( \frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}{f(X;\theta_0)}\right)^2\right)
\end{align*}
\]</span> <span id="eq-FisherInfoDeriv"><span class="math display">\[
\Rightarrow \qquad
\mathcal{I}(\theta_0) =
\mathbb{E}\left(\left( \frac{\frac{\partial}{\partial \theta}  f(X;\theta_0)}{f(X;\theta_0)}\right)^2\right)
\tag{1.12}\]</span></span></p>
<p>This means that <span class="math display">\[
-\frac{1}{n}\ell_n''(\theta_0)
\]</span> is an <strong>unbiased estimator</strong> of the Fisher information <span class="math inline">\(\mathcal{I}(\theta_0).\)</span></p>
<p>Moreover, <a href="#eq-FisherInfoDeriv" class="quarto-xref">Equation&nbsp;<span>1.12</span></a> provides an alternative expression for the Fisher information <span class="math inline">\(\mathcal{I}(\theta_0).\)</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Multivariate Settings
</div>
</div>
<div class="callout-body-container callout-body">
<p>For multivariate (<span class="math inline">\(p\)</span>-dimensional) parameters <span class="math inline">\(\theta_0,\)</span> the Fisher information <span class="math inline">\(\mathcal{I}(\theta_0)=(-1)\cdot \mathbb{E}\left(\ell_n''(\theta_0)\right)\)</span> becomes the (<span class="math inline">\(p\times p\)</span>) Fisher information matrix (see <a href="#sec-varMLE" class="quarto-xref"><span>Section 1.3.1</span></a>).</p>
</div>
</div>
<p>Second, the variance of variance of <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0):\)</span> <span class="math display">\[
\begin{align*}
Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)
&amp;=Var\left(-\frac{1}{n}\sum_{i=1}^n\frac{\partial^2}{\partial \theta\partial \theta}\ln f(X_i;\theta_0)\right)\\[2ex]
&amp;=\frac{n}{n^2}
\underbrace{Var\left(\frac{\partial^2}{\partial \theta \partial \theta}  \ln f(X;\theta_0)\right)}_{=\texttt{constant}}\\[2ex]
&amp;=\frac{1}{n}\texttt{constant},
\end{align*}
\]</span> which implies that <span class="math display">\[
Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\to 0\quad\text{as}\quad n\to\infty.
\]</span></p>
<p>With these mean and variance results for <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0),\)</span> we can write down the Mean Squared Error (MSE) of the estimator <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0)\)</span> of <span class="math inline">\(\mathcal{I}(\theta_0):\)</span> <span class="math display">\[
\begin{align*}
&amp;\operatorname{MSE}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\\[2ex]
&amp;=
\mathbb{E}\left(\left(-\frac{1}{n}\ell_n''(\theta_0) -\mathcal{I}(\theta_0)\right)^2\right)\\[2ex]
&amp;=\underbrace{\left(\operatorname{Bias}\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\right)^2}_{=0}+Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\\[3ex]
&amp;=Var\left(-\frac{1}{n}\ell_n''(\theta_0)\right)\to 0\quad\text{as}\quad n\to\infty.
\end{align*}
\]</span></p>
<p>That is, the estimator <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0)\)</span> is a <strong>mean square consistent</strong> estimator, i.e. <span class="math display">\[
-\frac{1}{n}\ell_n''(\theta_0)\to_{m.s.} \mathcal{I}(\theta_0)\quad \hbox{as}\quad n\to\infty,
\]</span> which implies that <span class="math inline">\(\frac{1}{n}\ell_n''(\theta_0)\)</span> is also a <strong>(weakly) consistent</strong> estimator, i.e.&nbsp; <span class="math display">\[
-\frac{1}{n}\ell_n''(\theta_0)\to_p \mathcal{I}(\theta_0)\quad \hbox{as}\quad n\to\infty,
\]</span> since mean square convergence implies convergence in probability.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>🤔 Remember, we wanted to study <span class="math inline">\(-\frac{1}{n}\ell_n''(\psi_n)\)</span> in <a href="#eq-MLNorm" class="quarto-xref">Equation&nbsp;<span>1.11</span></a> <strong>not</strong> <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0).\)</span> Studying <span class="math inline">\(-\frac{1}{n}\ell_n''(\theta_0)\)</span> was only the simpler thing to do.</p>
<p>Luckily, we are actually close now.</p>
</div>
</div>
<p>Next, we use that ML estimators <span class="math inline">\(\hat\theta_n\)</span> are (weakly) <strong>consistent</strong>, i.e., <span class="math display">\[
\hat\theta_n\to_p\theta_0\quad\text{as}\quad n\to\infty.
\]</span></p>
<blockquote class="blockquote">
<p><strong>Example:</strong> Our results in <a href="#sec-LinRegNorm" class="quarto-xref"><span>Section 1.3</span></a> imply, for instance, that the ML estimator <span class="math inline">\(\hat{\beta}_n\)</span> is consistent for <span class="math inline">\(\beta.\)</span></p>
</blockquote>
<p>Since <span class="math inline">\(\psi_n\)</span> is a <strong>mean value</strong> between <span class="math inline">\(\theta_0\)</span> and <span class="math inline">\(\hat{\theta}_n\)</span> (<a href="#eq-MVT" class="quarto-xref">Equation&nbsp;<span>1.6</span></a>), consistency of <span class="math inline">\(\hat{\theta}_n\)</span> implies that <span class="math display">\[
\psi_n\to_p\theta_0\quad\text{as}\quad n\to\infty.
\]</span></p>
<p>Therefore, we have by the <strong>continuous mapping theorem</strong> that <span class="math display">\[
\begin{align}
-\frac{1}{n}\ell_n''(\psi_n) &amp; \to_p \phantom{-}\mathcal{I}(\theta_0)\quad \hbox{ as }\quad n\to\infty\\[2ex]
\Rightarrow\qquad
\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)&amp;\to_p \sqrt{\mathcal{I}(\theta_0)} \quad \hbox{ as }\quad n\to\infty.
\end{align}
\]</span></p>
<p>Now, using <strong>Slutsky’s theorem</strong>, we can connect the above consistency result with the asymptotic normality result in <a href="#eq-MLNorm" class="quarto-xref">Equation&nbsp;<span>1.11</span></a> such that <span class="math display">\[
\begin{align*}
\underbrace{\left(\frac{-\frac{1}{n}\ell_n''(\psi_n)}{\sqrt{\mathcal{I}(\theta_0)}}\right)}_{\to_p \sqrt{\mathcal{I}(\theta_0)} }\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\to_d\mathcal{N}(0,1)
\end{align*}
\]</span> or equivalently <span id="eq-AsymNormMLE"><span class="math display">\[
\begin{align*}
\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\to_d \mathcal{N}\left(0,\frac{1}{\mathcal{I}(\theta_0)}\right),
\end{align*}
\tag{1.13}\]</span></span> where <span class="math inline">\(1/\mathcal{I}(\theta_0)\)</span> is the <strong>asymptotic variance</strong> of the ML estimator <span class="math inline">\(\hat{\theta}_n\)</span> and equals the inverse of the (here scalar valued) Fisher information <span class="math display">\[
\mathcal{I}(\theta_0)=-\frac{1}{n}\mathbb{E}(\ell_n''(\theta_0)).
\]</span></p>
<p><a href="#eq-AsymNormMLE" class="quarto-xref">Equation&nbsp;<span>1.13</span></a> is the asymptotic normality result we aimed for.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Multivariate Settings
</div>
</div>
<div class="callout-body-container callout-body">
<p>The above arguments can easily be generalized to multivariate (<span class="math inline">\(p\)</span>-dimensional) parameter vectors <span class="math inline">\(\theta\in\mathbb{R}^p\)</span>. In this case, <span class="math inline">\(\mathcal{I}(\theta_0)\)</span> becomes a <span class="math inline">\(p\times p\)</span> matrix, and <span class="math display">\[
\sqrt{n}\left(\hat{\theta}_n-\theta_0\right)\to_d \mathcal{N}_p\left(0, \mathcal{I}(\theta_0)^{-1}\right),
\]</span> where <span class="math inline">\(\mathcal{I}(\theta_0)=-\frac{1}{n}\mathbb{E}\left(H_{\ell_n}(\theta_0)\right)\)</span> is the <span class="math inline">\((p\times p)\)</span> Fisher information matrix with <span class="math inline">\(H_{\ell_n}(\theta_0)\)</span> denoting the Hesse matrix of <span class="math inline">\(\ell_n(\cdot)\)</span> evaluated at <span class="math inline">\(\theta_0.\)</span></p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
ML-Theory and Machine learning
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Fisher information is used in machine learning techniques such as elastic weight consolidation, which reduces catastrophic forgetting in artificial neural networks (<span class="citation" data-cites="Kirkpatrick_2017">Kirkpatrick et al. (<a href="#ref-Kirkpatrick_2017" role="doc-biblioref">2017</a>)</span>).</p>
<p>Fisher information can be used as an alternative to the Hessian of the loss function in second-order gradient descent network training (<span class="citation" data-cites="Martens_2020">Martens (<a href="#ref-Martens_2020" role="doc-biblioref">2020</a>)</span>).</p>
</div>
</div>
</section>
<section id="cramérrao-lower-bound" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="cramérrao-lower-bound"><span class="header-section-number">1.5</span> Cramér–Rao Lower Bound</h2>
<p>Harald Cramér and Calyampudi Radhakrishna Rao showed that for any unbiased estimator <span class="math inline">\(\hat\theta\)</span>, its asymptotic variance-covariance matrix cannot be smaller than <span class="math display">\[
\mathcal{I}^{-1}(\theta_0),
\]</span> where <span class="math inline">\(\mathcal{I}(\theta_0)\)</span> is the <strong>Fisher information matrix</strong> <span class="math display">\[
\mathcal{I}(\theta) = -\frac{1}{n}\mathbb{E}\left(H_{\ell_n}(\theta)\right)
\]</span> evaluated at the true parameter value <span class="math inline">\(\theta_0.\)</span></p>
<p>Thus, maximum likelihood estimators attain the Cramer-Rao lower bound and will therefore be asymptotically efficient.</p>
</section>
<section id="invariance-property-of-the-ml-estimator" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="invariance-property-of-the-ml-estimator"><span class="header-section-number">1.6</span> Invariance Property of the ML-Estimator</h2>
<p>Suppose that a distribution has the parameter <span class="math inline">\(\theta_0,\)</span> but we are interested in finding an estimator of a function of <span class="math inline">\(\theta_0,\)</span> say <span class="math display">\[
\eta_0=\tau(\theta_0).
\]</span> The invariance property of ML-estimators says that if <span class="math inline">\(\hat{\theta}_n\)</span> is the ML-estimator of <span class="math inline">\(\theta_0,\)</span> then <span class="math inline">\(\tau(\hat{\theta}_n)\)</span> is the ML-estimator of <span class="math inline">\(\eta_0=\tau(\theta_0).\)</span></p>
<section id="one-to-one-functions" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="one-to-one-functions">One-to-One Functions</h3>
<p>Let the function <span class="math display">\[
\eta = \tau(\theta)
\]</span> be a <strong>one-to-one</strong> function. That is, for each value of <span class="math inline">\(\theta\)</span> there is a unique value of <span class="math inline">\(\eta\)</span> and vice versa.</p>
<p>Important property of one-to-one functions: A one-to-one function <span class="math inline">\(\eta = \tau(\theta)\)</span> possesses a well-defined <strong>inverse</strong> <span class="math display">\[
\theta=\tau^{-1}(\eta).
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example:
</div>
</div>
<div class="callout-body-container callout-body">
<p>For instance, the functions <span class="math display">\[
\begin{align*}
\eta = \tau(\theta) &amp; = \theta + 3
\quad\Rightarrow\quad \theta = \tau^{-1}(\eta) = \eta -3 \\[2ex]
\eta = \tau(\theta) &amp; = \theta/5  
\quad\Rightarrow\quad \theta = \tau^{-1}(\eta) = 5 \eta
\end{align*}
\]</span> are one-to-one functions. However, for instance, the functions <span class="math display">\[
\begin{align*}
\tau(\theta) &amp; = \sin(\theta)\\[2ex]
\tau(\theta) &amp; = \theta^2  
\end{align*}
\]</span> are <strong>not</strong> one-to-one functions.</p>
</div>
</div>
<p>In this one-to-one case, it is easily seen that it makes no difference whether we maximize the likelihood function as a function of <span class="math inline">\(\theta\)</span> or as a function of <span class="math inline">\(\eta = \tau(\theta)\)</span>—in each case we get the same answer.</p>
<p>The likelihood function of <span class="math inline">\(\tau(\theta),\)</span> written as a function of <span class="math inline">\(\eta,\)</span> is given by <span class="math display">\[
\begin{align*}
\mathcal{L}^*(\eta)
&amp;= \prod_{i=1}^n f\big(X_i;\tau^{-1}(\eta)\big)
= \mathcal{L}\big(\;\overbrace{\tau^{-1}(\eta)}^{=\theta}\;\big)
\end{align*}
\]</span> and <span class="math display">\[
\begin{align*}
  \sup_{\eta}  \mathcal{L}^*(\eta)
= \sup_{\eta}  \mathcal{L}\big(\;\overbrace{\tau^{-1}(\eta)}^{=\theta}\;\big)
= \sup_{\theta}\mathcal{L}\big(\theta\big).
\end{align*}
\]</span> Thus, the maximum of <span class="math inline">\(\mathcal{L}^*(\eta)\)</span> is attained at <span class="math display">\[
\eta=\tau(\theta)=\tau(\hat\theta_n),
\]</span> showing that the ML-estimator of <span class="math inline">\(\tau(\theta_0)\)</span> is <span class="math inline">\(\tau(\hat\theta_n).\)</span></p>
<!-- 
Moreover, using the multivariate version (for $\tau(\theta_0)\in\mathcal{K}$) of the first-order Taylor expansion of $\tau$ around $\theta_0,$ one can show that
$$
\sqrt{n}\left(\tau(\hat\theta_n) - \tau(\theta_0)\right)\sim\mathcal{N}\left(0,\left(\mathcal{I}(\theta_0)\right)^{-1}\right) \nabla\ell_n(\theta^T)
$$ 
-->
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
More general (not one-to-one) functions
</div>
</div>
<div class="callout-body-container callout-body">
<p>In many cases, however, this simply version of the invariance of ML-estimators is not useful since many functions of interest are not one-to-one.</p>
<p>Luckily, the invariance property of the ML-estimator also holds for functions that are not one-to-one; see Chapter 7 in <span class="citation" data-cites="CasellaBerger_StatInf_2001">Casella and Berger (<a href="#ref-CasellaBerger_StatInf_2001" role="doc-biblioref">2001</a>)</span>.</p>
</div>
</div>
</section>
</section>
<section id="exercises" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="exercises">Exercises</h2>
<section id="exercise-1." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exercise-1.">Exercise 1.</h4>
<p>Program the Newton-Raphson algorithm for a numerical computation of the ML estimate <span class="math inline">\(\hat\theta\)</span> of the parameter <span class="math inline">\(\theta=P(\text{Coin}=\texttt{HEAD})\)</span> in our coin toss example of this chapter. Replicate the results shown in <a href="#tbl-NR" class="quarto-xref">Table&nbsp;<span>1.1</span></a>.</p>
</section>
<section id="exercise-2." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exercise-2.">Exercise 2.</h4>
<p>Assume an i.i.d. random sample <span class="math inline">\(X_1,\dots,X_n\)</span> from an exponential distribution, i.e.&nbsp;the underlying density of <span class="math inline">\(X_i\)</span> is given by <span class="math display">\[
f(x;\theta_0)=
\left\{\begin{array}{ll}\theta_0\exp(-\theta_0 x),&amp;x\geq 0\\0,&amp;x&lt;0\end{array}\right.
\]</span> with <span class="math inline">\(\theta_0&gt;0,\)</span> where <span class="math display">\[
\mu:=\mathbb{E}(X_i)=\frac{1}{\theta_0}
\]</span> and <span class="math display">\[
Var(X_i)=\frac{1}{\theta_0^2}.
\]</span></p>
<ol type="a">
<li>What is the log-likelihood function for the i.i.d. random sample <span class="math inline">\(X_1,\dots,X_n\)</span>?</li>
<li>Derive the maximum likelihood (ML) estimator <span class="math inline">\(\hat\theta_n\)</span> of <span class="math inline">\(\theta_0.\)</span></li>
<li>From maximum likelihood theory we know that <span class="math display">\[
\sqrt{n}(\hat\theta_n-\theta_0)\to_d \mathcal{N}\left(0,\frac{1}{\mathcal{I}(\theta_0)}\right).
\]</span> Derive the expression for the Fisher information <span class="math inline">\(\mathcal{I}(\theta_0).\)</span> Use the Fisher information to give the <em>explicit</em> formula for the asymptotic distribution of <span class="math inline">\(\hat\theta_n\)</span>.</li>
</ol>
</section>
<section id="exercise-3." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exercise-3.">Exercise 3.</h4>
<!-- From All of Statistics p 151 -->
<p>Let <span class="math inline">\(X_1,\dots,X_n\overset{\text{i.i.d.}}{\sim}X\)</span> with <span class="math inline">\(X\sim\mathcal{Unif}(0,\theta_0).\)</span></p>
<ol type="a">
<li><p>What is the likelihood function?</p></li>
<li><p>What is the maximum likelihood estimator of <span class="math inline">\(\theta_0\)</span>?</p></li>
</ol>
</section>
<section id="exercise-4." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exercise-4.">Exercise 4.</h4>
<p>Let <span class="math inline">\(X_1,\dots,X_n\overset{\text{i.i.d.}}{\sim}X\)</span> with <span class="math inline">\(X\sim\mathcal{Poisson}(\lambda_0).\)</span> That is <span class="math inline">\(X\sim f\)</span> with density function <span class="math display">\[
f(x;\lambda_0) = \frac{\lambda_0^x \exp(-\lambda_0)}{x!}.
\]</span></p>
<ol type="a">
<li><p>Find the maximum likelihood estimator, <span class="math inline">\(\hat{\lambda},\)</span> of <span class="math inline">\(\lambda_0.\)</span></p></li>
<li><p>Let <span class="math inline">\(0&lt;\lambda_0\leq 4.\)</span> Find the maximum likelihood estimator, <span class="math inline">\(\hat{P}(X=4),\)</span> of <span class="math inline">\(P(X=4).\)</span></p></li>
</ol>
</section>
<section id="exercise-5." class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="exercise-5.">Exercise 5.</h4>
<p>Show that the Newton-Raphson algorithm converges; i.e.&nbsp;that <span class="math display">\[
|e_{(m)}|\to 0 \quad\text{as}\quad m \to\infty.
\]</span> under the setup outlined in <a href="#sec-ConvNR" class="quarto-xref"><span>Section 1.2.2</span></a>.</p>
<p><strong>Tip:</strong> Use the first-order Taylor expansion of <span class="math inline">\(\ell'(\theta_{root})\)</span> around <span class="math inline">\(\theta_{(m)}\)</span> with <strong>explicit reminder</strong> term <span class="math inline">\(R\)</span> given by <span class="math display">\[
\begin{align*}
\overset{\theta_{(m)}+(\theta_{root}-\theta_{(m)})}{\ell'\big(\;\overbrace{\theta_{root}}\;\big)}
&amp; = \ell'(\theta_{(m)}) + \ell''(\theta_{(m)})(\theta_{root}-\theta_{(m)}) + R,
\end{align*}
\]</span> where <span class="math display">\[
R=\frac{1}{2}\ell'''(\xi_{(m)})(\theta_{root}-\theta_{(m)})^2
\]</span> for a mean-value <span class="math inline">\(\xi_{(m)}\)</span> between <span class="math inline">\(\theta_{(m)}\)</span> and <span class="math inline">\(\theta_{root}\)</span>. This is called the Lagrange form of the Taylor-Series reminder term and follows from the Mean-Value Theorem <a href="#thm-MVT" class="quarto-xref">Theorem&nbsp;<span>1.2</span></a>.</p>
<!-- 
## Solutions {-} 

#### Solutions of Exercise 1. {-} 

Below I use the same data (one H, four T) that was used to produce the results in @tbl-NR of our script. However, you can produce new data by setting another seed-value





::: {.cell}

```{.r .cell-code}
theta_true <- 0.2    # unknown true theta value
n          <-  5     # sample size

set.seed(1)

# simulate data: n many (unfair) coin tosses
x <- sample(x       = c(0,1), 
            size    = n, 
            replace = TRUE, 
            prob    = c(1-theta_true, theta_true)) 

## number of heads (i.e., the number of "1"s in x)
N_H <- sum(x)

## First derivative of the log-likelihood function
Lp_fct   <- function(theta, N_H = N_H, n = n){
    (N_H/theta) - (n - N_H)/(1 - theta)    
}
## Second derivative of the log-likelihood function
Lpp_fct   <- function(theta, N_H = N_H, n = n){
    - (N_H/theta^2) - (n - N_H)/(1 - theta)^2    
}

t     <- 1e-10   # convergence criterion
check <- TRUE    # check object to stop the while-loop
i     <- 0       # count iterations

## Initializations 
theta  <- 0.4     # starting value theta_{(0)}
h_step <- NULL    # empty value 
Lp     <- Lp_fct( theta, N_H=N_H, n=n)
Lpp    <- Lpp_fct(theta, N_H=N_H, n=n)

while(check){
    i         <- i + 1
    ##
    h_step_new <- -1 * (Lp_fct(theta[i], N_H=N_H, n=n) / Lpp_fct(theta[i], N_H=N_H, n=n))    
    h_step     <- c(h_step, h_step_new)
    theta_new  <- theta[i] + h_step_new
    Lp_new     <- Lp_fct( theta_new, N_H=N_H, n=n)
    Lpp_new    <- Lpp_fct(theta_new, N_H=N_H, n=n)
    ##
    theta      <- c(theta, theta_new) 
    Lp         <- c(Lp,    Lp_new) 
    Lpp        <- c(Lpp,   Lpp_new) 
    ##
    if( abs(Lp_fct(theta_new, N_H=N_H, n=n)) < t ){
      check <- FALSE
    }
}

results           <- cbind(1:length(theta)-1, theta, -Lp/Lpp, Lp)
colnames(results) <- c("m", "theta_m", "h_m", "Lp(theta_m)")
results
```

::: {.cell-output .cell-output-stdout}

```
     m   theta_m           h_m   Lp(theta_m)
[1,] 0 0.4000000 -2.400000e-01 -4.166667e+00
[2,] 1 0.1600000  3.326733e-02  1.488095e+00
[3,] 2 0.1932673  6.558924e-03  2.159084e-01
[4,] 3 0.1998263  1.736356e-04  5.433195e-03
[5,] 4 0.1999999  1.132731e-07  3.539786e-06
[6,] 5 0.2000000  4.814638e-14  1.504574e-12
```


:::
:::






#### Solutions of Exercise 2. {-} 

##### (a) Log-Likelihood Function {-}

The log-likelihood function is given by
$$
\begin{align*}
\ell_n(\theta)
&=\sum_{i=1}^n \ln (\theta\exp(-\theta X_i))\\
&=\sum_{i=1}^n (\ln \theta -\theta X_i)\\
&=n \ln \theta -\sum_{i=1}^n \theta X_i
\end{align*}
$$

##### (b) ML-Estimator  {-}

The ML estimator is defined as $\hat{\theta}_{n}=\arg\max_{\theta}\ell(\theta)$. Deriving the ML estimator $\hat\theta_n$:
$$
\begin{align*}
\ell_n'(\theta)&=n\frac{1}{\theta} - \sum_{i=1}^n X_i\\
\ell_n'(\hat\theta_n)=0\quad \Leftrightarrow &\quad 0=n\frac{1}{\hat\theta_n} - \sum_{i=1}^n X_i\\
\Leftrightarrow &\quad n\frac{1}{\hat\theta_n} = \sum_{i=1}^n X_i\\
\Leftrightarrow &\quad \hat\theta_n = \frac{1}{\frac{1}{n}\sum_{i=1}^n X_i}= \frac{1}{\bar{X}_n}
\end{align*}
$$

##### (b) Fisher Information {-}

The Fisher information is given by 
$$
\mathcal{I}(\theta_0)=-\frac{1}{n}\mathbb{E}(\ell''(\theta_0)).
$$ 
The second derivative of $\ell_n(\theta)$ evaluated at $\theta_0$ is given by
$$
\ell''_n(\theta)=-n\frac{1}{\theta^2_0}.
$$
Thus,
$$
\begin{align*}
\mathcal{I}(\theta_0)
&=-\frac{1}{n}\mathbb{E}(\ell''_n(\theta_0))\\[2ex]
&=-\frac{1}{n}\left(-n\frac{1}{\theta^2_0}\right)\\[2ex]
&=\frac{1}{\theta^2_0}.
\end{align*}
$$
Therefore, the asymptotic distribution of $\hat\theta_n$ is 
$$
\begin{align*}
\sqrt{n}(\hat\theta_n-\theta)&\to_d \mathcal{N}\left(0,\theta^2_0\right),
\end{align*}
$$
$n\to\infty.$

Since we do not know the asymptotic variance $\theta_0^2,$ we need to plug-in a consistent estimator; namely,
$$
\hat{\theta}_n^2 = \left(\frac{1}{\bar{X}_n}\right)^2 \approx \theta^2_0.
$$
This allows us to use the following Normal approximation to construct statistical hypothesis tests and confidence intervals, etc:
$$
\begin{align*}
\hat\theta_n&\overset{a}{\sim}\mathcal{N}\left(\theta,\frac{\hat{\theta}_n^2}{n}\right)
\end{align*}
$$
This approximation is good for largish sample sizes (roughly $n\geq 30$). 

Note: The above asymptotic normality result coincides with the result obtained by the delta-method.

#### Solutions of Exercise 3. {-}

##### (a) Likelihood Function {-}

Recall that the density function of $\mathcal{Unif}(0,\theta)$ is
$$
f(x;\theta_0)
=\left\{
\begin{array}{ll}
\frac{1}{\theta} & 0\leq x\leq \theta_0\\
0                & \text{otherwise}\\
\end{array}
\right.
$$
Thus, the likelihood function is
$$
\mathcal{L}_n(\theta) = \prod_{i=1}^n f(X_i;\theta).
$$
**Note:** If any $\theta<X_i,$ we have that 
$$
\mathcal{L}_n(\theta)=0.
$$ 
Putting it differently, let 
$$
X_{(n)}=\max\{X_1,\dots,X_n\}
$$ 
denote the $n$th order-statistic, then
$$
\mathcal{L}_n(\theta)=0\quad\text{for all}\quad \theta<X_{(n)}.
$$ 

However, for all values of $\theta$ with $\theta \geq X_{(n)}$ we have that 
$$
f(X_i;\theta)=\frac{1}{\theta}\quad\textbf{for all}\quad i=1,\dots,n.
$$
Thus, for all values of $\theta$ with $\theta \geq X_{(n)},$
$$
\mathcal{L}_n(\theta)=\left(\frac{1}{\theta}\right)^n.
$$ 

Summing up, 
$$
\mathcal{L}_n(\theta)
=\left\{
\begin{array}{ll}
\left(\frac{1}{\theta}\right)^n & \theta \geq  X_{(n)}\\
0                               & \theta < X_{(n)}\\
\end{array}
\right.
$${#eq-MLMaxestim}


#### (b) Maximum Likelihood Estimator of $\theta_0$ {-}

$\mathcal{L}_n(\theta)$ is strictly decreasing over the interval $[X_{(n)},\infty);$ see @fig-MLMaxestim.





::: {.cell}

```{.r .cell-code}
n          <- 20   # sample size
X_max      <- 0.25

theta_vec  <- seq(from = 0, 
                  to   = X_max * 1.5, 
                  len  = 100) 
likelihood_fun <- function(theta, X_max, n){ 
    likelihood                <- 1/(theta^n)
    likelihood[theta < X_max] <- 0 
    return(likelihood) 
}

likelihood_vec <- likelihood_fun(theta = theta_vec,
                                 X_max = X_max, 
                                 n     = n)

plot(y = likelihood_vec, 
     x = theta_vec, 
     type = "l", 
     xlab = expression(theta),
     ylab = "Likelihood", 
     main = "")            
axis(1, at = X_max, labels = expression(X[(n)]))                  
```

::: {.cell-output-display}
![Graph of the likelihood function $\mathcal{L}_n(\theta)$ given in @eq-MLMaxestim.](Ch1_MaximumLikelihood_files/figure-html/fig-MLMaxestim-1.png){#fig-MLMaxestim width=672}
:::
:::





Thus, the maximum likelihood estimator of $\theta_0$ is 
$$
\begin{align}
\hat{\theta}_{ML} 
& =\arg\max_{\theta>0}\mathcal{L}_n(\theta)\\
& = X_{(n)}.
\end{align}
$$


#### Solutions of Exercise 4. {-}


##### (a) Finding the Maximum Likelihood Estimator of $\lambda_0$ {-}

$$
\begin{align}
\mathcal{L}_n(\lambda) 
& = \prod_{i=1}^n f(X_i;\lambda)\\[2ex]
& = \prod_{i=1}^n \frac{\lambda^{X_i} \exp(-\lambda)}{X_i!} \\[2ex]
& = \frac{\lambda^{\sum_{i=1}^n X_i}  \exp(-n \lambda)}{\prod_{i=1}^n (X_i!)} \\[4ex]
\ell(\lambda) 
&= \left(\sum_{i=1}^n X_i\right) \ln(\lambda) -n\lambda\cdot 1 - \sum_{i=1}^n \ln(X_i!)
\end{align}
$$

$$
\begin{align}
\ell'_n(\lambda) 
&= \frac{\left(\sum_{i=1}^n X_i\right)}{\lambda}  - n 
\end{align}
$$

$$
\begin{align}
\ell''_n(\lambda) 
&= -\frac{\left(\sum_{i=1}^n X_i\right)}{\lambda^2} < 0  
\end{align}
$$
since by the properties of the Poisson distribution $X_1,\dots,X_n>0$ and $\lambda>0.$

Thus the maximum likelihood estimator of $\lambda_0$ is given by
$$
\begin{align}
&\frac{\left(\sum_{i=1}^n X_i\right)}{\hat\lambda_n}  - n \overset{!}{=} 0\\[2ex]
\Rightarrow & \hat \lambda_n = \frac{1}{n}\sum_{i=1}^n X_i.
\end{align}
$$


##### (b) Finding the Maximum Likelihood Estimator of $P(X=4)$ {-}

$$
\begin{align}
P(X=4) = \frac{\lambda_0^4 \exp(-\lambda_0)}{4!}
\end{align}
$$

Thus $P(X=4)$ is a function of $\lambda$
$$
\begin{align}
P(X=4)\equiv P(X=4|\lambda) = \frac{\lambda^4 \exp(-\lambda)}{4!} = \tau(\lambda)
\end{align}
$$






::: {.cell}

```{.r .cell-code}
lambda_vec <- seq(from = .0001, to = 15, len = 100)
g_vec      <- (lambda_vec^4 * exp(-1*lambda_vec))/( factorial(4) )

plot(x = lambda_vec, y = g_vec, 
     type = "l", xlab=expression(lambda), ylab=expression(tau(lambda)))
abline(v = 4)
axis(1, at = 4)
```

::: {.cell-output-display}
![](Ch1_MaximumLikelihood_files/figure-html/unnamed-chunk-5-1.png){width=672}
:::
:::





(For $0<\lambda\leq 4,$ $g(\lambda)$ is even a one-to-one mapping.) 

By the invariance property of the maximum likelihood estimator (which also applies to functions $\tau$ that are not one-to-one) we thus have
$$
\begin{align}
\hat{P}(X=4)\equiv \hat{P}(X=4|\hat{\lambda}_n) = \frac{\hat{\lambda}^4_n \exp(-\hat{\lambda}_n)}{4!}
\end{align}
$$
with $\hat{\lambda}_n=\frac{1}{n}\sum_{i=1}^n X_i.$


#### Solutions of Exercise 5. {-}

Setup of @sec-ConvNR: 

Let $\theta_{root}$ denote the root of $\ell_n';$ i.e. 
$$
\ell_n'(\theta_{root})=0.
$$ 
Let 
$$
\begin{align*}
e_{(0)}&=\theta_{root}-\theta_{(0)}\\[2ex]
e_{(m)}&=\theta_{root}-\theta_{(m)}
\end{align*}
$$
denote the start-value error and the $m$th step error, respectively.

Let 
$$
I=[\theta_{root}-|e_{(0)}|, \theta_{root}+|e_{(0)}|]
$$
denote the start-value neighborhood around $\theta_{root}.$   

Let $\ell_n'$ be "well behaved" over $I;$ such that 

* $\ell_n''(\theta)\neq 0$ for all $\theta\in I$  and 
* $\ell_n'''(\theta)$ is finite and continuous for all $\theta\in I.$ 

Let $\theta_{(0)}$ be "close enough;" i.e. let

* $M|e_{(0)}|<1,$ 

where 
$$
M=\frac{1}{2}\left(\sup_{\theta\in I}|\ell_n'''(\theta)|\right)\left(\sup_{\theta\in I}\frac{1}{|\ell_n''(\theta)|}\right)\geq 0,
$$ 

In the following, we show that the Newton-Raphson algorithm converges under this setup. 


By the second-order Taylor expansion of $\ell'(\theta_{root})$ around $\theta_{(m)}$ with the mean-value form of the remainder term, we have that 
$$
\begin{align*}
\overset{\theta_{(m)}+(\theta_{root}-\theta_{(m)})}{\ell'\big(\;\overbrace{\theta_{root}}\;\big)} 
& = \ell'(\theta_{(m)}) + 
    \ell''(\theta_{(m)})(\theta_{root}-\theta_{(m)}) + 
    \frac{1}{2}\ell'''(\xi)(\theta_{root}-\theta_{(m)})^2
\end{align*}
$$
for some real-valued number $\xi_{(m)}$ between $\theta_{root}$ and $\theta_{(m)}.$ 


Since $\ell'(\theta_{root})=0,$ we have that
$$
\begin{align*}
0
& = \ell'(\theta_{(m)}) + \ell''(\theta_{(m)})(\theta_{root}-\theta_{(m)}) + \frac{1}{2}\ell'''(\xi_{(m)})(\theta_{root}-\theta_{(m)})^2
\end{align*}
$$
Some rearrangments lead
$$
\begin{align*}
\ell'(\theta_{(m)}) + \ell''(\theta_{(m)})(\theta_{root}-\theta_{(m)}) 
& = -\frac{1}{2}\ell'''(\xi_{(m)})(\theta_{root}-\theta_{(m)})^2\\[2ex]
{\color{blue}\frac{\ell'(\theta_{(m)})}{\ell''(\theta_{(m)})}} + (\theta_{root}-\theta_{(m)}) 
&= \frac{-\ell'''(\xi_{(m)})}{2\ell''(\theta_{(m)})}(\theta_{root}-\theta_{(m)})^2\qquad[\text{dividing by}\;\ell''(\theta_{(m)})]\\[2ex]
\end{align*}
$$
Using the update steps of the alrorithm
$$
\theta_{(m+1)} = \theta_{(m)} - \frac{\ell'(\theta_{(m)})}{\ell''(\theta_{(m)})}
\quad\Leftrightarrow\quad 
\theta_{(m)} - \theta_{(m+1)}  = {\color{blue}\frac{\ell'(\theta_{(m)})}{\ell''(\theta_{(m)})}}
$$
yields
$$
\begin{align*}
\theta_{(m)} - \theta_{(m+1)} + (\theta_{root}-\theta_{(m)}) 
&= \frac{-\ell'''(\xi_{(m)})}{2\ell''(\theta_{(m)})}(\theta_{root}-\theta_{(m)})^2\\[2ex]
\Leftrightarrow\quad
\theta_{root} - \theta_{(m+1)}  
&= \frac{-\ell'''(\xi_{(m)})}{2\ell''(\theta_{(m)})}(\theta_{root}-\theta_{(m)})^2\\[2ex]
\Leftrightarrow\quad
e_{(m+1)}  
&= \frac{-\ell'''(\xi_{(m)})}{2\ell''(\theta_{(m)})}(e_{(m)})^2
\end{align*}
$$
Taking absolute values, since we are not interested in the sign of the approximation errors, yields
$$
\begin{align*}
|e_{(m+1)}|  
&= \frac{1}{2} \; |\ell'''(\xi_{(m)})|\;\frac{1}{|\ell''(\theta_{(m)})|}(e_{(m)})^2
\end{align*}
$$
Considering the worst case within $I,$ leads to the following inequality
$$
\begin{align*}
|e_{(m+1)}|  
&\leq  \overbrace{\frac{1}{2} \; \left(\sup_{\theta\in I}|\ell'''(\theta)|\right)\;\left(\sup_{\theta\in I}\frac{1}{|\ell''(\theta_{(m)})|}\right)}^{=M}\;(e_{(m)})^2\\[2ex]
\Leftrightarrow\quad |e_{(m+1)}|  
&\leq  M\;(e_{(m)})^2\\[-2ex]
\end{align*}
$${#eq-NRIneq}
To show that the Newton-Raphon algorithm converges, we need to show that 
$$
|e_{(m)}|\to 0 \quad\text{as}\quad m \to\infty. 
$$

For $0\leq M\,|e_{(0)}|<1$ the inequality in @eq-NRIneq becomes a sharp inequality
$$
\begin{align*}
&|e_{(1)}|\leq \overbrace{M\;|e_{(0)}|}^{<1}\,|e_{(0)}|
\quad\Rightarrow\quad |e_{(1)}|< \,|e_{(0)}|\\[3ex]
&{\color{darkgreen}[\text{Using that $M\;|e_{(0)}|<1$ and that $|e_{(1)}|<|e_{(0)}|$}]}\\[2ex]
\Rightarrow\quad 
& |e_{(2)}|\leq {\color{darkgreen}\overbrace{M\;|e_{(1)}|}^{<1}}\,|e_{(1)}|
\quad\Rightarrow\quad |e_{(2)}|< \,|e_{(1)}|\\[2ex]
&\phantom{|e_{(2)}|\leq \overbrace{M\;|e_{(1)}|}^{<1}\,|e_{(1)}|}\vdots\\[2ex]
\Rightarrow\quad 
& |e_{(m+1)}|< \,|e_{(m)}| \quad\text{for all }m=0,1,2\dots
\end{align*}
$$
which shows the convergence of the Newton Raphson algorithm. (The inequality in @eq-NRIneq implies that the convergence is even quadratic; i.e. very fast.)

**Special Case** $M=0$: </br>
For
$$
\sup_{\theta\in I}|\ell'''(\theta)|=0
$$
we have that $M=0$ which implies that we find the root, $\theta_{root},$ already in the first $(m=1)$ update step, since  
$$
\begin{align*}
|e_{(1)}|  
&\leq \overbrace{\left(M |e_{(0)}|\right)}^{=0}\;|e_{(0)}|\\[2ex]
\Rightarrow\quad |e_{(1)}|&=0\\[2ex]
\Rightarrow\quad \theta_{(1)}&=\theta_{root},
\end{align*}
$$ 
even when $|e_{(0)}|\gg 0.$ 

This makes sense, since $\sup_{\theta\in I}|\ell'''(\theta)|=0$ implies that $\ell'(\theta)$ has no curvature; i.e. $\ell'(\theta)$ is a straight line for all $x\in I$ which implies that the Taylor approximation used in the update steps of the Newton-Raphson algorithm is just perfect (no approximation error).


-->
</section>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>
<!-- DO NOT DELETE! -->
<!-- Further ML-Material (Particularly Tests) -->
<!-- DO NOT DELETE! -->
<!-- ## Discussion of Assumptions and Results {-} -->
<!-- \begin{itemize} -->
<!-- \item **Strict exogeneity**:  Needed to assume $\E[\varepsilon | X]=0$ to show consistency of $\hat\beta_{ML}$.  -->
<!-- \item **Homoskedasticity and non-autocorrelation**:  We used the assumption that $\E[\varepsilon eps']\sim(0, \sigma^2 I)$ to derive estimator of $\sigma^2$.   -->
<!-- \item **Normality**:  The normality assumption is used **only** to derive small-sample properties of the estimators. By using asymptotic arguments one can show that both $\hat\beta_{ML}$ and $s_{ML}^2$ will be distributed -->
<!-- asymptotically normally also without the normality assumption. -->
<!-- \end{itemize} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Best Linear Unbiased Estimator} -->
<!-- Given our assumptions, then by the Gauss-Markov theorem, it is possible to show that  -->
<!-- \begin{itemize}  -->
<!-- \item<1->$\hat\beta$ is the Best Linear Unbiased (BLUE) estimator of $\beta$ -->
<!-- \item<2-> The best linear unbiased estimator of any linear combination of the $\beta$'s is the same linear combination -->
<!-- of the $\hat\beta$'s. -->
<!-- \item<3-> The Best Linear Unbiased Predictor (BLUP) of $Y$ based on the vector $X_s$ is $\hat y_s=X^T_s\hat\beta$ -->
<!-- \end{itemize} -->
<!-- \end{frame} -->
<!-- ## Hypothesis Testing -->
<!-- ### Testing Hypotheses about One Parameter -->
<!-- \noindent**Definition of the Score** -->
<!-- Define the **score of the log likelihood** (also known as the **gradient vector** -->
<!-- for observation $i$ -->
<!-- \begin{equation*} -->
<!-- s_i(\beta)\equiv \left(\dfrac{\partial L_i}{\partial \beta_0}(\beta), \dfrac{\partial L_i}{\partial \beta_1}(\beta), \dots, \dfrac{\partial L_i}{\partial \beta_k}(\beta)\right)^T -->
<!-- \end{equation*} -->
<!-- %In the logit and probit cases, this can be shown to be -->
<!-- %\begin{equation*} -->
<!-- %s_i(\beta)\equiv\dfrac{g(x_i\beta)[y_i-G(x_i\beta)]} -->
<!-- %{G(x_i\beta)[1-G(x_i\beta)]}x_i' -->
<!-- %\end{equation*} -->
<!-- %Since $x_i$ is $1 \times (k+1)$, the score is a $(k+1) \times 1$ vector.  Recalling that in the probit %case -->
<!-- %\begin{center} -->
<!-- %$g(z)=\phi(z)$ and $G(z)=\Phi(z)$ -->
<!-- %\end{center} -->
<!-- %while with logit -->
<!-- %\begin{center} -->
<!-- %$g(z)=\exp(z)/[1+\exp(z)]^2$ and $G(z)=\exp(z)/[1+\exp(z)]$. -->
<!-- %\end{center} -->
<!-- #### Variance-Covariance Matrix {-} -->
<!-- Using the standard maximum likelihood theory it can be -->
<!-- show that the asymptotic-variance covariance matrix of the MLE $\hat\beta_{ML}$ is given by -->
<!-- \begin{equation*} -->
<!-- \text{Asy.~Var}(\hat\beta_{ML})=\left[\sum_{i=1}^N s_i(\hat\beta)s_i(\hat\beta)^T\right]^{-1} -->
<!-- \end{equation*} -->
<!-- %and therefore in our case we have -->
<!-- %\begin{equation*} -->
<!-- %\text{Asy. Var-Cov}(\hat\beta)=\left[\sum_{i=1}^N\dfrac{[g(x_i\hat\beta)]^2 x_i' x_i}{G(x_i\hat\beta) -->
<!-- %[1-G(x_i\hat\beta)]}\right]^{-1} -->
<!-- %\end{equation*} -->
<!-- %with $g(\cdot)$ and $G(\cdot)$ defined as above. -->
<!-- %\vskip .1in -->
<!-- The square roots of the diagonals of this matrix will give us the -->
<!-- **standard errors** of the estimates. -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Asymptotic Distribution} -->
<!-- Now, by the usual asymptotic theory, we have -->
<!-- \begin{equation*} -->
<!-- \dfrac{\hat\beta_j - \beta_j^0}{\text{std. err.}(\hat\beta_j)}\stackrel{a}{\sim} \mathcal{N}(0,1) -->
<!-- \end{equation*} -->
<!-- where $\beta_j^0$ is the value of the parameter under the null hypothesis. -->
<!-- So, we can do our usual "$t$-tests" although because we rely on asymptotics, -->
<!-- they should probably be more properly called $z$-tests. -->
<!-- \end{frame} -->
<!-- \subsection{Testing Hypotheses about Multiple Parameters} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Testing Joint Hypotheses} -->
<!-- We may also want to test hypotheses about multiple parameters.  Here it will -->
<!-- be useful to think about the regressions implied by imposing the restrictions. -->
<!-- So, for example,  -->
<!-- \begin{equation*} -->
<!-- \begin{array}{ll} -->
<!-- H_0: & R\beta - r = 0\\ -->
<!-- H_A: & H_0 \text{ is not true} \\ -->
<!-- \end{array} -->
<!-- \end{equation*} -->
<!-- where $R$ is a $q \times (k+1)$ matrix that defines the $q$ restrictions placed on the parameters -->
<!-- under the null hypothesis and $r$ is a $q \times 1$ vector of constants. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Restricted and Unrestricted Regressions} -->
<!-- We will define the **restricted regression** as one in which we force -->
<!-- the $R\hat\beta$ to be equal to  -->
<!-- $r$ (i.e. under the null hypothesis), and the -->
<!-- **unrestricted regression** to be one in which we allow the data to tell -->
<!-- us what the values of $\beta$ should be. -->
<!-- \vskip .2in -->
<!-- Define $L_r$ as the log-likelihood corresponding to the restricted regeression -->
<!-- and $L_u$ as the log-likelihood corresponding to the unrestricted regression. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Three Asymptotically Equivalent Tests} -->
<!-- We will discuss three asymptotically equivalent tests: -->
<!-- \begin{itemize} -->
<!-- \item **Wald test**: based on the unrestricted regression -->
<!-- \item **Likelihood ratio test**: based on both the restricted and unrestrcited regressions -->
<!-- \item **Lagrange multiplier test**: based on the restricted regression. -->
<!-- \end{itemize} -->
<!-- All three tests will give us the same answer asymptotically, but will differ -->
<!-- in their values in finite samples. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Wald Test (1)} -->
<!-- From maximum likelihood theory, we know that  -->
<!-- \begin{equation*} -->
<!-- \hat\beta \adist \mathcal{N}(\beta,V) -->
<!-- \end{equation*} -->
<!-- and therefore that $R\hat\beta$ also has an asymptotically normal distribution -->
<!-- (since it is just a linear combination of asymptotically normal variables): -->
<!-- \begin{equation*} -->
<!-- (R\hat\beta - R\beta) \adist \mathcal{N}(0, RVR') -->
<!-- \end{equation*} -->
<!-- This suggests a quadratic form which we can use to test hypotheses -->
<!-- \begin{equation*} -->
<!-- W\equiv(R\hat\beta - r)^T[R \hat V_u R']^{-1}(R\hat\beta - r) \adist \chi_q^2 -->
<!-- \end{equation*} -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Wald Test (2)} -->
<!-- Thus, with the **Wald test**, we need only estimate the *unrestricted* regression. -->
<!-- \vskip .25in -->
<!-- It measures how far apart the estimated parameters are from the values of  -->
<!-- the parameters under the null hypothesis. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Likelihood Ratio Test} -->
<!-- More conceptually simple, perhaps, is the **Likelihood Ratio Test**. -->
<!-- \vskip .15in -->
<!-- If the null hypothesis holds, imposing restrictions on the data should lead -->
<!-- to values of $L_r$ and $L_u$ that are ``close''.  The question then, is what -->
<!-- metric to use to judget how ``close '' they are. -->
<!-- \vskip .15in -->
<!-- It can be shown that -->
<!-- \begin{equation*} -->
<!-- LR\equiv -2 [L_r - L_u] \adist \chi^2_q -->
<!-- \end{equation*} -->
<!-- Therefore the $\chi^2_q$ distribution is the proper metric for judging how close -->
<!-- the likelihoods are. -->
<!-- \vskip .15in -->
<!-- We must fit both models to calculate the differences between the restricted -->
<!-- and restricted likelihoods. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Motivation} -->
<!-- The **Lagrange Multiplier Test** (also called the **Score Test**) is based -->
<!-- on the score, or gradient, vector (as defined earlier).  The idea is to measure -->
<!-- how far away from the peak of the *unrestricted* likelihood imposing the -->
<!-- restrctions forces us, which is some akin to the notion of the likelihood ratio -->
<!-- test.  -->
<!-- \vskip.15in -->
<!-- At the peak of the unrestricted log likelihood, the score would be a vector of -->
<!-- zeros.  Intuitively, then, the Lagrante Multiplier Test will measure how ``close'' -->
<!-- the score vector when we estimate the *restricted* regression is to  -->
<!-- the vector of zeroes. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Derivation (1)} -->
<!-- We can think about finding the maximum of the log likelihood subject to -->
<!-- the constraints imposed by the null hypothesis.  To simplify things, suppose we have only two -->
<!-- parameters, $\beta_1$ and $\beta_2$ with $H_0: \beta_2=c$. -->
<!-- Then: -->
<!-- \begin{equation*} -->
<!-- H(\beta, \lambda)=\sum_{i=1}^N  L_i(\beta) - \lambda'(\beta_2-c) -->
<!-- \end{equation*} -->
<!-- where $\lambda$ is the Lagrange multiplier.  Then the first order conditions -->
<!-- are -->
<!-- \begin{align*} -->
<!-- \sum_{i=1}^N  \dfrac{\partial L_i (\beta)}{\partial \beta_1} \big\vert_{\tilde\beta} -->
<!-- &=\sum_{i=1}^N s_{i1}(\tilde\beta)=0\\ -->
<!-- \tilde\lambda=\sum_{i=1}^N \dfrac{\partial L_i (\beta)}{\partial \beta_1} \big\vert_{\tilde\beta} &=\sum_{i=1}^N s_{i2}(\tilde\beta)\\ -->
<!-- \end{align*} -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Lagrange Multiplier Test: Derivation (2)} -->
<!-- Define $s_{i1}$ and $s_{i2}$ are the subvectors of $s_i(\beta)$ corresponding to  -->
<!-- $\beta_1$ and $\beta_2$, respectively. -->
<!-- \vskip .15in -->
<!-- So we are in some sense testing whether $\tilde\lambda$ is ``close'' to zero or -->
<!-- not, evaluated at the restricted values of the parameters. -->
<!-- \vskip .15in -->
<!-- It's possible to show, then, that -->
<!-- \begin{equation*} -->
<!-- LM\equiv  s'(\tilde\beta) \tilde V_r^{-1} s(\tilde\beta) \adist \chi^2_q -->
<!-- \end{equation*} -->
<!-- where $s(\tilde\beta)$ is the score evaluated at the *restricted* estimates of -->
<!-- the parameters, and $\tilde V_r$ is the estimated variance-covariance matrix from the *restricted* regression. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Relationshiop between W, LR, and LM tests} -->
<!-- \includegraphics[angle=90, scale=.60]{wald-lm-lr.ps} -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Relationship between W, LR, and LM} -->
<!-- While all three tests are asymptotically equivalent, it can be shown that in finite -->
<!-- samples -->
<!-- \begin{center} -->
<!-- $LM < LR < W$ -->
<!-- \end{center} -->
<!-- meaning that LM tests will favor not rejecting the null and W tests will favor rejecting -->
<!-- the null. -->
<!-- \end{frame} -->
<!-- \end{document} -->
<!-- \section{Goodness of Fit Measures} -->
<!-- \subsection{Goodness of Fit Measures} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Goodness of Fit in Probit and Logit} -->
<!-- As in the linear regression model, we would like to have some measure -->
<!-- of how well our model fits the data.  Unlike linear models, however, where -->
<!-- $R^2$ serves as the primary goodness-of-fit measure, there is no -->
<!-- standard metric that is used. -->
<!-- \vskip .15in -->
<!-- Now, define $L_0$ as the log likelihood of a model in which we constrain -->
<!-- all of the coefficients (except the constant) to be equal to zero. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- %------------------------------------------------- -->
<!-- %\begin{frame} -->
<!-- %\frametitle{A Note on $L_0$} -->
<!-- %Note that we do not actually need to run a  regression to estimate $L_0$. -->
<!-- %\vskip .15in -->
<!-- %With just a constant term in the model, the likelihood function is given by -->
<!-- %\begin{align*} -->
<!-- %L_0&=\sum y_i \ln(N_1/N) + \sum (1-y_i) \ln(1-N_1/N)\\ -->
<!--  %    &=N_1 \ln(N_1/N) + N_0\ln(N_0/N)\\ -->
<!-- %\end{align*} -->
<!-- %where $N_1$ indicates the number of success and $N_0$ is the number of failures. -->
<!-- %\end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{Pseudo-$R^2$} -->
<!-- The first goodness-of-fit measure is meant as an analog to the $R^2$ from -->
<!-- linear regression, called the pseudo-$R^2$.  It is defined as -->
<!-- \begin{equation*} -->
<!-- \text{pseudo}-R^2=1-\dfrac{1}{1+2(L_u - L_0)/N} -->
<!-- \end{equation*} -->
<!-- Intuitively, the greater the distance between the restricted and -->
<!-- unrestricted log likelihoods, the more the model explains the variation -->
<!-- in $y$, and the greater the pseudo-$R^2$ will be. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- \begin{frame} -->
<!-- \frametitle{McFadden's $R^2$} -->
<!-- McFadden suggested an alternative goodness of fit-measures: -->
<!-- \begin{equation*} -->
<!-- \text{McFadden}-R^2= 1- L_u/L_0 -->
<!-- \end{equation*} -->
<!-- since the log likelihood is just the sum of log probabilities, it must be that -->
<!-- $L_0 < L_u < 0$. -->
<!-- \end{frame} -->
<!-- %------------------------------------------------- -->
<!-- %\begin{frame} -->
<!-- %\frametitle{Proportion of Correct Predictions} -->
<!-- %An additional measure of the fit of the model is the number of observations for -->
<!-- %which the model correctly predicts the outcome. -->
<!-- %\end{frame} -->


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-CasellaBerger_StatInf_2001" class="csl-entry" role="listitem">
Casella, George, and Roger Berger. 2001. <em>Statistical Inference</em>. 2nd ed. Duxbury.
</div>
<div id="ref-Kirkpatrick_2017" class="csl-entry" role="listitem">
Kirkpatrick, James, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, et al. 2017. <span>“Overcoming Catastrophic Forgetting in Neural Networks.”</span> <em>Proceedings of the National Academy of Sciences</em> 114 (13): 3521–26.
</div>
<div id="ref-Martens_2020" class="csl-entry" role="listitem">
Martens, James. 2020. <span>“New Insights and Perspectives on the Natural Gradient Method.”</span> <em>The Journal of Machine Learning Research</em> 21 (1): 5776–5851.
</div>
<div id="ref-White1982" class="csl-entry" role="listitem">
White, Halbert. 1982. <span>“Maximum Likelihood Estimation of Misspecified Models.”</span> <em>Econometrica</em>, 1–25.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="Organization of the Course">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Organization of the Course</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Ch2_EMAlgorithmus.html" class="pagination-link" aria-label="EM Algorithm &amp; Cluster Analysis">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">EM Algorithm &amp; Cluster Analysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>